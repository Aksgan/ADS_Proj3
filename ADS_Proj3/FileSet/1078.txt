an inverse-arithmetic-coder. == Theory == The theoretical background of compression is provided by [[information theory]] (which is closely related to [[algorithmic information theory]]) for lossless compression, and by [[rate–distortion theory]] for lossy compression. These fields of study were essentially created by [[Claude Shannon]], who published fundamental papers on the topic in the late 1940s and early 1950s. [[Cryptography]] and [[coding theory]] are also closely related. The idea of data compression is deeply connected with [[statistical inference]]. Many lossless data compression systems can be viewed in terms of a four-stage model. Lossy data compression systems typically include even more stages, including, for example, prediction, frequency transformation, and quantization. === Machine learning === {{see also|Machine learning}} There is a close connection between [[machine learning]] and compression: a system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression (by using arithmetic coding on the output distribution), while an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as justification for data compression as a benchmark for "general intelligence".<ref>[http://cs.fit.edu/~mmahoney/compression/rationale.html Rationale for a Large Text Compression Benchmark]</ref> === Data differencing === {{main|Data differencing}} Data compression can be seen as a special case of [[data differencing]]<ref>RFC 3284</ref><ref>{{Citation | first1=D.G. | last1 = Korn | first2 = K.P. |last2=Vo |title=Vdelta: Differencing and Compression | series=Practical Reusable Unix Software | editor = B. Krishnamurthy | publisher=[[John Wiley & Sons]] | year = 1995}}</ref> – data differencing consists of producing a ''difference'' given a ''source'' and a ''target'', with patching producing a ''target'' given a ''source'' and a ''difference,'' while data compression consists of producing a compressed file given a target, and decompression consists of producing a target given only a compressed file. Thus, one can consider data compression as data differencing with empty source data, the compressed file corresponding to a "difference from nothing". This is the same as considering absolute [[entropy (information theory)|entropy]] (corresponding to data compression) as a special case of [[relative entropy]] (corresponding to data differencing) with no initial data. When one wishes to emphasize the connection, one may use the term '''[[differential compression]]''' to refer to data differencing. ==See also== === Data compression topics=== <div style="-moz-column-count:2; column-count:2;"> * [[Algorithmic complexity theory]] * [[Information entropy]] * [[Self-extracting archive]] * [[Image compression]] * [[Speech coding]] * [[Video compression]] * [[Multimedia compression]] * [[Minimum description length]] * [[Minimum message length]] (two-part lossless compression designed for inference) * [[List of archive formats]] * [[Comparison of file archivers]] * [[List of Unix programs]] * [[Free file format]] * [[HTTP compression]] * [[Magic compression algorithm]] * [[Data compression symmetry]] * [[Dyadic distribution]] </div> === Compression algorithms === ==== Lossless data compression ==== * [[Data deduplication]] * [[run-length encoding]] * [[dictionary coder]]s ** [[LZ77|LZ77 & LZ78]] ** [[LZW]] * [[Burrows-Wheeler transform]] * [[prediction by partial matching]] (also known as PPM) * [[context mixing]] * [[Dynamic Markov Compression]] (DMC) * [[entropy encoding]] ** [[Huffman coding]] (simple entropy coding; commonly used as the final stage of compression) *** [[Adaptive Huffman coding]] *** [[Shannon-Fano coding]] ** [[arithmetic coding]] (more advanced) *** [[range encoding]] (same as arithmetic coding, but looked at in a slightly different way) ** [[Golomb coding]] (simple entropy coding for infinite input data with a [[geometric distribution]]) ** [[universal code (data compression)|universal code]]s (entropy coding for infinite input data with an arbitrary distribution) *** [[Elias gamma coding]] *** [[Fibonacci coding]] * Slepian-Wolf coding (SWC) (lossless [[distributed source coding]] (DSC)) ==== Lossy data compression ==== * [[discrete cosine transform]] * [[fractal compression]] ** [[fractal transform]] * [[wavelet compression]] * [[vector quantization]] * [[linear predictive coding]] * [[Modulo-N code|Modulo-N code for correlated data]] * [[A-law]] Compander * [[Mu-law]] Compander * Wyner-Ziv coding(WZC) (lossy [[Distributed source coding]](DSC)) ==== Example implementations ==== * [[DEFLATE (algorithm)|DEFLATE]] (a combination of LZ77 and Huffman coding) &ndash; used by [[ZIP file format|ZIP]], [[gzip]] and [[Portable Network Graphics|PNG]] files * [[LZMA]] used by [[7-Zip]] * [[LZO]] (very fast LZ variation, speed oriented) * [[LZX (algorithm)|LZX]] (an LZ77 family compression algorithm) * [[liblzg]] (a minimal LZ77 based compression library) * [[Unix]] ''[[compress]]'' utility (the .Z file format), and [[Graphics Interchange Format|GIF]] use [[LZW]] * Unix ''[[pack (program)|pack]]'' utility (the .z file format) used [[Huffman coding]] * [[bzip2]] (a combination of the Burrows-Wheeler transform and Huffman coding) * [[PAQ]] (very high compression based on [[context mixing]], but extremely slow; competing in the top of the highest compression competitions) * [[JPEG]] (image compression using a discrete cosine transform, then quantization, then Huffman coding) * [[MPEG]] (audio and video compression standards family in wide use, using [[Discrete cosine transform|DCT]] and motion-compensated prediction for video) ** [[MP3]] (a part of the [[MPEG-1]] standard for sound and music compression, using subbanding and [[Modified discrete cosine transform|MDCT]], perceptual modeling, quantization, and Huffman coding) ** [[Advanced Audio Coding|AAC]] (part of the [[MPEG-2]] and [[MPEG-4]] audio coding specifications, using [[Modified discrete cosine transform|MDCT]], perceptual modeling, quantization, and Huffman coding) * [[Vorbis]] (DCT based AAC-alike audio codec, designed with a focus on avoiding patent encumbrance) * [[JPEG 2000]] (image compression using wavelets, then quantization, then entropy coding) * [[TTA (codec)|TTA]] (uses [[linear predictive coding]] for lossless audio compression) * [[Free Lossless Audio Codec|FLAC]] ([[linear predictive coding]] for lossless audio compression) === Corpora === Data collections, commonly used for comparing compression algorithms. * [[Canterbury Corpus]] * [[Calgary Corpus]] == References == {{reflist}} == External links == * [http://www.cs.cmu.edu/afs/cs/project/pscico-guyb/realworld/www/compression.pdf Introduction to Data Compression] by Guy E Blelloch from [[Carnegie Mellon University|CMU]] {{Compression Methods}} {{Compression Formats}} {{Compression Software Implementations}} {{DEFAULTSORT:Data Compression}} [[Category:Data compression| ]] [[Category:Computer storage]] [[Category:Formal sciences]] [[als:Datenkompression]] [[ar:ضغط بيانات]] [[be-x-old:Сьцісканьне зьвестак]] [[bs:Sažimanje podataka]] [[bg:Компресиране на данни]] [[ca:Compressió de dades]] [[cs:Komprese dat]] [[da:Datakomprimering]] [[de:Datenkompression]] [[et:Andmete pakkimine]] [[el:Συμπίεση δεδομένων]] [[es:Compresión de datos]] [[fa:فشرده‌سازی داده‌ها]] [[fr:Compression de données]] [[ga:Comhbhrú sonraí]] [[ko:데이터 압축]] [[hr:Sažimanje podataka]] [[id:Kompresi data]] [[it:Compressione dei dati]] [[he:דחיסת נתונים]] [[lt:Glaudinimas]] [[hu:Adattömörítés]] [[ms:Mampatan data]] [[nl:Datacompressie]] [[ja:データ圧縮]] [[pl:Kompresja (informatyka)]] [[pt:Compressão de dados]] [[ro:Compresia datelor]] [[ru:Сжатие данных]] [[simple:Data compression]] [[sk:Kompresia dát]] [[sh:Kompresija podataka]] [[fi:Tiedonpakkaus]] [[sv:Datakompression]] [[th:การบีบอัดข้อมูล]] [[tr:Veri sıkıştırma]] [[uk:Стиснення даних]] [[ur:معطیاتی دابیت]] 