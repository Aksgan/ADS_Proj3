a partial 32-bit model is one way to handle this and is in general reasonably effective. For example, the [[z/OS]] operating system takes this approach currently, requiring program code to reside in 31-bit address spaces (the high order bit is not used in address calculation on the underlying hardware platform) while data objects can optionally reside in 64-bit regions. Currently, most proprietary [[x86]] software is compiled into 32-bit code, with less being also compiled into 64-bit code (although the trend is rapidly equalizing {{Citation needed|date=July 2010}}), so much does not take advantage of the larger 64-bit address space or wider 64-bit registers and data paths on x86 processors, or the additional registers in 64-bit mode. However, users of most RISC platforms, and users of [[free software|free]] or [[open source]] operating systems (where the [[source code]] is available for recompiling with a 64-bit compiler) have been able to use exclusive 64-bit computing environments for years due to the likelihood of the existence of someone willing to compile the code thusly. Not all such applications require a large address space nor manipulate 64-bit data items, so they wouldn't benefit from the larger address space or wider registers and data paths. The main advantage to 64-bit versions of such applications is the ability to access more registers in the [[x86-64]] architecture. === Software availability === x86-based 64-bit systems sometimes lack equivalents to [[software]] that is written for 32-bit architectures. The most severe problem in Microsoft Windows is incompatible [[device driver]]s. Most 32-bit application software can run on a 64-bit operating system in a compatibility mode, also known as an [[Emulator|emulation]] mode, e.g. Microsoft [[WoW64]] Technology for IA-64 and AMD64. The 64-bit Windows Native Mode<ref>{{cite web|url=http://technet.microsoft.com/en-us/sysinternals/bb897447.aspx |title=Inside Native Applications |publisher=Technet.microsoft.com |date=2006-11-01 |accessdate=2010-11-19}}</ref> driver environment runs atop 64-bit NTDLL.DLL which cannot call 32-bit Win32 subsystem code (often devices whose actual hardware function is emulated in user mode software, like Winprinters). Because 64-bit drivers for most devices were not available until early 2007 (Vista x64), using 64-bit Microsoft Windows operating system was considered a challenge. However, the trend is changing towards 64-bit computing as most manufacturers provide both 32-bit and 64-bit drivers nowadays, so this issue is most likely to occur when attempting to use older peripherals. This is less of a problem with open source drivers that are already available for a 32-bit OS, since they can be modified to be 64-bit compatible, if necessary. Furthermore, support for hardware made before early 2007 was equally troubling for opensource platforms due to their small market shares in desktop market. On most Macs, [[Mac OS X]] runs with a 32-bit kernel even on 64-bit-capable processors, but the 32-bit kernel can run 64-bit user-mode code; this allows those Macs to support 64-bit processes while still supporting 32-bit device drivers - although not 64-bit drivers and performance advantages that would come with them. On systems with 64-bit processors, both the 32-bit and 64-bit Mac OS X kernel can run 32-bit user-mode code, and all versions of Mac OS X include 32-bit versions of libraries that 32-bit applications would use, so 32-bit user-mode software for Mac OS X will run on those systems. [[Linux]] and most other [[Unix-like]] operating systems, and the [[C (programming language)|C]] and [[C++]] toolchains for them, have supported 64-bit processors for many years: releasing 64-bit versions of their operating system before official Microsoft releases. Many applications and libraries for those platforms are [[open source]], written in C and C++, so that, if it's 64-bit-safe, they can be compiled into 64-bit versions. This source bade distribution model with an emphasis on frequent releases and cutting edge code makes availability of application software for those operating systems less of an issue. ==64-bit data models== {{inappropriate tone|section|date=December 2010}} Converting application software written in a [[high-level language]] from a 32-bit architecture to a 64-bit architecture varies in difficulty. One common recurring problem is that some programmers assume that [[Pointer (computing)|pointers]] have the same length as some other data type. These programmers assume they can transfer quantities between these data types without losing information. Those assumptions happen to be true on some 32-bit machines (and even some 16-bit machines), but they are no longer true on 64-bit machines. This common mistake is often called "the heresy that 'all the world's a VAX.'".<ref> [http://www.ibm.com/developerworks/power/library/pa-openpower1/#N100C7 "Exploring 64-bit development on POWER5: How portable is your code, really?"] by Peter Seebach 2006 </ref><ref>[http://www.lysator.liu.se/c/ten-commandments.html "The Ten Commandments for C Programmers"] by Henry Spencer</ref><ref>{{cite web|url=http://www.datacenterworks.com/stories/thud.html |title=The Story of Thud and Blunder |publisher=Datacenterworks.com |date= |accessdate=2010-11-19}}</ref> The [[C (programming language)|C programming language]] and its descendant [[C++]] make it particularly easy to make this sort of mistake. Differences between the [[C90 (C version)|C89]] and [[C (programming language)#C99|C99]] language standards also exacerbate the problem.<ref>{{cite web|firat=Eric |last=Sosman |url=http://groups.google.com/group/comp.lang.c/msg/82fdb7c12af4e6ba |title=Comp.lang.c: C89, size_t, and long |publisher=Groups.google.com |date=2007-03-14 |accessdate=2010-11-19}}</ref> To avoid this mistake in C and C++, the <code>sizeof</code> operator can be used to determine the size of these primitive types if decisions based on their size need to be made, both at compile- and run-time. Also, the <[[limits.h]]> header in the [[C (programming language)#C99|C99]] standard, and numeric_limits class in <limits> header in the C++ standard, give more helpful info; sizeof only returns the size in ''[[Character (computing)|chars]]''. This used to be misleading, because the standards leave the definition of the <code>CHAR_BIT</code> macro, and therefore the number of bits in a ''char'', to the implementations. However, except for those compilers targeting [[Digital Signal Processor|DSP]]s, "64 bits == 8 chars of 8 bits each" has become the norm. One needs to be careful to use the <code>ptrdiff_t</code> type (in the standard header <code><stddef.h></code>) for the result of subtracting two pointers; too much code incorrectly uses "int" or "long" instead. To represent a pointer (rather than a pointer difference) as an integer, use <code>uintptr_t</code> where available (it is only defined in C99, but some compilers otherwise conforming to an earlier version of the standard offer it as an extension). Neither C nor C++ define the length of a pointer, int, or long to be a specific number 