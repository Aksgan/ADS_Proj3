of the ACM | year=1974 | volume=21 | pages=201–208 | number= | doi= }}. *{{Citation | last1 = Shiloach | first1 = Yossi | last2 = Vishkin | first2 = Uzi | year = 1982 | title = An ''O''(''n''<sup>2</sup> log ''n'') parallel max-flow algorithm | journal = Journal of Algorithms | volume = 3 | issue = | pages = 128–146 | doi = }}. * {{cite book | first = Joseph | last = JaJa | coauthors = | title = [[An Introduction to Parallel Algorithms]] | edition = | publisher = Addison-Wesley | year = 1992 | isbn = 0-201-54856-9 }} * {{cite book | first = Jorg | last = Keller | coauthors = Kessler, Cristoph W.; Traeff, Jesper L. | title = [[Practical PRAM Programming]] | edition = | publisher = Wiley-Interscience | year = 2001 | isbn = 0-471-35351-5 }} *{{Citation | last1 = Naishlos | first1 = Dorit | last2 = Nuzman | first2 = Joseph | last3 = Tseng | first3 = Chau-Wen | last4 = Vishkin | first4 = Uzi | year = 2003 | title = Towards a First Vertical Prototyping of an Extremely Fine-Grained Parallel Programming Approach | journal = Theory of Computer Systems (Special Issue of 2001 ACM Symp. on Parallel Algorithms and Architecture) | volume = 36 | issue = | pages = 551–552 | doi = | url=http://www.umiacs.umd.edu/users/vishkin/XMT/spaa01-j-03.pdf }}. *{{Citation | last1 = Torbert | first1 = Shane | last2 = Vishkin | first2 = Uzi | last3 = Tzur | first3 = Ron | last4 = Ellison | first4 = David | year = 2010 | title = Is teaching parallel algorithmic thinking to high-school student possible? One teacher’s experience. | journal = ACM Technical Symposium on Computer Science Education (SIG CSE), Milwaukee, WI, March 10-13, 2010, to appear | volume = | issue = | pages = | doi = | url= }}. *{{Citation | last1=Vishkin | first1=Uzi | last2=Dascal | first2=Shlomit | last3=Berkovich | first3=Efraim | last4=Nuzman | first4=Joseph | title=Proc. 1998 ACM [[Symposium on Parallel Algorithms and Architectures]] (SPAA) | contribution=Explicit Multi-Threading (XMT) bridging models for instruction parallelism | pages=140–151 | year=1998 | doi= | url=http://www.umiacs.umd.edu/users/vishkin/XMT/spaa98.ps }}. * {{cite book | authorlink = Uzi Vishkin | first = Uzi | last = Vishkin | coauthors = | title = Thinking in Parallel: Some Basic Data-Parallel Algorithms and Techniques, 104 pages | edition = | publisher = Class notes of courses on parallel algorithms taught since 1992 at the University of Maryland, College Park, Tel Aviv University and the Technion | year = 2009 | isbn = | url=http://www.umiacs.umd.edu/users/vishkin/PUBLICATIONS/classnotes.pdf }} *{{Citation | last1=Wen | first1=Xingzhi | last2=Vishkin | first2=Uzi | title=Proc. 2008 ACM Conference on Computing Frontiers (Ischia, Italy) | contribution=FPGA-based prototype of a PRAM-on-chip processor | pages=55–66 | year=2008 | doi=10.1145/1366230.1366240 | url=http://www.umiacs.umd.edu/users/vishkin/XMT/CompFrontiers08.pdf }}. *{{Citation | last1=Vishkin | first1=Uzi | title=Communications of the ACM, Volume 54 Issue 1, January 2011 | contribution=Using simple abstraction to reinvent computing for parallelism | pages=75–85 | year=2011 | doi=10.1145/1866739.1866757 | url=10.1145/1866739.1866757 }}. ==Notes== {{reflist|2}} ==External links== * [http://www.umiacs.umd.edu/~vishkin/XMT/index.shtml Home page of the XMT project, with links to a software release, on-line tutorial and to material for teaching parallelism]. [[Category:Parallel computing]] [[Category:Distributed computing architecture]]</text> </page> <page> <id>12853</id> <title>Explicit parallelism</title> <text>{{Unreferenced|date=December 2009}} In [[computer programming]], '''explicit parallelism''' is the representation of concurrent computations by means of primitives in the form of special-purpose directives or function calls. Most parallel primitives are related to process synchronization, communication or task partitioning. As they seldom contribute to actually carry out the intended computation of the program, their computational cost is often considered as [[parallelization overhead]]. The advantage of explicit [[parallel programming]] is the absolute programmer control over the parallel execution. A skilled parallel programmer takes advantage of explicit parallelism to produce very efficient code. However, programming with explicit parallelism is often difficult, especially for non computing specialists, because of the extra work involved in planning the task division and synchronization of concurrent processes. In some instances, explicit parallelism may be avoided with the use of an optimizing compiler that automatically extracts the parallelism inherent to computations (see [[implicit parallelism]]). ==Programming with explicit parallelism== *[[Occam (programming language)]] *[[Erlang (programming language)]] *[[Message Passing Interface]] *[[Parallel Virtual Machine]] *[[Ease programming language]] *[[Ada programming language]] *[[Java (programming language)|Java programming language]] *[[JavaSpaces]] {{Parallel Computing}} {{DEFAULTSORT:Explicit Parallelism}} [[Category:Computer programming]]</text> </page> <page> <id>12855</id> <title>Explicitly parallel instruction computing</title> <text>{{primarysources|date=October 2010}} {{refimprove|date=October 2010}} '''Explicitly Parallel Instruction Computing''' ('''EPIC''') is a term coined in 1997 by the [[Itanium|HP–Intel alliance]]<ref>{{cite web |url = http://www.hpl.hp.com/techreports/1999/HPL-1999-111.pdf |format=PDF|title = EPIC: An Architecture for Instruction-Level Parallel Processors |accessdate = 2008-05-08 |last = Schlansker and Rau |work = HP Laboratories Palo Alto, HPL-1999-111 |month = February | year = 2000 }}</ref> to describe a [[computing paradigm]] that researchers had been investigating since the early 1980s.<ref>{{cite patent|US|4847755}}</ref> This paradigm is also called ''Independence'' architectures. It was the basis for [[Intel]] and [[Hewlett-Packard|HP]] development of the Intel [[Itanium]] architecture,<ref name="HP_Labs">{{cite web | url = http://www.hpl.hp.com/news/2001/apr-jun/itanium.html | title = Inventing Itanium: How HP Labs Helped Create the Next-Generation Chip Architecture | accessdate = 2007-12-14 | last = | first = | authorlink = | month = June | year = 2001 | work = [[Hewlett-Packard|HP]] Labs }}</ref> and [[Hewlet-Packard|HP]] later asserted that "EPIC" was merely an old term for the Itanium architecture.<ref name="anand">{{cite web | url = http://www.anandtech.com/cpuchipsets/showdoc.aspx?i=2598 | title = Itanium&ndash;Is there light at the end of the tunnel? | accessdate = 2008-05-08 | last = De Gelas | first = Johan | authorlink = | date = November 9, 2005 | work = [[AnandTech]] }}</ref> EPIC permits microprocessors to execute software instructions in parallel by using the [[compiler]], rather than complex on-[[die (integrated circuit)|die]] circuitry, to control parallel instruction execution. This was intended to allow simple performance scaling without resorting to higher [[clock rate|clock frequencies]]. ==Roots in VLIW== By 1989, researchers at HP recognized that RISC architectures were reaching a limit at one instruction per cycle {{Clarify|date=September 2009}}. They began an investigation into a new architecture, later named EPIC.<ref 