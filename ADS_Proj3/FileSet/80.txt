computation results in many steps and in a large number: :<math>\begin{align} A(4, 3) & = A(3, A(4, 2)) \\ & = A(3, A(3, A(4, 1))) \\ & = A(3, A(3, A(3, A(4, 0)))) \\ & = A(3, A(3, A(3, A(3, 1)))) \\ & = A(3, A(3, A(3, A(2, A(3, 0))))) \\ & = A(3, A(3, A(3, A(2, A(2, 1))))) \\ & = A(3, A(3, A(3, A(2, A(1, A(2, 0)))))) \\ & = A(3, A(3, A(3, A(2, A(1, A(1, 1)))))) \\ & = A(3, A(3, A(3, A(2, A(1, A(0, A(1, 0))))))) \\ & = A(3, A(3, A(3, A(2, A(1, A(0, A(0, 1))))))) \\ & = A(3, A(3, A(3, A(2, A(1, A(0, 2)))))) \\ & = A(3, A(3, A(3, A(2, A(1, 3))))) \\ & = A(3, A(3, A(3, A(2, A(0, A(1, 2)))))) \\ & = A(3, A(3, A(3, A(2, A(0, A(0, A(1, 1))))))) \\ & = A(3, A(3, A(3, A(2, A(0, A(0, A(0, A(1, 0)))))))) \\ & = A(3, A(3, A(3, A(2, A(0, A(0, A(0, A(0, 1)))))))) \\ & = A(3, A(3, A(3, A(2, A(0, A(0, A(0, 2)))))) \\ & = A(3, A(3, A(3, A(2, A(0, A(0, 3))))) \\ & = A(3, A(3, A(3, A(2, A(0, 4))))) \\ & = A(3, A(3, A(3, A(2, 5)))) \\ & = ... \\ & = A(3, A(3, A(3, 13))) \\ & = ... \\ & = A(3, A(3, 65533)) \\ & = ... \\ & = A(3, 2^{65536} - 3) \\ & = ... \\ & = 2^{2^{ \overset{65536}{} }} - 3. \\ \end{align}</math> Written as a power of 10, this is roughly equivalent to 10<sup>6.031{{e|19727}}</sup>. ==Inverse== Since the function ''f'' (''n'') = ''A''(''n'', ''n'') considered above grows very rapidly, its [[inverse function]], ''f''<sup>−1</sup>, grows very slowly. This '''inverse Ackermann function''' ''f''<sup>−1</sup> is usually denoted by α. In fact, α(n) is less than 5 for any practical input size ''n'', since A(4, 4) is on the order of <math>2^{2^{10^{19729}}}</math>. This inverse appears in the time [[computational complexity theory|complexity]] of some [[algorithm]]s, such as the [[disjoint-set data structure]] and [[Bernard Chazelle|Chazelle]]'s algorithm for [[minimum spanning tree]]s. Sometimes Ackermann's original function or other variations are used in these settings, but they all grow at similarly high rates. In particular, some modified functions simplify the expression by eliminating the ''−3'' and similar terms. A two-parameter variation of the inverse Ackermann function can be defined as follows, where <math>\lfloor x \rfloor</math> is the [[floor function]]: :<math>\alpha(m,n) = \min\{i \geq 1 : A(i,\lfloor m/n \rfloor) \geq \log_2 n\}.</math> This function arises in more precise analyses of the algorithms mentioned above, and gives a more refined time bound. In the disjoint-set data structure, ''m'' represents the number of operations while ''n'' represents the number of elements; in the minimum spanning tree algorithm, ''m'' represents the number of edges while ''n'' represents the number of vertices. Several slightly different definitions of α(''m'', ''n'') exist; for example, log<sub>2</sub> ''n'' is sometimes replaced by ''n'', and the floor function is sometimes replaced by a [[ceiling function|ceiling]]. Other studies might define an inverse function of one where m is set to a constant, such that the inverse applies to a particular row.<ref>[http://cat.inist.fr/?aModele=afficheN&cpsidt=15618233 An inverse-Ackermann style lower bound for the online minimum spanning tree verification problem] November 2002</ref> ==Use as benchmark== The Ackermann function, due to its definition in terms of extremely deep recursion, can be used as a benchmark of a [[compiler]]'s ability to optimize recursion. The first use of Ackermann's function in this way was by Yngve Sundblad, ''The Ackermann function. A Theoretical, computational and formula manipulative study.'' (BIT 11 (1971), 107119). This seminal paper was taken up by Brian Wichmann (co-author of the [[Whetstone (benchmark)|Whetstone benchmark]]) in a trilogy of papers written between 1975 and 1982.<ref>{{cite web | title=Ackermann's Function: A Study In The Efficiency Of Calling Procedures | year = 1975 | url=http://history.dcs.ed.ac.uk/archive/docs/Imp_Benchmarks/ack.pdf}}</ref><ref>{{cite web | title=How to Call Procedures, or Second Thoughts on Ackermann's Function | year = 1977 | url=http://history.dcs.ed.ac.uk/archive/docs/Imp_Benchmarks/ackpe.pdf}}</ref><ref>{{cite web | title=Latest results from the procedure calling test, Ackermann's function | year = 1982 | url=http://history.dcs.ed.ac.uk/archive/docs/Imp_Benchmarks/acklt.pdf}}</ref> For example, a compiler which, in analyzing the computation of ''A''(3, 30), is able to save intermediate values like ''A''(3, ''n'') and ''A''(2, ''n'') in that calculation rather than recomputing them, can speed up computation of ''A''(3, 30) by a factor of hundreds of thousands. Also, if ''A''(2, ''n'') is computed directly rather than as a recursive expansion of the form ''A''(1, ''A''(1, ''A''(1,...''A''(1, 0)...))), this will save significant amounts of time. Computing ''A''(1, ''n'') takes linear time in ''n''. Computing ''A''(2, ''n'') requires quadratic time, since it expands to [[Big O notation|O]](''n'') nested calls to ''A''(1, ''i'') for various ''i''. Computing ''A''(3, ''n'') requires time proportionate to 4<sup>''n''+1</sup>. The computation of ''A''(3, 1) in the example above takes 16 (4<sup>2</sup>) steps. ''A''(4, 2), which appears as a decimal expansion in several web pages, cannot possibly be computed by simple recursive application of the Ackermann function in any tractable amount of time. Instead, shortcut formulas such as ''A''(3, ''n'') = 8×2<sup>''n''</sup>−3 are used as an optimization to complete some of the recursive calls. A practical method of computing functions similar to Ackermann's is to use [[memoization]]<!--NOT memorization--> of intermediate results. A compiler could apply this technique to a function automatically using [[Donald Michie]]'s "[[memo function]]s".<ref>[http://www.gtoal.com/plsql/ackerman-memo.pls.html Example: Explicit memo function version of Ackermann's function] implemented in PL/SQL</ref>{{Citation needed|date=February 2007}} ==Ackermann numbers==<!-- This section is linked from [[Googolplex]] --> In ''The Book of Numbers'', [[John Horton Conway]] and [[Richard K. Guy]] define the sequence of '''Ackermann numbers''' to be 1↑1, 2↑↑2, 3↑↑↑3, etc.;<ref>John Horton Conway and Richard K. Guy. [http://books.google.com/books?id=0--3rcO7dMYC&lpg=PA60&dq=%22Ackermann%20number%22&pg=PA60#v=onepage&q=%22Ackermann%20number%22&f=false ''The Book of Numbers'']. New York: Springer-Verlag, pp. 60-61, 1996. ISBN 978-0-387-97993-9</ref> that is, the n<sup>th</sup> Ackermann number is defined to be n↑<sup>n</sup>n (''n'' = 1, 2, 3, ...), where m↑<sup>k</sup>n is [[Knuth's up-arrow notation|Knuth's up-arrow]] version of the Ackermann function. The first few Ackermann numbers are: :* 1↑1 = 1<sup>1</sup> = 1, :* 2↑↑2 = 2↑2 = 2<sup>2</sup> = 4, :* 3↑↑↑3 = 3↑↑3↑↑3 = 3↑↑(3↑3↑3) = <math>3\uparrow\uparrow3^{3^3} = 3\uparrow\uparrow7625597484987 = \underbrace{3^{3^{3^{3^{.^{.^{.^{3}}}}}}}}_{7625597484987{\rm\ threes}}</math> The fourth 