called a confidence interval for the parameter ''μ''. How do we calculate such an interval? The endpoints of the interval have to be calculated from the sample, so they are statistics, functions of the sample ''X''<sub>1</sub>, ..., ''X''<sub>25</sub> and hence random variables themselves. In our case we may determine the endpoints by considering that the sample mean {{overbar|''X''}} from a normally distributed sample is also normally distributed, with the same expectation ''μ'', but with [[Standard error (statistics)|standard error]] ''σ''/&radic;''n'' = 0.5 (grams). By standardizing, we get a random variable :<math>Z = \frac {\bar X-\mu}{\sigma/\sqrt{n}} =\frac {\bar X-\mu}{0.5} </math> dependent on the parameter μ to be estimated, but with a standard normal distribution independent of the parameter ''μ''. Hence it is possible to find numbers −''z'' and ''z'', independent of ''μ'', where ''Z'' lies in between with probability 1 − α, a measure of how confident we want to be. We take 1 &minus; α = 0.95. So we have: :<math>P(-z\le Z\le z) = 1-\alpha = 0.95. \, </math> The number ''z'' follows from the [[cumulative distribution function]]: :<math> \begin{align} \Phi(z) & = P(Z \le z) = 1 - \tfrac{\alpha}2 = 0.975,\\[6pt] z & = \Phi^{-1}(\Phi(z)) = \Phi^{-1}(0.975) = 1.96, \end{align} </math> and we get: :<math> \begin{align} 0.95 & = 1-\alpha=P(-z \le Z \le z)=P \left(-1.96 \le \frac {\bar X-\mu}{\sigma/\sqrt{n}} \le 1.96 \right) \\[6pt] & = P \left( \bar X - 1.96 \frac{\sigma}{\sqrt{n}} \le \mu \le \bar X + 1.96 \frac{\sigma}{\sqrt{n}}\right) \\[6pt] & = P\left(\bar X - 1.96 \times 0.5 \le \mu \le \bar X + 1.96 \times 0.5\right) \\[6pt] & = P \left( \bar X - 0.98 \le \mu \le \bar X + 0.98 \right). \end{align} </math> This might be interpreted as: with probability 0.95 we will find a confidence interval in which we will meet the parameter ''μ'' between the stochastic endpoints :<math> \bar X - 0{.}98 \, </math> and :<math> \bar X + 0.98. \, </math> This does not mean that there is 0.95 probability of meeting the parameter μ in the calculated interval. Every time the measurements are repeated, there will be another value for the mean {{overbar|''X''}} of the sample. In 95% of the cases ''μ'' will be between the endpoints calculated from this mean, but in 5% of the cases it will not be. The actual confidence interval is calculated by entering the measured masses in the formula. Our 0.95 confidence interval becomes: :<math>(\bar x - 0.98;\bar x + 0.98) = (250.2 - 0.98; 250.2 + 0.98) = (249.22; 251.18).\,</math> [[Image:NYW-confidence-interval.svg‎|thumb|300px|The vertical [[line segment]]s represent 50 realisations of a confidence interval for μ.]] As the desired value 250 of ''μ'' is within the resulted confidence interval, there is no reason to believe the machine is wrongly calibrated. The calculated interval has fixed endpoints, where μ might be in between (or not). Thus this event has probability either 0 or 1. One '''cannot''' say: "with probability (1 − α) the parameter ''μ'' lies in the confidence interval." One only knows that by repetition in 100(1 − α) % of the cases, μ will be in the calculated interval. In 100α % of the cases however it does not. And unfortunately one does not know in which of the cases this happens. That is why one can say: "with '''confidence level''' 100(1 − α) %, ''μ'' lies in the confidence interval." The figure on the right shows 50 realisations of a confidence interval for a given population mean μ. If we randomly choose one realisation, the probability is 95% we end up having chosen an interval that contains the parameter; however we may be unlucky and have picked the wrong one. We will never know; we are stuck with our interval. ===Theoretical example=== Suppose ''X''<sub>1</sub>, ..., ''X''<sub>''n''</sub> are an [[statistical independence|independent]] sample from a [[normal distribution|normally distributed]] population with ([[statistical parameters|parameters]]) [[mean]] ''μ'' and [[variance]] σ<sup>2</sup>. Let :<math>\overline{X}=(X_1+\cdots+X_n)/n\,,</math> :<math>S^2=\frac{1}{n-1}\sum_{i=1}^n\left(X_i-\overline{X}\,\right)^2.</math> be the well known [[statistic]]s, [[sample mean]] and [[sample variance]]. Then :<math>T=\frac{\overline{X}-\mu}{S/\sqrt{n}}</math> has a [[Student's t-distribution]] with ''n'' &minus; 1 degrees of freedom. Note that the distribution of ''T'' does not depend on the values of the unobservable parameters ''μ'' and ''σ''<sup>2</sup>; i.e., it is a [[pivotal quantity]]. Suppose we wanted to calculate a 90% confidence interval for ''μ''. Then, denoting ''c'' as the 95th percentile of this distribution, :<math>\Pr\left(-c<T<c\right)=0.9.\,</math> (Note: "95th" and "0.9" are correct in the preceding expressions. There is a 5% chance that ''T'' will be less than &minus;''c'' and a 5% chance that it will be larger than +''c''. Thus, the probability that ''T'' will be between &minus;''c'' and +''c'' is 90%.) Consequently :<math>\Pr\left(\overline{X} - \frac{cS}{\sqrt{n}} < \mu < \overline{X} + \frac{cS}{\sqrt{n}} \right)=0.9\,</math> and we have a theoretical (stochastic) 90% confidence interval for ''μ''. After observing the sample we find values {{overbar|''x''}} for {{overbar|''X''}} and ''s'' for ''S'', from which we compute the confidence interval :<math> \left[ \overline{x} - \frac{cs}{\sqrt{n}}, \overline{x} + \frac{cs}{\sqrt{n}} \right], \,</math> an interval with fixed numbers as endpoints, of which we can no more say there is a certain probability it contains the parameter ''μ''. Either ''μ'' is in this interval or isn't. ==Relation to hypothesis testing== While the formulations of the notions of confidence intervals and of [[statistical hypothesis testing]] are distinct they are in some senses related and to some extent complementary. While not all confidence intervals are constructed in this way, one general purpose approach to constructing confidence intervals is to define a 100(1 &minus; ''α'')% confidence interval to consist of all those values ''θ''<sub>0</sub> for which a test of the hypothesis ''θ'' = ''θ''<sub>0</sub> is not rejected at a significance level of 100α%. Such an approach may not always be available since it presupposes the practical availability of an appropriate significance test. Naturally, any assumptions required for the significance test would carry over to the confidence intervals. It may be convenient to make the general correspondence that parameter values within a confidence interval are equivalent to those values that would not be rejected by an hypothesis test, but this would be dangerous. In many instances the 