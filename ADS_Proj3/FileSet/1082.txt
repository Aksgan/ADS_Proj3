or wilma. Although the example is formatted this way, it is important to emphasize that tabular query operations (as well as all data drilling operations) can be applied to any conceivable [[data type]], regardless of the underlying formatting. The only requirement is that the data be readable by the software application in use. === Pivot query === A pivot query allows multiple representations of data according to different dimensions. This query type is similar to tabular query, except it also allows data to be represented in summary format, according to a flexible user-selected [[hierarchy]]. This class of data drilling operation is formally (and loosely) known by different names, including '''[[crosstab|crosstab query]]''', '''[[pivot table]]''', '''data pilot''', '''selective hierarchy''', '''[[intertwingularity]]''' and others. To illustrate the basics of pivot query operations, consider the '''Fred and Wilma table (Fig 001)'''. A quick scan of the data reveals that the table has redundant information. This redundancy could be consolidated using an [[outline]] or a [[tree structure]] or in some other way. Moreover, once consolidated, the data could have many different alternate layouts. Using a simple text outline as output, the following alternate layouts are all possible with a pivot query: '''Summarize by gender (Fig 001)''': female flintstone, wilma rudolph, wilma webb, wilma male chopin, fred flintstone, fred durst, fred johnson, fred (Dimensions = gender; Tabular fields = lname, fname;) '''Summarize by home, lname (Fig 001)''': bedrock flintstone fred wilma Poland chopin fred usa ... (Dimensions = home, lname; Tabular fields = fname;) ==== Uses ==== Pivot query operations are useful for summarizing a corpus of data in multiple ways, thereby illustrating different representations of the same basic information. Although this type of operation appears prominently in [[spreadsheet]]s and desktop [[database]] software, its flexibility is arguably under-utilized. There are many applications that allow only a 'fixed' hierarchy for representing data, and this represents a substantial limitation. [[Category:Hierarchy]] [[Category:Information science]] {{Comp-sci-stub}} [[de:Drill-Down]] [[id:Pengeboran data]]</text> </page> <page> <id>9369</id> <title>Data exchange</title> <text>'''Data exchange''' is the process of taking [[data]] structured under a ''source'' [[Database schema|schema]] and actually transforming it into data structured under a ''target'' schema, so that the target data is an accurate representation of the source data. Data exchange is similar to the related concept of [[data integration]] except that data is actually restructured (with possible loss of content) in data exchange. There may be no way to transform an [[instance]] given all of our constraints. Conversely, there may be numerous ways to transform the instance (possibly infinitely many), in which case we must identify and justify a "best" choice of solutions. == References == {{reflist}} {{refbegin}} *R. Fagin, P. Kolaitis, R. Miller, and L. Popa. "Data ex- change: semantics and query answering." Theoretical Computer Science, 336(1):89–124, 2005. *P. Kolaitis. "Schema mappings, data exchange, and metadata management." Proceedings of the twenty- fourth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, pages 61–75, 2005 {{refend}} [[Category: Data management]] {{comp-stub}} [[de:Datenaustausch]] [[th:การแลกเปลี่ยนข้อมูล]]</text> </page> <page> <id>9371</id> <title>Data extraction</title> <text>'''Data extraction''' is the act or process of retrieving ([[binary data|binary]]) [[data]] out of (usually [[unstructured data|unstructured]] or poorly structured) [[data source]]s for further [[data processing]] or [[data storage device|data storage]] ([[data migration]]). The [[data import|import]] into the intermediate extracting system is thus usually followed by [[data transformation]] and possibly the addition of [[metadata]] prior to [[data export|export]] to another stage in the data [[workflow]].<ref>[http://www.extractingdata.com Definition of data extraction.]</ref> Usually, the term data extraction is applied when ([[experiment]]al) data is first imported into a computer from primary sources, like [[measuring device|measuring]] or [[recording device]]s. Today's [[electronic device]]s will usually present a [[electrical connector]] (e.g. [[USB]]) through which '[[raw data]]' can be [[data stream|streamed]] into a [[personal computer]]. Typical unstructured data sources include web pages, emails, documents, PDFs, scanned text, mainframe reports, spool files etc. Extracting data from these unstructured sources has grown into a considerable technical challenge where as historically data extraction has had to deal with changes in physical hardware formats, the majority of current data extraction deals with extracting data from these unstructured data sources, and from different software formats. This growing process of data extraction from the web is referred to as [[Web scraping]]. The act of adding structure to unstructured data takes a number of forms * Using text pattern matching also known as [[Regular expression]] to identify small or large-scale structure e.g. records in a report and their associated data from headers and footers; * Using a table-based approach to identify common sections within a limited domain e.g. in emailed resumes, identifying skills, previous work experience, qualifications etc using a standard set of commonly used headings (these would differ from language to language), eg Education might be found under Education/Qualification/Courses; * Using text analytics to attempt to understand the text and link it to other information ==Notes== <references /> ==External links== * [http://www.etltools.org/extraction.html Data Extraction] as a part of the ETL process in a Data Warehousing environment {{Data warehouse}} {{DEFAULTSORT:Data Extraction}} [[Category:Data management]] [[Category:Data warehousing]] {{computer-stub}}</text> </page> <page> <id>9376</id> <title>Data governance</title> <text>'''Data governance''' is an emerging discipline with an evolving definition. The discipline embodies a convergence of data quality, data management, data policies, business process management, and risk management surrounding the handling of data in an organization. Through data governance, organizations are looking to exercise positive control over the processes and methods used by their [[data stewards]] and [[Data custodian|data custodians]] to handle data. Data governance is a set of processes that ensures that important data assets are formally managed throughout the enterprise. Data governance ensures that data can be trusted and that people can be made accountable for any adverse event that happens because of low data quality. It is about putting people in charge of fixing and preventing issues with data so that the enterprise can become more efficient. Data governance also describes an evolutionary process for a company, altering the company’s way of thinking and setting up the processes to handle information so that it may be utilized by the entire organization. It’s about using technology when necessary in many forms to help aid 