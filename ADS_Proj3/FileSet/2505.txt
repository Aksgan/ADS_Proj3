to [[Java bytecode]]. It additionally trains any machine learning components of the program (based on a training set specified in the program). The resulting bytecode can be called as a library from any [[Java Virtual Machine|Java VM]] program. Learning components included in the LBJ libraries include [[AdaBoost]], [[Naive Bayes classifier|na√Øve Bayesian]] classifiers, [[perceptron]]s and [[Sparse network of winnows|sparse networks of winnows]]. Via interfaces to external libraries, [[support vector machine]]s and the learners in the [[Weka (machine learning)|Weka]] toolkit are supported. LBJ further includes the ability to add [[Constraint programming|constraint inference]] to the output of machine learners, following the [[Constrained Conditional Models]] paradigm. These constraints are expressed in a [[first-order logic]] language and can be used to, e.g., rule out certain results known to be impossible when using combinations of classifiers. Classification results and constraints are translated to [[Linear programming|linear]]/[[Linear programming#Integer unknowns|mixed integer programming]] problems, which are then solved using the [[GNU Linear Programming Kit|GLPK]] or [[Xpress MP]] toolkits.<ref> {{Cite conference | first = Nick | last = Rizzolo | first2 = Dan | last2 = Roth | title = Modeling discriminative global inference | booktitle = Proc. First International Conference on Semantic Computing (ICSC) | year = 2007 | url = http://l2r.cs.uiuc.edu/~danr/Papers/RizzoloRo07.pdf }} </ref> ==External link== * [http://cogcomp.cs.illinois.edu/page/software_view/11 Learning Based Java] at the University of Illinois at Urbana Champaign * [http://cogcomp.cs.illinois.edu/page/software_view/3 Illinois Part of Speech Tagger]: a [[Part-of-speech tagging|POS tagger]] for English, written in LBJ ==References== <references/> [[Category:Java programming language]] [[Category:Machine learning]] [[Category:Natural language processing toolkits]]</text> </page> <page> <id>21391</id> <title>Least frequently used</title> <text>In computer science, the term '''"Least Frequently Used"''' (LFU) refers to a [[cache algorithm]] for memory management. The expiration policy removes entities from the cache that are used the least. If the use frequency of each entity is the same, then they are expired by the [[Least Recently Used]] (LRU) algorithm. ==Variations == There are variations of the LFU algorithm. ; LFU* : A revised version of the LFU policy proposed by M. Arlitt. This policy only considers documents whose reference counts are one when it needs to be removed. If the total size of documents whose reference counts are one is not enough to give room for the in-coming document, then the document is not cached and no document is removed. ; LFU-Aging : This LFU policy addresses the problem of [[cache pollution]]. The aging policy is applied at interval to bring down the reference counts of such pages and ultimately make them candidates for replacement. ; LFU*-Aging : This is the LFU* algorithm with LFU-Aging applied. ; Window-LFU : An LFU algorithm that uses windows of time to estimate the frequency of usage over the cached population.<ref>ftp://ftp.cs.princeton.edu/techreports/2000/622.pdf</ref> ==See also== *[[cache algorithm]] ==References== {{reflist}} [[Category:Memory management algorithms]] {{comp-sci-stub}} [[de:Least frequently used]]</text> </page> <page> <id>21395</id> <title>Least slack time scheduling</title> <text>{{Unreferenced|date=December 2009}} '''Least Slack Time''' (LST) scheduling is a [[scheduling algorithm]]. It assigns priority based on the ''slack time'' of a process. Slack time is the amount of time left after a job if the job was started now. This algorithm is also known as '''Least Laxity First'''. Its most common use is in embedded systems, especially those with multiple processors. It imposes the simple constraint that each process on each available processor possesses the same run time, and that individual processes do not have an affinity to a certain processor. This is what lends it a suitability to embedded systems. ==Slack time== This scheduling algorithm first selects those processes that have the smallest "slack time". Slack time is defined as the temporal difference between the deadline, the ready time and the run time. More formally, the ''slack time'' for a process is defined as: <math>(d - t) - c'</math> where <math>d</math> is the process deadline, <math>t</math> is the real time since the cycle start, and <math>c'</math> is the remaining computation time. ==Suitability== LST scheduling is most useful in systems comprising mainly aperiodic tasks, because no prior assumptions are made on the events' rate of occurrence. The main weakness of LST is that it does not look ahead, and works only on the current system state. Thus, during a brief overload of system resources, LST can be sub-optimal. It will also be suboptimal when used with uninterruptible processes. However, like [[Earliest deadline first scheduling|earliest deadline first]], and unlike [[Rate-monotonic scheduling|rate monotonic scheduling]], this algorithm can be used for processor utilization up to 100%. {{DEFAULTSORT:Least Slack Time Scheduling}} [[Category:Scheduling algorithms]] [[de:Least Laxity First]] [[ja:Least Slack Time]]</text> </page> <page> <id>21399</id> <title>Least trimmed squares</title> <text>'''Least trimmed squares''' ('''LTS'''), or '''least trimmed sum of squares''', is a robust [[Statistics|statistical method]] that attempts to fit a function to a set of data whilst not being unduly affected by the presence of outliers. It is one of a number of possible applications of the ideas of [[robust statistics]] to the application of [[regression analysis]]. == Description of method == Instead of the standard [[least squares]] method, which minimises the sum of squared [[errors and residuals in statistics|residuals]] over ''n'' points, the LTS method attempts to minimise the sum of squared residuals over a subset, ''k'', of those points. The ''n-k'' points which are not used do not influence the fit. In a standard least squares problem, the estimated parameter values, &beta;, are defined to be those values that minimise the object function, ''S''(&beta;), of squared residuals :<math>S=\sum_{i=1}^{n}{r_i(\beta)}^2</math>, where the [[errors and residuals in statistics|residuals]] are defined as the differences between the values of the [[Dependent and independent variables|dependent variables]] (observations) and the model values :<math>r_i(\beta)= y_i - f(x_i, \beta),</math> and where ''n'' is the overall number of data points. For a least trimmed squares analysis, this objective function is replaced by one constructed in the following way. For a fixed value of &beta;, let {|''r''<sub>(''j'')</sub>(&beta;)|} denote the set of ordered absolute values of the residuals (in increasing order of absolute value). In this notation, the standard sum of squares function is :<math>S(\beta)=\sum_{j=1}^n |r_{(j)}(\beta)|^2,</math> while the objective function for LTS is :<math>S_k(\beta)=\sum_{j=1}^k |r_{(j)}(\beta)|^2.</math> == Computational considerations == Because this method is binary, in that points are 