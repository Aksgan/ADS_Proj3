fairly sharp line between the physical and intellectual capacities of a man."<ref name=T434>{{Harvnb|Turing|1950|p=434}}</ref> To demonstrate this approach Turing proposes a test inspired by a [[party game]], known as the "Imitation Game", in which a man and a woman go into separate rooms and guests try to tell them apart by writing a series of questions and reading the typewritten answers sent back. In this game both the man and the woman aim to convince the guests that they are the other. Turing proposes recreating the game as follows: <blockquote>We now ask the question, "What will happen when a machine takes the part of A in this game?" Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, "Can machines think?"<ref name=T434/></blockquote> Later in the paper Turing suggests an "equivalent" alternative formulation involving a judge conversing only with a computer and a man.<ref>{{Harvnb|Turing|1950|p=446}}</ref> While neither of these formulations precisely matches the version of the Turing Test that is more generally known today, he proposed a third in 1952. In this version, which Turing discussed in a [[BBC]] radio broadcast, a jury asks questions of a computer and the role of the computer is to make a significant proportion of the jury believe that it is really a man.<ref>{{Harvnb|Turing|1952|pp=524–525}}. Turing does not seem to distinguish between "man" as a gender and "man" as a human. In the former case, this formulation would be closer to the Imitation Game, whereas in the latter it would be closer to current depictions of the test.</ref> Turing's paper considered nine putative objections, which include all the major arguments against artificial intelligence that have been raised in the years since the paper was published. (See ''[[Computing Machinery and Intelligence]]''.)<ref name=RN948>{{Harvnb|Turing|1950|pp=442–454}} and see {{Harvtxt|Russell|Norvig|2003|p=948}}, where they comment, "Turing examined a wide variety of possible objections to the possibility of intelligent machines, including virtually all of those that have been raised in the half century since his paper appeared."</ref> ===ELIZA and PARRY=== [[Blay Whitby]] lists four major turning points in the history of the Turing Test — the publication of "Computing Machinery and Intelligence" in 1950, the announcement of [[Joseph Weizenbaum]]'s [[ELIZA]] in 1966, [[Kenneth Colby]]'s creation of [[PARRY]], which was first described in 1972, and the Turing Colloquium in 1990.<ref>{{Harvnb|Whitby|1996|p=53}}</ref> Sixty years following its introduction, and continued argument over Turing's 'can machines think?' experiment, led to its reconsideration for the 21st century through the [http://www.cse.dmu.ac.uk/~aayesh/TuringTestRevisited/Welcome.html AISB's 'Towards a comprehensive intelligence test' symposium], 29 March - 1 April 2010, at De Montford University, UK. ELIZA works by examining a user's typed comments for keywords. If a keyword is found, a rule that transforms the user's comments is applied, and the resulting sentence is returned. If a keyword is not found, ELIZA responds either with a generic riposte or by repeating one of the earlier comments.<ref>{{Harvnb|Weizenbaum|1966|p=37}}</ref> In addition, Weizenbaum developed ELIZA to replicate the behaviour of a [[person-centered psychotherapy|Rogerian psychotherapist]], allowing ELIZA to be "free to assume the pose of knowing almost nothing of the real world."<ref name=Weizenbaum42>{{Harvnb|Weizenbaum|1966|p=42}}</ref> With these techniques, Weizenbaum's program was able to fool some people into believing that they were talking to a real person, with some subjects being "very hard to convince that ELIZA [...] is ''not'' human."<ref name=Weizenbaum42 /> Thus, ELIZA is claimed by some to be one of the programs (perhaps the first) able to pass the Turing Test,<ref name=Weizenbaum42 /><ref>{{Harvnb|Thomas|1995|p=112}}</ref> although this view is highly contentious (see [[#Naivete of interrogators and the anthropomorphic fallacy|below]]). Colby's PARRY has been described as "ELIZA with attitude":<ref>{{Harvnb|Bowden|2006|p=370}}</ref> it attempts to model the behaviour of a [[paranoia|paranoid]] [[schizophrenic]], using a similar (if more advanced) approach to that employed by Weizenbaum. In order to validate the work, PARRY was tested in the early 1970s using a variation of the Turing Test. A group of experienced psychiatrists analysed a combination of real patients and computers running PARRY through [[teletype]] machines. Another group of 33 psychiatrists were shown transcripts of the conversations. The two groups were then asked to identify which of the "patients" were human and which were computer programs.<ref>{{Harvnb|Colby|Hilf|Weber|Kraemer|1972|p=42}}</ref> The psychiatrists were able to make the correct identification only 48 per cent of the time — a figure consistent with random guessing.<ref>{{Harvnb|Saygin|Cicekli|Akman|2000|p=501}}</ref> In the 21st century, ELIZA and PARRY have been developed into [[malware]] systems, such as [http://www.itwire.com/your-it-news/home-it/15748-flirty-bot-passes-for-human CyberLover], which preys on Internet users convincing them to "reveal information about their identities or to lead them to visit a web site that will deliver malicious content to their computers" ([http://www.itwire.com/your-it-news/home-it/15748-flirty-bot-passes-for-human (iTWire, 2007)]. A one-trick pony, ''CyberLover'', a software program developed in Russia, has emerged as a "Valentine-risk" flirting with people "seeking relationships online in order to collect their personal data" [http://www.v3.co.uk/vnunet/news/2205441/online-love-seekers-warned-flirt-bots# (V3, 2010)]. ===The Chinese room=== [[John Searle]]'s 1980 paper ''[[Minds, Brains, and Programs]]'' proposed an argument against the Turing Test known as the "[[Chinese room]]" thought experiment. Searle argued that software (such as ELIZA) could pass the Turing Test simply by manipulating symbols of which they had no understanding. Without understanding, they could not be described as "thinking" in the same sense people do. Therefore—Searle concludes—the Turing Test cannot prove that a machine can think.<ref name="Searle 1980">{{Harvnb|Searle|1980}}</ref> Arguments such as that proposed by Searle and others working on the [[philosophy of mind]] sparked off a more intense debate about the nature of intelligence, the possibility of intelligent machines and the value of the Turing test that continued through the 1980s and 1990s.<ref>{{Harvnb|Saygin|Cicekli|Akman|2000|p=479}}</ref> ===Turing Colloquium=== 1990 was the fortieth anniversary of the first publication of Turing's "Computing Machinery and Intelligence" paper, and, thus, saw renewed interest in the test. Two significant events occurred in that year: The first was the Turing Colloquium, which was held at the [[University of Sussex]] in April, and brought together academics and researchers from a wide variety of disciplines to discuss the Turing Test in terms of its past, present, and future; the second was the formation of the annual 