simplify the notation. We are looking for the eigenvalues of the matrix <math>D + w w^{T}</math>, where <math>D</math> is diagonal with distinct entries and <math>w</math> is any vector with nonzero entries. If w<sub>i</sub> is zero, (<math>e_i</math>,d<sub>i</sub>) is an eigenpair of <math>D + w w^{T}</math> since <math>(D + w w^{T})e_i = De_i = d_i e_i</math>. If <math>\lambda</math> is an eigenvalue, we have: :<math>(D + w w^{T})q = \lambda q</math> where <math>q</math> is the corresponding eigenvector. Now :<math>(D - \lambda I)q + w(w^{T}q) = 0</math> :<math>q + (D - \lambda I)^{-1} w(w^{T}q) = 0</math> :<math>w^{T}q + w^{T}(D - \lambda I)^{-1} w(w^{T}q) = 0</math> Keep in mind that <math>w^{T}q</math> is a nonzero scalar. Neither <math>w</math> nor <math>q</math> are zero. If <math>w^{T}q</math> were to be zero, <math>q</math> would be an eigenvector of <math>D</math> by <math>(D + w w^{T})q = \lambda q</math>. If that were the case, <math>q</math> would contain only one nonzero position since <math>D</math> is distinct diagonal and thus the inner product <math>w^{T}q</math> can not be zero after all. Therefore, we have: :<math>1 + w^{T}(D - \lambda I)^{-1} w = 0</math> or written as a scalar equation, :<math>1 + \sum_{j=1}^{m} \frac{w_{j}^{2}}{d_{j} - \lambda} = 0.</math> This equation is known as the ''secular equation''. The problem has therefore been reduced to finding the roots of the [[rational function]] defined by the left-hand side of this equation. All general eigenvalue algorithms must be iterative, and the divide-and-conquer algorithm is no different. Solving the [[nonlinear]] secular equation requires an iterative technique, such as the [[Newton's method|Newton–Raphson method]]. However, each root can be found in [[Big O notation|O]](1) iterations, each of which requires <math>\Theta(m)</math> flops (for an <math>m</math>-degree rational function), making the cost of the iterative part of this algorithm <math>\Theta(m^{2})</math>. ==Analysis== As is common for divide and conquer algorithms, we will use the [[Master theorem]] to analyze the running time. Remember that above we stated we choose <math>n \approx m/2</math>. We can write the [[recurrence relation]]: :<math>T(m) = 2 \times T\left(\frac{m}{2}\right) + \Theta(m^{2})</math> In the notation of the Master theorem, <math>a = b = 2</math> and thus <math>\log_{b} a = 1</math>. Clearly, <math>\Theta(m^{2}) = \Omega(m^{1})</math>, so we have :<math>T(m) = \Theta(m^{2})</math> Remember that above we pointed out that reducing a Hermitian matrix to tridiagonal form takes <math>\frac{4}{3}m^{3}</math> flops. This dwarfs the running time of the divide-and-conquer part, and at this point it is not clear what advantage the divide-and-conquer algorithm offers over the QR algorithm (which also takes <math>\Theta(m^{2})</math> flops for tridiagonal matrices). The advantage of divide-and-conquer comes when eigenvectors are needed as well. If this is the case, reduction to tridiagonal form takes <math>\frac{8}{3}m^{3}</math>, but the second part of the algorithm takes <math>\Theta(m^{3})</math> as well. For the QR algorithm with a reasonable target precision, this is <math>\approx 6 m^{3}</math>, whereas for divide-and-conquer it is <math>\approx \frac{4}{3}m^{3}</math>. The reason for this improvement is that in divide-and-conquer, the <math>\Theta(m^{3})</math> part of the algorithm (multiplying <math>Q</math> matrices) is separate from the iteration, whereas in QR, this must occur in every iterative step. Adding the <math>\frac{8}{3}m^{3}</math> flops for the reduction, the total improvement is from <math>\approx 9 m^{3}</math> to <math>\approx 4 m^{3}</math> flops. Practical use of the divide-and-conquer algorithm has shown that in most realistic eigenvalue problems, the algorithm actually does better than this. The reason is that very often the matrices <math>Q</math> and the vectors <math>z</math> tend to be ''numerically sparse'', meaning that they have many entries with values smaller than the [[floating point]] precision, allowing for ''numerical deflation'', i.e. breaking the problem into uncoupled subproblems. ==Variants and implementation== The algorithm presented here is the simplest version. In many practical implementations, more complicated rank-1 corrections are used to guarantee stability; some variants even use rank-2 corrections. <sup>[citation needed]</sup> There exist specialized root-finding techniques for rational functions that may do better than the Newton-Raphson method in terms of both performance and stability. These can be used to improve the iterative part of the divide-and-conquer algorithm. The divide-and-conquer algorithm is readily [[Parallel algorithm|parallelized]], and [[linear algebra]] computing packages such as [[LAPACK]] contain high-quality parallel implementations. ==References== * {{Citation | last = Demmel | first = James W. | date = August 1, 1997 | title = Applied Numerical Linear Algebra | publisher = SIAM | isbn = 978-0898713893 }} {{Numerical linear algebra}} [[Category:Numerical linear algebra]]</text> </page> <page> <id>10844</id> <title>Division by zero</title> <text>{{about|the mathematical concept}} <!-- Markup note: See the discussion about how to properly format fractions --> [[File:Hyperbola one over x.svg|thumb|Diagrammatic representation of limits approaching infinity|The function ''y'' = 1/''x''. As ''x'' approaches 0 from the right, ''y'' approaches infinity. As ''x'' approaches 0 from the left, ''y'' approaches minus infinity (see [[asymptote]]).]] In [[mathematics]], '''division by zero''' is a term used if the divisor (denominator) is [[0 (number)|zero]]. Such a division can be formally expressed as ''a'' / 0 where ''a'' is the dividend (numerator). Whether this [[expression (mathematics)|expression]] can be assigned a [[well-defined]] value depends upon the mathematical setting. In ordinary ([[real number]]) arithmetic, the expression has [[Defined and undefined|no meaning]], as there is no number which, multiplied by 0, gives ''a'' (''a''≠0). In [[computer programming]], an attempt to divide by zero may, depending on the programming language and the type of number being divided by zero, generate an exception, generate an error message, crash the program being executed, generate either positive or negative infinity, or could result in a special [[NaN|not-a-number]] value (see [[Division by zero#In computer arithmetic|below]]). Historically, one of the earliest recorded references to the mathematical impossibility of assigning a value to ''a'' / 0 is contained in [[George Berkeley]]'s criticism of [[infinitesimal calculus]] in ''[[The Analyst]]''; see [[Ghosts of departed quantities]]. ==In elementary arithmetic== When division is explained at the [[elementary arithmetic]] level, it is often considered as a description of dividing a [[Set (mathematics)|set]] of objects into equal parts. As an example, consider having ten apples, and these apples are to be distributed equally to five people at a table. Each person would receive <math>\textstyle\frac{10}{5}</math> = 2 apples. Similarly, if there are 10 apples, and only one person at the table, that person 