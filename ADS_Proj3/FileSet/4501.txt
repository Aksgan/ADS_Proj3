the control program would be equally loaded into core and each program or record on DASD could be potentially accessed by either mainframe. In order to serialize accesses between data records on a loosely coupled system, a practice known as [[Record locking]] must be used. This means that when one mainframe processor obtains a '''hold''' on a record, the mechanism must prevent all other processors from obtaining the same hold and communicate to the requesting processors that they are waiting. Within any tightly coupled system this is easy to manage between I-streams via the use of the '''Record Hold Table'''. However when the lock is obtained offboard of the TPF processor in the DASD control unit, an external process must be used. Historically the record locking was accomplished in the DASD control unit via an '''RPQ''' known as '''LLF''' (Limited Locking Facility) and later '''ELLF''' (extended). LLF and ELLF were both replaced by the Multipathing Lock Facility (MPLF). To run clustered (loosely-coupled) zTPF requires either MPLF in all disk control units or an alternative locking device called a Coupling Facility. [http://publib.boulder.ibm.com/infocenter/zvm/v5r4/index.jsp?topic=/com.ibm.zvm.v54.hcpf2/hcsf9b3153.htm] [http://www-01.ibm.com/support/docview.wss?uid=swg27007957] =====Processor shared records===== Records that absolutely must be managed by a [[record locking]] process are those which are processor shared. In TPF most record accesses are done by using '''record type''' and '''ordinal'''. So if you had defined a record type in the TPF system of 'FRED' and gave it 100 records or ordinals, then in a processor shared scheme record type 'FRED' ordinal '5' would resolve to exactly the same file address on DASD - clearly necessitating the use of a record locking mechanism. All processor shared records on a TPF system will be accessed via exactly the same file address which will resolve to exactly the same location. =====Processor unique records===== A processor unique record is one that is defined such that each processor expected to be in the loosely coupled complex has a record type of 'FRED' and perhaps 100 ordinals. However, if a user on any 2 or more processors examines the file address that record type 'FRED', ordinal '5' resolves to, they will note a different physical address is used. ==TPF attributes== ===What TPF is not=== TPF has no graphical user interface ([[GUI]]). TPF's built-in user interface is line driven with simple text screens that scroll upwards. There are no mice, windows, or icons on a TPF '''Prime CRAS'''. All work is accomplished via the use of typed one or two line commands, similar to early versions of [[UNIX]] before [[X Window System|X]]. TPF also does not include a compiler/assembler, text editor, or the concept of a desktop. TPF application source code is typically kept in [[Partitioned dataset|PDSs]] on a z/OS system. However, some previous installations of TPF kept source code in [[z/VM]]-based<!-- needs cite. Have any shops used boris/carloff, sourcebank, tsmlib-style SCM tools on z/VM or are they all off vm? --> files and used the CMS update facility to handle versioning. Currently the z/OS compiler/assembler is used to build TPF code into object modules, producing load files that the TPF "online system" can accept. Starting with z/TPF 1.1, [[Linux]] will be the build platform. Using TPF requires an intimate knowledge of the Operations Guide since there is no shipped support for any type of online command "directory" that you might find on other platforms. Commands created by IBM and shipped by IBM for the running and administration of TPF are referred to as "Z-messages" as they are all prefixed with the letter "Z." Other letters are reserved so that customers may write their own commands. TPF has extremely limited capability to debug itself. Typically third party software packages such as [[IBM]]'s '''TPF Tool Kit''' or '''Step by Step Trace''' from [http://www.bedford.com/ Bedford Associates] or '''CMSTPF,TPF/GI,zTPF/GI''' from [http://www.tpfsoftware.com/ TPF Software Inc.] are employed to aid in the tracing and tracking of errant TPF code. Since TPF can run as a second level guest under IBM's z/VM, a user can employ the VM trace facility to closely follow the execution of code. TPF will allow certain types of function traces to operate and dump their data to a tape, typically through '''user exits''' that present parameters to a called function or perhaps the contents of a block of storage. There are some other types of trace information that TPF can collect in core while running, and this information gets "dumped" whenever the system encounters a severe error. ===What TPF is=== TPF is highly optimized to permit messages from the supported network to either be switched out to another location, routed to an application (specific set of programs) or to permit extremely efficient accesses to database records. =====Data records===== Historically all data on the TPF system had to fit in fixed record (and core block) sizes of 381, 1055 and 4K bytes. This was due in part to the physical record sizes of blocks located on DASD. Much overhead was saved by freeing up any part of the operating system from breaking large data entities into smaller ones during file operations, and reassembling same during read operations. Since IBM hardware does I/O via the use of '''channels''' and '''channel programs''', TPF would generate very small and efficient channel programs to do its I/O - all in the name of speed. Since the early days also placed a premium on the size of storage media - be it memory or disk, TPF applications evolved into doing very powerful things while using very little resource. Today, much of these limitations are removed. In fact, only because of legacy support are smaller than 4K DASD records still used. With the advances made in DASD technology, a read/write of a 4K record is just as efficient as a 1055 byte record. The same advances have increased the capacity of each device so that there is no longer a premium placed on the ability to pack data into the smallest model as possible. =====Programs and residency===== TPF also had its programs allocated as 381, 1055 and 4K bytes in 