Finding Stationary Subspaces in Multivariate Time Series] ''Phys. Rev. Letter'' 103, 214101. </ref> is a [[blind source separation]] [[algorithm]] which factorizes a [[multivariate]] [[time series]] into [[stationary]] and [[non-stationary]] components. == Introduction == In many settings, the measured time series contains contributions from various underlying sources that cannot be measured directly. For instance, in [[EEG]] analysis, the electrodes on the scalp record the activity of a large number of sources located inside the brain<ref>Niedermeyer E, da Silva F L. Electroencephalography: Basic Principles, Clinical Applications, and Related Fields. Lippincott Williams & Wilkins, 2004. ISBN 0781751268</ref>. These sources can be stationary or non-stationary, but they are not discernible in the electrode signals, which are a mixture of these sources. SSA allows the separation of the stationary from the non-stationary sources in an observed time series. According to the SSA model<ref name="ssaprl"/>, the observed multivariate time series <math>x(t)</math> is assumed to be generated as a linear superposition of stationary sources <math>s^\mathfrak{s}(t)</math> and non-stationary sources <math>s^\mathfrak{n}(t)</math>, :<math> x(t) = A s(t) = \begin{bmatrix} A^\mathfrak{s} & A^\mathfrak{n} \end{bmatrix} \begin{bmatrix} s^\mathfrak{s}(t) \\ s^\mathfrak{n}(t) \\ \end{bmatrix}, </math> where <math>A</math> is an unknown but time-constant mixing matrix; <math>A^\mathfrak{s}</math> and <math>A^\mathfrak{s}</math> are the basis of the stationary and non-stationary subspace respectively. Given samples from the time series <math>x(t)</math>, the aim of Stationary Subspace Analysis is to estimate the inverse mixing matrix <math>A^{-1}</math> separating the stationary from non-stationary sources in the mixture <math>x(t)</math>. == Identifiability of the solution == The true stationary sources <math>s^\mathfrak{s}(t)</math> are identifiable (up to a linear transformation) and the true non-stationary subspace <math>A^\mathfrak{n}</math> is identifiable. The true non-stationary sources <math>s^\mathfrak{n}(t)</math> and the true stationary subspace <math>A^\mathfrak{s}</math> cannot be identified, because arbitrary contributions from the stationary sources do not change the non-stationary nature of a non-stationary source<ref name="ssaprl"/> == Applications and Extensions == Stationary Subspace Analysis has been successfuly applied to [[Brain-Computer Interface|Brain Computer Interfacing]]<ref>von Bünau P, Meinecke F C, Scholler S, Müller K-R. Finding Stationary Brain Sources in EEG Data, IEEE EMBC 2010, Buenos Aires</ref>, [[Computer Vision]]<ref>Meinecke F, von Bünau P, Kawanabe M, Müller K-R. [http://dx.doi.org/10.1109/ICCVW.2009.5457715 Learning Invariances with Stationary Subspace Analysis], Proc. Subspace Workshop of the ICCV 2009, Kyoto</ref> and Temporal Segmentation. There are variants of the SSA problem that can be solved analytically in closed form, without numerical optimization<ref>Hara S, Kawahara Y, Washio T, von Bünau P. [http://dx.doi.org/10.1007/978-3-642-17537-4_52 Stationary Subspace Analysis as a Generalized Eigenvalue Problem] Lecture Notes in Computer Science, 2010, Volume 6443/2010, 422-429</ref>. == See also == * [[Blind signal separation|Blind signal separation (BSS)]] * [[Factor analysis]] * [[Independent component analysis]] * [[Cointegration]] == References == {{Reflist}} <!--- Categories ---> {{DEFAULTSORT:Stationary Subspace Analysis}} [[Category:Signal processing]] [[Category:Data analysis]] [[Category:Time series analysis]] [[Category:Statistical models]] [[Category:Multivariate statistics]] [[Category:Articles created via the Article Wizard]]</text> </page> <page> <id>35647</id> <title>Stationary target indication</title> <text>'''Stationary target indication''' ('''STI''') is a mode of operation of a [[radar]] to discriminate a target against [[clutter (radar)|clutter]]. <ref name=eh/> In contrast to another mode, [[moving target indication]] (MTI), it cannot take an advantage of the fact that the target moves with respect to clutter. Therefore the radar must exploit some intrinsic characteristics of the target which are different from those of clutter. The simplest method is available when the apparent size of the target is relatively small with respect to clutter source. In this case the reduced pulse and beam width which matches the expected target size may produce good [[signal to noise ratio]] ([[target to clutter ratio]]). Additional discrimination capabilities rely on target imaging or scattering properties of the target. <ref name=eh>Jerry C. Whitaker (2005) ''The Electronics Handbook'', ISBN 0849318890, [http://books.google.com/books?id=FdSQSAC3_EwC&pg=PA1824&dq=%22Moving-target+indication%22&sig=ZdJ7WQUan2g5FKdlL_rfr393JK8 p. 1824]</ref> ==References== {{reflist}} [[Category:Radar signal processing]] [[Category:Targeting (warfare)]]</text> </page> <page> <id>35651</id> <title>Statistical assumption</title> <text>'''Statistical assumptions''' are general assumptions about statistical populations. [[Statistics]], like all mathematical disciplines, does not generate valid conclusions from nothing. In order to generate interesting conclusions about real [[statistical population]]s, it is usually required to make some background assumptions. These must be made with care, because inappropriate assumptions can generate wildly inaccurate conclusions. The most commonly applied statistical assumptions are:{{Citation needed|date=March 2010}} #independence of observations from each other: This assumption is a common error.<ref> *{{cite journal|title=Miracles and Statistics: The Casual Assumption of Independence (ASA Presidential address) |authorlink=William Kruskal |first=William |last=Kruskal |journal=Journal of the American Statistical Association |volume=83 |issue=404 |month=December |year=1988 |pages=929–940 |url=http://www.jstor.org/stable/2290117 }} {{jstor|2290117}} </ref> (see [[statistical independence]]) #independence of observational error from potential confounding effects #exact or approximate normality of observations: The assumption of normality is often erroneous, because many populations are not normal. However, it is standard practice to assume that the sample mean from a random sample is normal, because of the [[central-limit theorem]]<!-- and simulation studies. See Hoffman-Jorgensen's ''Probability Theory with a view towards statistics''. -->. (see [[normal distribution]]) #linearity of graded responses to quantitative stimuli (see [[linear regression]]) ==Types of assumptions== Statistical assumptions can be categorised into a number of different types: *Non-modelling assumptions. Statistical analyses of data involve making certain types of assumption, whether or not a formal statistical model is used. Such assumptions underlie even [[descriptive statistics]]. **Population assumptions. A statistical analysis of data is made on the basis that the observations available derive from either a single population or several different populations, each of which is in some way meaningful. Here a "population" is informally a set of other possible observations that might have been made. The assumption here is a simple one, to the effect that the observer should know that the observations obtained are representative of the problem, topic or class of objects being studied. **Sampling assumptions. These relate to the way in which observations have been gathered and may often involve an assumption of [[random selection]] of some type.<ref>McPherson, 1990 (Section 3.3)</ref> *Modelling assumptions. These may be divided into two types: **Distributional assumptions. Where a [[statistical model]] involves terms relating to [[random errors]] assumptions may be made about the [[probability distribution]] of these errors.<ref>McPherson, 1990 (Section 3.4.1)</ref> In some cases, the distributional assumption relates to the observations themselves. **Structural assumptions. Statistical relationships between variables are often modelled by equating one variable to a function of another (or 