<math>f_A(w_1x_1 + w_2x_2 + \ldots + w_nx_n)</math>. Some neurons are selected to be the output neurons, and the network function is the vectorial function that associates to the ''n'' input values, the outputs of the ''m'' selected output neurons. Note that different choices of weights produce different network functions for the same inputs. Back-propagation is a [[supervised learning|supervised learning method]] by which the weights of the connections in the network are repeatedly adjusted so as to minimize the difference between the vector of actual outputs and that of desired outputs. [[machine learning|Learning algorithm]]s based on [[backpropagation|backwards propagation of errors]] can be used to find optimal weights for given [[network topology|topology of the network]] and input-output pairs. === Evolutionary computation === : ''Further information: [[Evolutionary computation]]'' Evolutionary computation<ref name=BFM97>B&auml;ck, T., Fogel, D., Michalewicz, Z., editors. Handbook of Evolutionary Computation. IOP Publishing, U.K., 1997</ref> is a computational paradigm inspired by [[Darwinian evolution]]. An artificial evolutionary system is a computational system based on the notion of simulated evolution. It comprises a constant- or variable-size population of individuals, a [[fitness (biology)|fitness criterion]], and genetically inspired operators that produce the next '''[[generation]]''' from the current one. The initial population is typically generated randomly or heuristically, and typical operators are [[mutation]] and [[genetic recombination|recombination]]. At each step, the individuals are evaluated according to the given fitness function ([[survival of the fittest]]). The next generation is obtained from selected individuals (parents) by using genetically inspired operators. The choice of parents can be guided by a selection operator which reflects the biological principle of [[mate selection]]. This process of simulated [[evolution]] eventually converges towards a nearly optimal population of individuals, from the point of view of the fitness function. The study of evolutionary systems has historically evolved along three main branches: [[Evolution strategies]] provide a solution to [[optimization (mathematics)|parameter optimization problems]] for real-valued as well as discrete and mixed types of parameters. [[Evolutionary programming]] originally aimed at creating optimal "intelligent agents" modelled, e.g., as finite state machines. [[Genetic algorithms]]<ref name="Koza92">Koza, J. [http://www.ru.lv/~peter/zinatne/ebooks/MIT%20-%20Genetic%20Programming.pdf Genetic Programming: On the Programming of Computers by Means of Natural Selection]. MIT Press, 1992</ref> applied the idea of evolutionary computation to the problem of finding a (nearly-)optimal solution to a given problem. Genetic algorithms initially consisted of an input population of individuals encoded as fixed-length bit strings, the genetic operators mutation (bit flips) and recombination (combination of a prefix of a parent with the suffix of the other), and a problem-dependent fitness function. Genetic algorithms have been used to optimize computer programs, called [[genetic programming]], and today they are also applied to real-valued parameter optimization problems as well as to many types of [[combinatorial tasks]]. === Swarm intelligence === [[Swarm intelligence]]<ref name="">Engelbrecht, A. Fundamentals of Computational Swarm Intelligence. Wiley and Sons, 2005.</ref>, sometimes referred to as [[collective intelligence]], is defined as the problem solving behavior that emerges from the interaction of [[intelligence agent|individual agents]] (e.g., [[bacteria]], [[ants]], [[termites]], [[bees]], [[spiders]], [[fish]], [[birds]]) which communicate with other agents by acting on their [[neighborhood (mathematics)|local environments]]. [[Particle swarm optimization]] applies this idea to the problem of finding an optimal solution to a given problem by a search through a (multi-dimensional) [[solution space]]. The initial set-up is a swarm of ''particles'', each representing a possible solution to the problem. Each particle has its own [[velocity]] which depends on its previous velocity (the inertia component), the tendency towards the past personal best position (the nostalgia component), and its tendency towards a global neighborhood optimum or local neighborhood optimum (the social component). Particles thus move through a multidimensional space and eventually converge towards a point between the [[maxima and minima|global best]] and their personal best. Particle swarm optimization algorithms have been applied to various optimization problems, and to [[unsupervised learning]], [[game learning]], and [[scheduling (computing)|scheduling]] applications. In the same vein, [[ant colony optimization|ant algorithms]] model the foraging behaviour of ant colonies. To find the best path between the nest and a source of food, ants rely on indirect communication by laying a [[pheromone]] trail on the way back to the nest if they found food, respectively following the concentration of pheromones if they are looking for food. Ant algorithms have been successfully applied to a variety of combinatorial optimization problems over discrete search spaces. === Artificial immune systems === Artificial immune systems (a.k.a. immunological computation or [[immunocomputing]]) are computational systems inspired by the natural immune systems of biological organisms. Viewed as an information processing system, the [[immune system|natural immune system]] of organisms performs many complex tasks in [[parallel computation|parallel]] and [[distributed computing]] fashion.<ref name="Dasgupta98>Dasgupta, D. editor. Artificial Immune Systems and Their Applications. Springer, 1998</ref> These include distinguishing between self and [[exogenous antigen|nonself]],<ref name=DeCastro>de Castro, L., Timmis, J. [http://www.springer.com/computer/artificial/book/978-1-85233-594-6 Artificial Immune Systems: A New Computational Intelligence Approach]. Springer, 2002.</ref> [[neutralization]] of nonself [[pathogens]] ([[viruses]], bacteria, [[fungi]], and [[parasitism|parasites]]), [[learning]], [[memory]], [[associative retrieval]], [[homeostasis|self-regulation]], and [[fault-tolerance]]. [[Artificial immune systems]] are abstractions of the natural immune system, emphasizing these computational aspects. Their applications include [[antivirus software|computer virus detection]], [[anomaly detection]] in a time series of data, [[fault diagnosis]], [[pattern recognition]], machine learning, [[bioinformatics]], optimization, [[robotics]] and [[control]]. === Membrane computing === [[Membrane computing]] investigates computing models abstracted from the [[cell compartment|compartmentalized structure]] of living cells effected by [[cell membrane|membranes]].<ref name="Paun02">Paun, G. Membrane Computing: An Introduction. Springer, 2002</ref> A generic membrane system (P-system) consists of cell-like compartments (regions) delimited by ''membranes'', that are placed in a [[nested hierarchy|nested hierarchical]] structure. Each membrane-enveloped region contains objects, transformation rules which modify these objects, as well as transfer rules, which specify whether the objects will be transferred outside or stay inside the region. Regions communicate with each other via the transfer of objects. The computation by a membrane system starts with an initial configuration, where the number ([[multiplicity]]) of each object is set to some value for each region ([[multiset|multiset of objects]]). It proceeds by choosing, [[nondeterminism|nondeterministically]] and in a [[parallelism (computing)|maximally parallel manner]], which rules are applied to which objects. The output of the computation is collected from an ''a priori'' determined output region. Applications of 