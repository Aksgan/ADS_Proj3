on Computer Analysis of Images and Patterns |year=2009|pages=74–82 }}</ref> ==Software== {{Main|List of statistical packages}} All major statistical software packages perform [[least squares]] regression analysis and inference. [[Simple linear regression]] and multiple regression using least squares can be done in some [[spreadsheet]] applications and on some calculators. While many statistical software packages can perform various types of nonparametric and robust regression, these methods are less standardized; different software packages implement different methods, and a method with a given name may be implemented differently in different packages. Specialized regression software has been developed for use in fields such as survey analysis and neuroimaging. ==See also== {{Portal|Statistics}} {{Colbegin}} * [[Pearson product-moment correlation coefficient]] * [[Fraction of variance unexplained]] * [[Segmented regression]] * [[Curve fitting]] * [[Kriging]] (a linear least squares estimation algorithm) * [[Forecasting]] * [[Prediction interval]] * [[Trend estimation]] * [[Robust regression]] * [[Modifiable areal unit problem]] * [[Multivariate normal distribution]] * [[Multivariate adaptive regression splines]] * [[Stepwise regression]] * [[Local regression]] {{Colend}} ==Notes== {{Reflist}} ==References== * [[William Kruskal|William H. Kruskal]] and Judith M. Tanur, ed. (1978), "Linear Hypotheses," ''International Encyclopedia of Statistics''. Free Press, v. 1, :Evan J. Williams, "I. Regression," pp. 523–41. :[[Julian C. Stanley]], "II. Analysis of Variance," pp. 541–554. * [[D.V. Lindley|Lindley, D.V.]] (1987). "Regression and correlation analysis," [[New Palgrave: A Dictionary of Economics]], v. 4, pp. 120–23. * Birkes, David and Yadolah Dodge, ''Alternative Methods of Regression''. ISBN 0-471-56881-3 * Chatfield, C. (1993) "Calculating Interval Forecasts," ''Journal of Business and Economic Statistics,'' '''11'''. pp. 121–135. * Corder, G.W. and Foreman, D.I. (2009).''Nonparametric Statistics for Non-Statisticians: A Step-by-Step Approach'' Wiley, ISBN 9780470454619 * Draper, N.R. and Smith, H. (1998).''Applied Regression Analysis'' Wiley Series in Probability and Statistics * Fox, J. (1997). ''Applied Regression Analysis, Linear Models and Related Methods.'' Sage * Hardle, W., ''Applied Nonparametric Regression'' (1990), ISBN 0-521-42950-1 * Meade, N. and T. Islam (1995) "Prediction Intervals for Growth Curve Forecasts," ''Journal of Forecasting,'' '''14''', pp. 413–430. * N. Cressie (1996) Change of Support and the Modiable Areal Unit Problem. Geographical Systems 3:159–180. * A.S. Fotheringham, C. Brunsdon, and M. Charlton. (2002) Geographically weighted regression: the analysis of spatially varying relationships. Wiley. * T. Strutz: ''Data Fitting and Uncertainty (A practical introduction to weighted least squares and beyond)''. Vieweg+Teubner, ISBN 978-3-8348-1022-9. ==External links== {{Commons category|Regression analysis}} * [http://jeff560.tripod.com/r.html Earliest Uses: Regression] - gives basic history and references. * [http://www.vias.org/simulations/simusoft_regrot.html Regression of Weakly Correlated Data] - How linear regression mistakes can appear when Y-range is much smaller than X-range {{least squares and regression analysis}} {{Statistics|correlation|state=collapsed}} {{DEFAULTSORT:Regression Analysis}} [[Category:Regression analysis]] [[Category:Statistical methods]] [[Category:Econometrics]] [[Category:Actuarial science]] [[ar:تحليل الانحدار]] [[bg:Регресионен анализ]] [[cs:Regresní analýza]] [[da:Regressionsanalyse]] [[de:Regressionsanalyse]] [[es:Regresión (estadística)]] [[fa:تحلیل رگرسیون]] [[fr:Régression (statistiques)]] [[ko:회귀분석]] [[id:Regresi]] [[it:Analisi di regressione]] [[lv:Lineārās regresijas analīze]] [[hu:Regressziószámítás]] [[nl:Regressie-analyse]] [[ja:回帰分析]] [[no:Regresjonsanalyse]] [[pl:Regresja (statystyka)]] [[pt:Regressão]] [[ru:Регрессионный анализ]] [[simple:Regression analysis]] [[su:Analisis régrési]] [[fi:Regressioanalyysi]] [[sv:Regressionsanalys]] [[tr:Regresyon analizi]] [[uk:Регресійний аналіз]] [[vi:Phân tích hồi quy]] [[zh:迴歸分析]]</text> </page> <page> <id>31675</id> <title>Regression toward the mean</title> <text>{{Expert-subject|statistics|date=July 2010}} In [[statistics]], '''regression toward the mean''' is the phenomenon that if a variable is extreme on its first measurement, it will tend to be closer to the average on a second measurement, and&mdash;a fact that may superficially seem paradoxical&mdash;if it is extreme on a second measurement, will tend to have been closer to the average on the first measurement.<ref>Everitt, B.S. (2002) ''The Cambridge Dictionary of Statistics'', CUP. ISBN 0-521-81099-x</ref><ref>Upton, G., Cook, I. (2006) ''Oxford Dictionary of Statistics'', OUP. ISBN 978-0-19-954145-4</ref><ref>{{cite journal | doi=10.1191/096228097676361431 | last=Stigler | first=Stephen M | title=Regression toward the mean, historically considered | journal=Statistical Methods in Medical Research | volume=6 | issue=2 | pages=103–114 | url=http://smm.sagepub.com/content/6/2/103.abstract | year=1997 | pmid=9261910}}</ref> To avoid making wrong inferences, the possibility of regression toward the mean must be considered when designing experiments and interpreting experimental, survey, and other empirical data in the physical, life, behavioral and social sciences. The conditions under which regression toward the mean occurs depend on the way the term is mathematically defined. [[Sir Francis Galton]] first observed the phenomenon in the context of [[simple linear regression]] of data points. However, a less restrictive approach is possible. Regression towards the mean can be defined for any [[joint probability distribution|bivariate distribution]] with identical [[marginal distribution]]s. Two such definitions exist.<ref name=Samuels>Samuels (1991).</ref> One definition accords closely with the common usage of the term “regression towards the mean”. Not all such bivariate distributions show regression towards the mean under this definition. However, all such bivariate distributions show regression towards the mean under the other definition. Historically, what is now called regression toward the mean has also been called '''reversion to the mean''' and '''reversion to mediocrity'''. ==Conceptual background== Consider a simple example: a class of students takes a 100-item true/false test on a subject. Suppose that all students choose randomly on all questions. Then, each student’s score would be a realization of one of a set of [[i.i.d. random variables]], with a [[mean]] of 50. Naturally, some students will score substantially above 50 and some substantially below 50 just by chance. If one takes only the top scoring 10% of the students and gives them a second test on which they again choose randomly on all items, the mean score would again be expected to be close to 50. Thus the mean of these students would “regress” all the way back to the mean of all students who took the original test. No matter what a student scores on the original test, the best prediction of his score on the second test is 50. If there were no luck or random guessing involved in the answers supplied by students to the test questions then all students would score the same on the second test as they scored on the original test, and there would be no regression toward the mean. Most realistic situations fall between these two extremes: for example, one might consider exam scores as a combination of [[skill]] and [[luck]]. In this case, the subset of students scoring above average would be composed of those who were skilled and had not especially bad luck, together with those who 