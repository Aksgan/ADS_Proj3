example of concentration [added below, on august 27, 2005]; explanation on usage in maximum likelihood in optimization --> For example, consider a [[regression analysis]] model with [[normal distribution|normally distributed]] [[errors and residuals in statistics|errors]]. The most likely value of the error [[variance]] is the variance of the [[errors and residuals in statistics|residuals]]. The residuals depend on all other parameters. Hence the variance parameter can be written as a function of the other parameters. Unlike conditional and marginal likelihoods, profile likelihood methods can always be used, even when the profile likelihood cannot be written down explicitly. However, the profile likelihood is not a true likelihood, as it is not based directly on a probability distribution, and this leads to some less satisfactory properties. Attempts have been made to improve this, resulting in modified profile likelihood. The idea of profile likelihood can also be used to compute [[confidence interval]]s that often have better small-sample properties than those based on asymptotic [[Standard error (statistics)|standard errors]] calculated from the full likelihood. In the case of parameter estimation in partially observed systems, the profile likelihood can be also used for [[identifiability]] analysis.<ref> {{cite journal |last=Raue |first=A |title=Structural and practical identifiability analysis of partially observed dynamical models by exploiting the profile likelihood |url=http://bioinformatics.oxfordjournals.org/cgi/content/abstract/btp358?ijkey=iYp4jPP50F5vdX0&keytype=ref |journal=Bioinformatics |year=2009 |doi=10.1093/bioinformatics/btp358 |pmid=19505944 |last2=Kreutz |first2=C |last3=Maiwald |first3=T |last4=Bachmann |first4=J |last5=Schilling |first5=M |last6=Klingmüller |first6=U |last7=Timmer |first7=J |volume=25 |issue=15 |pages=1923–9 }}</ref> ===Partial likelihood=== A partial likelihood is a factor component of the likelihood function that isolates the parameters of interest.<ref> {{cite journal |last=Cox |first=D. R. |authorlink=David Cox (statistician) |title=Partial likelihood |journal=[[Biometrika]] |year=1975 |volume=62 |issue=2 |pages=269&ndash;276 |doi=10.1093/biomet/62.2.269 |id={{MR|0400509}} }}</ref> It is a key component of the [[proportional hazards model]]. ==Historical remarks== In English, "likelihood" has been distinguished as being related to but weaker than "probability" since its earliest uses. The comparison of hypotheses by evaluating likelihoods has been used for centuries, for example by [[John Milton]] in [[Aeropagitica]]: "when greatest likelihoods are brought that such things are truly and really in those persons to whom they are ascribed". In Danish, "likelihood" was used by [[Thorvald N. Thiele]] in 1889.<ref>{{cite book |title=A History of Mathematical Statistics from 1750 to 1930 |author=[[Anders Hald]]|year=1998 |publisher=Wiley |location=New York |isbn=0471179124}}</ref><ref> [http://www.stats.ox.ac.uk/~steffen/ Steffen L. Lauritzen], [http://www.stats.ox.ac.uk/~steffen/papers/isi99.ps ''Aspects of T. N. Thiele’s Contributions to Statistics'']. ''Bulletin of the [[International Statistical Institute]]'', 58, 27-30, 1999.</ref><ref> {{cite book|author=[http://www.stats.ox.ac.uk/~steffen/ Steffen L. Lauritzen]|title=Thiele: Pioneer in Statistics|publisher=[Oxford University Press]|year=2002|pages=288|isbn=978-0-19-850972-1}}</ref> In English, "likelihood" appears in many writings by [[Charles Sanders Peirce]], where [[Statistical model|model]]-based inference (usually [[abductive reasoning|abduction]] but sometimes including [[inductive reasoning|induction]]) is distinguished from statistical procedures based on [[objective]] [[randomization]]. Peirce's preference for randomization-based inference is discussed in "[[Charles Sanders Peirce bibliography#illus|Illustrations of the Logic of Science]]" (1877–1878) and "[[Charles Sanders Peirce bibliography#SIL|A Theory of Probable Inference]]" (1883)".{{Citation needed|date=November 2010}} <blockquote> "probabilities that are strictly objective and at the same time very great, although they can never be absolutely conclusive, ought nevertheless to influence our preference for one hypothesis over another; but slight probabilities, even if objective, are not worth consideration; and merely subjective likelihoods should be disregarded altogether. For they are merely expressions of our preconceived notions" (7.227 in his ''[[Charles Sanders Peirce bibliography#CP|Collected Papers]]''{{Citation needed|date=November 2010}}). </blockquote> <blockquote> "But experience must be our chart in economical navigation; and experience shows that likelihoods are treacherous guides. Nothing has caused so much waste of time and means, in all sorts of researchers, as inquirers' becoming so wedded to certain likelihoods as to forget all the other factors of the economy of research; so that, unless it be very solidly grounded, likelihood is far better disregarded, or nearly so; and even when it seems solidly grounded, it should be proceeded upon with a cautious tread, with an eye to other considerations, and recollection of the disasters caused." (''[[Charles Sanders Peirce bibliography#EP|Essential Peirce]]''{{Citation needed|date=November 2010}}, volume 2, pages 108–109) </blockquote> Like Thiele, Peirce considers the likelihood for a binomial distribution. Peirce uses the [[log odds|logarithm of the odds-ratio]] throughout his career. Peirce's propensity for using the [[log odds]] is discussed by [[Stephen Stigler]].{{Citation needed|date=November 2010}} In Great Britain, "likelihood" was introduced in mathematical statistics by [[R.A. Fisher]] in 1922<ref name=Fisher1922>{{cite journal | last=Fisher | first=R.A. |authorlink=Ronald Fisher | journal= Philosophical Transactions of the Royal Society of London. Series A | title=On the mathematical foundations of theoretical statistics | volume=222 | year=1922 | pages=309–368 | url=http://digital.library.adelaide.edu.au/dspace/handle/2440/15172 | id={{JSTOR|91208}}. {{JFM|48.1280.02}} |doi=10.1098/rsta.1922.0009 }}</ref>: "On the mathematical foundations of theoretical statistics". In that paper, Fisher also uses the term "[[method of maximum likelihood]]". Fisher argues against [[inverse probability]] as a basis for statistical inferences, and instead proposes inferences based on likelihood functions. Fisher's use of "likelihood" fixed the terminology that is used by statisticians throughout the world. == See also == * [[Bayes factor]] * [[Bayesian inference]] * [[Conditional probability]] * [[Likelihood principle]] * [[Likelihood-ratio test]] * [[Principle of maximum entropy]] * [[Conditional entropy]] * [[Score (statistics)]] ==Notes== {{Reflist}} ==References== * {{Cite journal |doi=10.1214/aos/1176343457 |title=[[Francis Ysidro Edgeworth|F. Y. Edgeworth]] and [[R. A. Fisher]] on the Efficiency of Maximum Likelihood Estimation | author=John W. Pratt| journal=The Annals of Statistics| volume=4| issue=3 |month=May |year=1976|pages=501&ndash;514 }} {{Jstor|2958222}} * {{Cite journal |doi=10.2307/2344804 |title=[[Francis Ysidro Edgeworth]], Statistician|author=Stephen M. Stigler|authorlink=Stephen Stigler|url=http://jstor.org/stable/2344804|journal= [[Journal of the Royal Statistical Society]], Series A | volume=141 |issue= 3 |year= 1978 | pages =287&ndash;322 }} {{jstor|2344804}} * {{Cite book|author=Stephen M. Stigler|authorlink=Stephen Stigler|title=The History of Statistics: The Measurement of Uncertainty before 1900| isbn=0-674-40340-1|publisher=Harvard University Press}} * {{Cite book|author=Stephen M. Stigler|authorlink=Stephen Stigler|title=Statistics on the Table: The History of Statistical Concepts and Methods| isbn=0-674-83601-4|publisher=Harvard University Press}} * {{Cite journal | title=On the History of Maximum Likelihood in Relation to Inverse Probability and Least Squares| author= Anders Hald |authorlink=Anders Hald |journal=Statistical Science|volume= 14| issue=2 |year=1999 | pages =214&ndash;222 }} {{jstor|2676741}} * {{Cite book| author=Hald, A. |authorlink=Anders Hald|year=1998| title=A History of Mathematical Statistics from 1750 to 1930| publisher=Wiley| location=New York| isbn=0471179124}} ==External links== {{Wiktionary|likelihood}} * [http://planetmath.org/encyclopedia/LikelihoodFunction.html Likelihood function at Planetmath] {{DEFAULTSORT:Likelihood Function}} [[Category:Estimation theory]] [[Category:Bayesian statistics]] [[ar:دالة الإمكان]] [[bn:সম্ভাব্যতা অপেক্ষক]] [[de:Likelihood-Funktion]] [[es:Función de verosimilitud]] [[fa:تابع درست‌نمایی]] [[fr:Fonction de vraisemblance]] [[it:Funzione di verosimiglianza]] [[nl:Aannemelijkheidsfunctie]] [[ja:尤度関数]] [[pl:Częstość]] [[ru:Функция правдоподобия]] [[uk:Функція правдоподібності]] 