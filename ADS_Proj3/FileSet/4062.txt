on OUR terms, not on the misanthropic terms of the Masters. A few words from Thoreau have a particular potency in this technophilic society, "for every 100 people chopping at the branches, only one is hacking at the roots". And so it is that we find ourselves, quite 'naturally' -- blade in hand.<ref name="Green Anarchy 2005"/>}} ==See also== * [[Matrioshka brain]] * [[Nanorobotics]] * [[Post scarcity]] * [[Seed AI]] * [[Strong AI]] * [[Technological Singularity]] * [[Transhumanism]] ==References== {{Reflist}} == External links == * [http://www.singinst.org/why-singularity.html Why Work Towards the Singularity?] by Eliezer Yudkowsky * [http://www.nickbostrom.com/ethics/ai.html Ethical Issues in Advanced Artificial Intelligence] by Nick Bostrom [[Category:Singularitarianism| ]] [[Category:Anticipatory thinking]] [[Category:Futurology]] [[Category:Prediction]] [[Category:Philosophy of artificial intelligence]] [[Category:Technology forecasting]] [[Category:Technology neologisms]] [[Category:Transhumanism]] [[it:Singolaritanismo]] [[lt:Singuliaritarianizmas]]</text> </page> <page> <id>34549</id> <title>Singularity Institute for Artificial Intelligence</title> <text>{{moreref|date=July 2010}} {{Transhumanism}} The '''Singularity Institute for Artificial Intelligence (SIAI)''' is a [[non-profit organization]] founded in 2000 to develop safe [[artificial intelligence]] software, and to raise awareness of both the dangers and potential benefits it believes AI presents. The organization advocates ideas initially put forth by [[I. J. Good]] and [[Vernor Vinge]] regarding an "intelligence explosion", or [[Technological Singularity|Singularity]], which is predicted to follow the creation of sufficiently advanced AI. In their view, the potential benefits and risks of this event necessitate the search for solutions to problems involving AI goal systems to ensure powerful AIs are not dangerous when they are created. The Singularity Institute espouses the [[Friendly AI]] model created by its co-founder [[Eliezer Yudkowsky]] as a potential solution to such problems. [[Michael Vassar]] serves as the organization's president, and inventor and [[futures studies]] author [[Ray Kurzweil]] serves as one of its directors. SIAI maintains an advisory board whose members include [[University of Oxford|Oxford]] philosopher [[Nick Bostrom]], biomedical gerontologist [[Aubrey de Grey]], [[PayPal]] co-founder [[Peter Thiel]], and [[Foresight Nanotech Institute]] co-founder Christine Peterson. The SIAI is [[tax exemption|tax exempt]] under [[501(c)(3)|Section 501(c)(3) of the United States Internal Revenue Code]], and has a Canadian branch, SIAI-CA, formed in 2004 and recognized as a Charitable Organization by the [[Canada Revenue Agency]]. ==History== SIAI was founded in 2000 by AI researcher [[Eliezer Yudkowsky]] and Internet entrepreneurs Brian and Sabine Atkins. At first, SIAI operated primarily over the Internet, receiving financial contributions from [[transhumanists]] and [[futurists]]. On July 23, 2001, SIAI launched the open source [http://flarelang.sourceforge.net/ Flare Programming Language Project], described as an "annotative programming language" with [http://flarelang.sourceforge.net/features.html features] inspired by [[Python (programming language)|Python]], [[Java (programming language)|Java]], [[C++]], [[Eiffel (programming language)|Eiffel]], [[Common Lisp]], [[Scheme (programming language)|Scheme]], [[Perl]], [[Haskell (programming language)|Haskell]], and others. The specifications were designed with the complex challenges of [[seed AI]] in mind. However, the effort is no longer active, as more focus was put on the problem of [[Friendly AI]]. In 2002, SIAI published on its website the paper [http://www.singinst.org/LOGI ''Levels of Organization in General Intelligence''], a preprint of a book chapter later included in a compilation of general AI theories, entitled "Artificial General Intelligence" ([[Ben Goertzel]] and Cassio Pennachin, eds.). Later that year, SIAI released their two main introductory pieces, [http://www.singinst.org/what-singularity.html "What is the Singularity"] and [http://www.singinst.org/why-singularity.html "Why Work Toward the Singularity"]. In 2003, the Singularity Institute appeared at the Foresight Senior Associates Gathering, where co-founder [[Eliezer Yudkowsky]] presented a talk titled "Foundations of Order". They also made an appearance at the Transvision 2003 conference at [[Yale University]] with a talk by SIAI volunteer Michael Anissimov. In 2004, SIAI released [http://www.asimovlaws.com AsimovLaws.com], a website that examined AI morality in the context of the "I, Robot" movie starring Will Smith, released just two days later. From July to October, SIAI ran a Fellowship Challenge Grant that raised $35,000 over the course of three months. Early the next year, the Singularity Institute relocated from Atlanta, Georgia to Silicon Valley. In February 2006, the Singularity Institute completed a $200,000 [http://www.singularitychallenge.com Singularity Challenge] fundraising drive, in which every donation up to $100,000 was matched by [[Clarium Capital]] President, Paypal Co-Founder and SIAI Advisor [[Peter Thiel]]. The stated uses of the funds included hiring additional full-time staff, an additional full-time research fellow position, and the organization of the [[Singularity Summit]] at Stanford. In 2006, the Singularity Institute, along with the Symbolic Systems Program at Stanford, the Center for Study of Language and Information, KurzweilAI.net, and Peter Thiel, co-sponsored the [[Singularity Summit]] at Stanford.<ref>[http://www.sfgate.com/cgi-bin/article.cgi?f=/c/a/2006/05/12/BUG9IIMG1V197.DTL Smarter than thou?], ''San Francisco Chronicle'', 12 May 2006</ref> The summit took place on 13 May 2006 at Stanford University with Thiel moderating and 1300 in attendance. The keynote speaker was Ray Kurzweil, followed by eleven others: [[Nick Bostrom]], [[Cory Doctorow]], [[K. Eric Drexler]], [[Douglas Hofstadter]], [[Steve Jurvetson]], [[Bill McKibben]], [[Max More]], [[Christine Peterson]], [[John Smart (futurist)|John Smart]], [[Sebastian Thrun]], and [[Eliezer Yudkowsky]]. The 2007 [[Singularity Summit]] took place on September 8-September 9, 2007, at the [[Palace of Fine Arts]] Theatre, [[San Francisco]]. A third Singularity Summit took place on October 25, 2008, at the Montgomery Theater in San Jose. The 2009 Singularity Summit took place on October 3rd, at the [[92nd Street Y]] in New York City, New York. The 2010 Summit was held on August 14-15, 2010, at the [[Hyatt Regency]] in San Francisco. ==See also== *[[Lifeboat Foundation]] ==References== <references/> ==External links== *[http://www.singinst.org/ Singularity Institute for Artificial Intelligence] *[http://www.singularitysummit.com/ The Singularity Summit 2010] *[http://sss.stanford.edu/ The Singularity Summit at Stanford] [[Category:Singularitarianism|Singularitarianism]] [[Category:Artificial intelligence associations]] [[ru:Singularity Institute for Artificial Intelligence]] [[uk:Singularity Institute for Artificial Intelligence]]</text> </page> <page> <id>34553</id> <title>Sinusoidal model</title> <text>{{Unreferenced|date=February 2008}} In [[statistics]], [[signal processing]], and [[time series analysis]], a '''sinusoidal model''' to approximate a sequence ''Y<sub>i</sub>'' is: :<math>Y_i = C + \alpha\sin(\omega T_i + \phi) + E_i </math> where ''C'' is constant defining a [[mean]] level, α is an [[amplitude]] for the [[sine wave]], ω is the [[frequency]], ''T<sub>i</sub>'' is a time variable, φ is the [[phase (waves)|phase]], and ''E<sub>i</sub>'' is the error sequence in approximating the sequence ''Y<sub>i</sub>'' by the model. This sinusoidal model can be fit using [[nonlinear least squares]]; to obtain a good fit, nonlinear least squares routines may require good starting values for the constant, the amplitude, and the frequency. Fitting a model with a 