is a [[computer]] where single [[instruction set architecture|instruction]]s can execute several low-level operations (such as a load from [[Memory (computers)|memory]], an [[arithmetic]] [[operator (programming)|operation]], and a [[memory (computers)|memory store]]) and/or are capable of multi-step operations or [[addressing mode]]s within single instructions. The term was retroactively coined in contrast to [[reduced instruction set computer]] (RISC). Examples of CISC instruction set architectures are [[System/360]] through [[z/Architecture]], [[PDP-11]], [[VAX]], [[Motorola 68000 family|Motorola 68k]], and [[x86]]. ==Historical design context== ===Incitements and benefits=== Before the [[Reduced instruction set computing|RISC]] philosophy became prominent, many [[computer Architecture|computer architects]] tried to bridge the so called [[semantic gap]], i.e. to design instruction sets that directly supported high-level programming constructs such as procedure calls, loop control, and complex [[addressing mode]]s, allowing data structure and array accesses to be combined into single instructions. Instructions are also typically highly encoded in order to further enhance the code density. The compact nature of such instruction sets results in smaller [[Computer program|program]] sizes and fewer (slow) main memory accesses, which at the time (early 1960s and onwards) resulted in a tremendous savings on the cost of computer memory and disc storage, as well as faster execution. It also meant good programming productivity even in [[assembly language]], as [[high level language]]s such as [[Fortran]] or [[ALGOL|Algol]] were not always available or appropriate (microprocessors in this category are sometimes still programmed in assembly language for certain types of critical applications). ====New instructions==== In the 70's, analysis of high level languages indicated some complex machine language implementations and it was determined that new instructions could improve performance. Some instructions were added that were never intended to be used in assembly language but fit well with compiled high level languages. Compilers were updated to take advantage of these instructions. The benefits of semantically rich instructions with compact encodings can be seen in modern processors as well, particularly in the high performance segment where caches are a central component (as opposed to most [[embedded system]]s). This is because these fast, but complex and expensive, memories are inherently limited in size, making compact code beneficial. Of course, the fundamental reason they are needed is that main memories (i.e. [[dynamic RAM]] today) remain slow compared to a (high performance) CPU-core. ===Design issues=== While many designs achieved the aim of higher throughput at lower cost and also allowed high-level language constructs to be expressed by fewer instructions, it was observed that this was not ''always'' the case. For instance, low-end versions of complex architectures (i.e. using less hardware) could lead to situations where it was possible to improve performance by ''not'' using a complex instruction (such as a procedure call or enter instruction), but instead using a sequence of simpler instructions. One reason for this was that architects (microcode writers) sometimes "over-designed" assembler language instructions, i.e. including features which were not possible to implement efficiently on the basic hardware available. This could, for instance, be "side effects" (above conventional flags), such as the setting of a register or memory location that was perhaps seldom used; if this was done via ordinary (non duplicated) internal buses, or even the ''external'' bus, it would demand extra cycles every time, and thus be quite inefficient. Even in balanced high performance designs, highly encoded and (relatively) high-level instructions could be complicated to decode and execute efficiently within a limited transistor budget. Such architectures therefore required a great deal of work on the part of the processor designer in cases where a simpler, but (typically) slower, solution based on decode tables and/or microcode sequencing is not appropriate. At the time where transistors and other components were a limited resource, this also left fewer components and less area for other types of performance optimizations. ====The RISC idea==== The circuitry that performs the actions defined by the microcode in many (but not all) CISC processors is, in itself, a processor which in many ways is reminiscent in structure to very early CPU designs. This gave rise to ideas to return to simpler processor designs in order to make it more feasible to cope without (''then'' relatively large and expensive) ROM tables, or even without PLA structures, for sequencing and/or decoding. At the same time, simplicity and regularity, would make it easier to implement overlapping processor stages (pipelining) at the machine code level (i.e. the level seen by compilers). The first (retroactively) RISC-''labeled'' processor ([[IBM 801]] - [[IBM]]s Watson Research Center, mid-1970s) was therefore a tightly pipelined machine originally intended to be used as an internal microcode kernel, or engine, in a CISC design. At the time, pipelining at the machine code level was already used in some high performance CISC computers, in order to reduce the instruction cycle time, but it was fairly complicated to implement within the limited component count and wiring complexity that was feasible at the time. (Microcode execution, on the other hand, could be more or less pipelined, depending on the particular design.) ====Superscalar==== In a more modern context, the complex variable length encoding used by some of the typical CISC architectures makes it complicated, but still feasible, to build a superscalar implementation of a CISC programming model ''directly''; the in-order superscalar [[Intel P5|Original Pentium]] and the out-of-order superscalar [[Cyrix 6x86]] are well known examples of this. The frequent memory accesses for operands of a typical CISC machine may limit the instruction level parallelism that can be extracted from the code, although this is strongly mediated by the fast cache structures used in modern designs, as well as by other measures. Due to inherently compact and semantically rich instructions, the average amount of work performed per machine code unit (i.e. per byte or bit) is higher for a CISC than a RISC processor, which may give it a significant advantage in a modern cache based implementation. (Whether the downsides versus the upsides justifies a complex design or not is food for a never-ending debate in certain circles.) Transistors for logic, PLAs, and microcode are no longer scarce resources; only large high-speed cache memories are limited 