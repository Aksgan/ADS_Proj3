of Parallelism | author = Anthes, Gry | accessdate = 2008-01-08 | date = November 19, 2001 | work = [[Computerworld]]}}</ref> In 1967, Amdahl and Slotnick published a debate about the feasibility of parallel processing at American Federation of Information Processing Societies Conference.<ref name=G_Wilson/> It was during this debate that Amdahl's Law was coined to define the limit of speed-up due to parallelism. In 1969, US company [[Honeywell]] introduced its first Multics system, a symmetric multiprocessor system capable of running up to eight processors in parallel.<ref name=G_Wilson/> [[C.mmp]], a 1970s multi-processor project at [[Carnegie Mellon University]], was "among the first multiprocessors with more than a few processors".<ref name=PH753/> "The first bus-connected multi-processor with snooping caches was the [[Synapse N+1]] in 1984."<ref name=PH753/> SIMD parallel computers can be traced back to the 1970s. The motivation behind early SIMD computers was to amortize the [[Propagation delay|gate delay]] of the processor's [[control unit]] over multiple instructions.<ref>Patterson and Hennessy, p. 749.</ref> In 1964, Slotnick had proposed building a massively parallel computer for the [[Lawrence Livermore National Laboratory]].<ref name=G_Wilson/> His design was funded by the [[US Air Force]], which was the earliest SIMD parallel-computing effort, [[ILLIAC IV]].<ref name=G_Wilson/> The key to its design was a fairly high parallelism, with up to 256 processors, which allowed the machine to work on large datasets in what would later be known as [[vector processor|vector processing]]. However, ILLIAC IV was called "the most infamous of Supercomputers", because the project was only one fourth completed, but took 11 years and cost almost four times the original estimate.<ref>Patterson and Hennessy, pp. 749–50: "Although successful in pushing several technologies useful in later projects, the ILLIAC IV failed as a computer. Costs escalated from the $8 million estimated in 1966 to $31 million by 1972, despite the construction of only a quarter of the planned machine ... It was perhaps the most infamous of supercomputers. The project started in 1965 and ran its first real application in 1976."</ref> When it was finally ready to run its first real application in 1976, it was outperformed by existing commercial supercomputers such as the [[Cray-1]]. ==See also== * [[List of important publications in concurrent, parallel, and distributed computing]] * [[List of distributed computing conferences]] * [[Content Addressable Parallel Processor]] * [[Transputer]] ==References== {{reflist|2}} ==Further reading== *C. Rodríguez, M. Villagra and B. Barán, {{doi-inline|10.1109/BIMNICS.2007.4610083|Asynchronous team algorithms for Boolean Satisfiability}}, Bionetics2007, pp. 66–69, 2007. ==External links== {{Spoken Wikipedia|En-Parallel_computing.ogg|2010-11-01}} {{wikibooks|Distributed Systems}} * {{dmoz|Computers/Parallel_Computing/}} * [http://www.llnl.gov/computing/tutorials/parallel_comp/ Lawrence Livermore National Laboratory: Introduction to Parallel Computing] * [http://www-unix.mcs.anl.gov/dbpp/ Designing and Building Parallel Programs, by Ian Foster] *[http://wotug.ukc.ac.uk/parallel/ Internet Parallel Computing Archive] *[http://dsonline.computer.org/portal/site/dsonline/index.jsp?pageID=dso_level1_home&path=dsonline/topics/parallel&file=index.xml&xsl=generic.xsl Parallel processing topic area at IEEE Distributed Computing Online] *[http://www.new-npac.org/projects/cdroms/cewes-1998-05/copywrite/pcw/book.html Parallel Computing Works Free On-line Book] *[http://ark.cdlib.org/ark:/13030/ft0f59n73z/ Frontiers of Supercomputing Free On-line Book Covering topics like algorithms and industrial applications] * [http://www.upcrc.illinois.edu/ Universal Parallel Computing Research Center] *[http://ppppcourse.ning.com/ Course in Parallel Programming at Columbia University (in collaboration with IBM T.J Watson X10 project)] ==Related information==<!--navbox heading--> {{Parallel Computing}} {{featured article}} [[Category:Parallel computing| ]] {{Link FA|pl}} [[ar:حوسبة متوازية]] [[bg:Паралелни изчисления]] [[bs:Paralelno programiranje]] [[ca:Computació paral·lela]] [[de:Parallelrechner]] [[el:Παράλληλος προγραμματισμός]] [[es:Computación paralela]] [[fa:برنامه‌سازی موازی]] [[fr:Parallélisme (informatique)]] [[ko:병렬 컴퓨팅]] [[hr:Paralelna obrada]] [[id:Pemrograman paralel]] [[it:Calcolo parallelo]] [[he:עיבוד מקבילי]] [[lv:Paralēlā skaitļošana]] [[ml:പാരലല്‍ കംപ്യൂട്ടിങ്ങ്]] [[ja:並列コンピューティング]] [[pl:Obliczenia równoległe]] [[pt:Computação paralela]] [[ru:Параллельные вычислительные системы]] [[sl:Vzporedna obdelava]] [[fi:Rinnakkaislaskenta]] [[sq:Paralelizmi (informatikë)]] [[sv:Parallelldator]] [[tr:Paralel hesaplama]] [[uk:Паралельні обчислення]] [[zh:并行计算]]</text> </page> <page> <id>28416</id> <title>Parallel manipulator</title> <text>{{Merge|Delta robot|date=October 2009}} {{Context|date=October 2009}} A generalized parallel manipulator is a closed-loop kinematic chain mechanism whose end-effector is linked to the base by several independent kinematic chains A '''parallel manipulator''', also called a '''parallel robot''', consists of a fixed "base" platform, connected to an [[Industrial robot end effector|end effector]] platform by means of a number of "legs". These legs often consist of an actuated [[prismatic joint]], connected to the platforms through passive (i.e. not actuated) spherical and/or [[universal joint]]s. Hence, the links feel only traction or compression, not bending, which increases their position [[accuracy]] and allows a lighter construction. A '''parallel robot''' is a device for performing manipulations, where the end effector is connected to the base via multiple [[kinematic chain]]s. Any two chains thus form a closed loop. This is opposed to classical open loop mechanisms such as the [[serial robot]] [[robotic arm]] (e.g. articulated robots such as jointed arms). The actuators for the prismatic joints can be placed in the motionless base platform, so that their mass does not have to be moved, which again makes the construction lighter.<br /> Parallel manipulators have (in principle) high structural [[stiffness]], since the end effector is supported in several places at the same time. All these features result in manipulators with a wide range of motion capability. Their major drawback is their limited workspace, because the legs can collide and, in addition, each leg has five passive joints that each have their own mechanical limits. Another drawback of Parallel Robots is that they lose stiffness in singular positions completely (The robot gains finite or infinite degrees of freedom which are uncontrolable; it becomes shaky or mobile). This means that the Jacobian matrix, which is the mapping from joint space to euclidian space, becomes singular (the rank decreases from six). ==Applications== Major industrial applications of these devices are * [[flight simulator|airplane simulators]] * automobile simulators * in work processes * photonics / fiber alignment http://www.pb.izm.fhg.de/p2sa/020_Technologies/Optik/FundE_Faserjustage.html They also become more popular * in high speed, high-accuracy positioning with limited workspace, such as in assembly of [[Printed circuit board|PCBs]] * as micro manipulators mounted on the end effector of larger but slower [[serial manipulator]]s * as high speed/high-precision [[milling machine]]s Parallel robots are usually faster than traditional articulated robots, since the motors can be mounted on the base, thus saving weight. They are also stronger than serial robots because the end effector is connected to more links. Another benefit is that the error of the end effector is less than the errors of serial robots since the errors are averaged (as opposed to being additive as in serial robots). However, parallel robots are usually more limited in the workspace; for instance, they generally cannot 