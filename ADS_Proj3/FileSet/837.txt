the remaining entropy must be 0. It follows that ''k'' must be at least ''log<sub>2</sub>(n!)''. Note that this differs from the worst case argument given above, in that it does not allow rounding up to the nearest integer. For example, for ''n = 3'', the lower bound for the worst case is 3, the lower bound for the average case as shown above is approximately 2.58, while the highest lower bound for the average case is 8/3, approximately 2.67. In the case that multiple items may have the same key, there is no obvious statistical interpretation for the term "average case", so an argument like the above cannot be applied without making specific assumptions about the distribution of keys. ==Notes == <references/> ==References== * [[Donald Knuth]]. ''The Art of Computer Programming'', Volume 3: ''Sorting and Searching'', Second Edition. Addison-Wesley, 1997. ISBN 0-201-89685-0. Section 5.3.1: Minimum-Comparison Sorting, pp. 180&ndash;197. * [[Thomas H. Cormen]], [[Charles E. Leiserson]], [[Ronald L. Rivest]], and [[Clifford Stein]]. ''[[Introduction to Algorithms]]'', Second Edition. MIT Press and McGraw-Hill, 2001. ISBN 0-262-03293-7. Section 8.1: Lower bounds for sorting, pp. 165&ndash;168. {{DEFAULTSORT:Comparison Sort}} [[Category:Sorting algorithms]] [[it:Algoritmi di ordinamento comparativi]] [[ml:താരതമ്യ സോർട്ട്]] [[pt:Ordenação por comparação]]</text> </page> <page> <id>7249</id> <title>Compensating transaction</title> <text>{{Unreferenced|date=November 2006}} The execution of a business process consists of one or more [[Transaction processing|transactions]]. Each transaction may consist of several individual operations yet, as a whole, it moves the system between consistent states. In the context of a [[database]] this is often easily achieved using [[Database transaction|transactions]] and the [[Commit (data management)|commit]]/[[Rollback (data management)|rollback]] mechanism. For systems without a [[Commit (data management)|commit]]/[[Rollback (data management)|rollback]] mechanism available, one can undo a failed transaction with a '''compensating transaction''', which will bring the system back to its initial state. Typically, this is only a ''workaround'' which has to be implemented manually and cannot guarantee that the system always ends in a consistent state. The system designer may need to consider what happens if the compensating transaction also fails. '''Compensating transactions''' are also used in case where a transaction is long lived (commonly called [[Long-running transaction|Saga Transactions]]), for instance in a business process requiring user input. In such cases data will be committed to permanent storage, but may subsequently need to be rolled back, perhaps due to the user opting to cancel the operation. Unlike conventional rollbacks, specific business logic will typically be required to rollback a long lived transaction and restore the system to its original state. This type of transaction differs from [[distributed transaction]]s (often implemented using the [[two-phase-commit protocol]]), because although both types of transactions can result in multiple data stores being updated, '''compensating transactions''' allows for the updates to span a long period of time. '''Compensating transactions''' are often designed into [[Web service]]s that participate in the execution of business processes that are part of a [[service-oriented architecture]] solution. ==See also== *[[Commit (data management)]] *[[Business Process Execution Language]] {{DEFAULTSORT:Compensating Transaction}} [[Category:Data synchronization]] [[Category:Transaction processing]] {{Comp-stub}}</text> </page> <page> <id>7256</id> <title>Competitive learning</title> <text>'''Competitive learning''' is a form of [[unsupervised learning]] in [[artificial neural networks]], in which nodes compete for the right to respond to a subset of the input data.<ref>{{cite book | last = Rumelhart | first = David | authorlink = David Rumelhart | coauthors = David Zipser, James L. McClelland, et al. | title = Parallel Distributed Processing, Vol. 1 | publisher = MIT Press | year = 1986 | location = | pages = 151–193 | url = | doi = | id = | isbn = }}</ref> A variant of [[Hebbian learning]], competitive learning works by increasing the specialization of each node in the network. It is well suited to finding [[cluster analysis | clusters]] within data. == Example algorithm == Here is a simple competitive learning algorithm to find three clusters within some input data. 1. (Set-up.) Let a set of sensors all feed into three different nodes, so that every node is connected to every sensor. Let the weights that each node gives to its sensors be set randomly between 0.0 and 1.0. Let the output of each node be the sum of all its sensors, each sensor's signal strength being multiplied by its weight. 2. When the net is shown an input, the node with the highest output is deemed the winner. The input is classified as being within the cluster corresponding to that node. 3. The winner updates each of its weights, moving weight from the connections that gave it weaker signals to the connections that gave it stronger signals. Thus, as more and more data is received, each node "listens" more and more carefully to the sensors that relate to one cluster, and "listens" less and less to sensors that relate to other clusters. ==References== {{reflist}} [[Category:Neural networks]]</text> </page> <page> <id>7261</id> <title>Compile time function execution</title> <text>'''Compile time function execution''' (or '''compile-time function evaluation''', '''CTFE''') is the ability of a [[compiler]], that would normally compile a function to machine code and execute it at [[Run time (computing)|run time]], to execute the function at [[compile time]]. This is possible if the arguments to the function are known at compile time, and the function does not make any reference to or attempt to modify any global state (is a [[pure function]]). Even if the value of only some of the arguments are known, the compiler may still be able to perform some level of compile time function execution ([[partial evaluation]]), possibly producing more optimized code than if no arguments were known. ==Example== In [[C++]], [[template metaprogramming]] is often used to compute values at compile time, such as: <source lang="CPP"> template <int N> struct Factorial { enum { value = N * Factorial<N - 1>::value }; }; template <> struct Factorial<0> { enum { value = 1 }; }; // Factorial<4>::value == 24 // Factorial<0>::value == 1 void foo() { int x = Factorial<0>::value; // == 1 int y = Factorial<4>::value; // == 24 } </source> But with compile time function evaluation the code used to compute the factorial would be exactly the same as what one 