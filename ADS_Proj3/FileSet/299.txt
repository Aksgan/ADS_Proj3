with [[:de:Wikipedia:Helferlein/VBA-Macro for EXCEL tableconversion]] V1.7<\hiddentext> |- | width="47" height="13" valign="bottom" | | width="42" valign="bottom" | | width="37" colspan="3" align="center" valign="bottom" | Input | width="21" colspan="2" align="center" valign="bottom" | Initial | width="39" colspan="2" align="center" valign="bottom" | Output | width="35" valign="bottom" | | width="64" valign="bottom" | | width="38" valign="bottom" | | width="50" valign="bottom" | | width="41" colspan="2" align="center" valign="bottom" | Final |- | height="38" valign="bottom" | Threshold | valign="bottom" | Learning Rate | colspan="2" align="center" valign="bottom" | Sensor values | valign="bottom" | Desired output | colspan="2" align="center" valign="bottom" | Weights | colspan="2" align="center" valign="bottom" | Calculated | align="center" valign="bottom" | Sum | align="center" valign="bottom" | Network | align="center" valign="bottom" | Error | align="center" valign="bottom" | Correction | colspan="2" align="center" valign="bottom" | Weights |- align="center" valign="bottom" | height="13" | TH | LR | X1 | X2 | Z | w1 | w2 | C1 | C2 | S | N | E | R | W1 | W2 |- align="center" valign="bottom" | height="13" | | | | | | | | X1 x w1 | X2 x w2 | C1+C2 | IF(S>TH,1,0) | Z-N | LR x E | R+w1 | R+w2 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 0 | 0 | 0 | 0.1 | 0.3 | 0 | 0 | 0 | 0 | 0 | 0 | 0.1 | 0.3 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 0 | 1 | 1 | 0.1 | 0.3 | 0 | 0.3 | 0.3 | 0 | 1 | 0.2 | 0.3 | 0.5 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 1 | 0 | 1 | 0.3 | 0.5 | 0.3 | 0 | 0.3 | 0 | 1 | 0.2 | 0.5 | 0.7 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 1 | 1 | 1 | 0.5 | 0.7 | 0.5 | 0.7 | 1.2 | 1 | 0 | 0 | 0.5 | 0.7 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 0 | 0 | 0 | 0.5 | 0.7 | 0 | 0 | 0 | 0 | 0 | 0 | 0.5 | 0.7 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 0 | 1 | 1 | 0.5 | 0.7 | 0 | 0.7 | 0.7 | 1 | 0 | 0 | 0.5 | 0.7 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 1 | 0 | 1 | 0.5 | 0.7 | 0.5 | 0 | 0.5 | 0 | 1 | 0.2 | 0.7 | 0.9 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 1 | 1 | 1 | 0.7 | 0.9 | 0.7 | 0.9 | 1.6 | 1 | 0 | 0 | 0.7 | 0.9 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 0 | 0 | 0 | 0.7 | 0.9 | 0 | 0 | 0 | 0 | 0 | 0 | 0.7 | 0.9 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 0 | 1 | 1 | 0.7 | 0.9 | 0 | 0.9 | 0.9 | 1 | 0 | 0 | 0.7 | 0.9 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 1 | 0 | 1 | 0.7 | 0.9 | 0.7 | 0 | 0.7 | 1 | 0 | 0 | 0.7 | 0.9 |- align="center" valign="bottom" | height="13" | 0.5 | 0.2 | 1 | 1 | 1 | 0.7 | 0.9 | 0.7 | 0.9 | 1.6 | 1 | 0 | 0 | 0.7 | 0.9 |} Supervised neural network training for an OR gate. Note: Initial weight equals final weight of previous iteration. ==Limitations== Artificial neurons of simple types, such as the McCulloch–Pitts model, are sometimes characterized as "caricature models", in that they are intended to reflect one or more neurophysiological observations, but without regard to realism.<ref> {{cite book | author = F. C. Hoppensteadt and E. M. Izhikevich | title = Weakly connected neural networks | isbn = 9780387949482 | publisher = Springer | year = 1997 | page = 4 }}</ref> == See also == *[[Neural network]] *[[Perceptron]] *[[ADALINE]] *[[Biological neuron models]] *[[Connectionism]] == References == {{reflist}} == Further reading == {{refbegin}} * [[Warren McCulloch|McCulloch, W]]. and [[Walter Pitts|Pitts, W]]. (1943). ''A logical calculus of the ideas immanent in nervous activity.'' Bulletin of Mathematical Biophysics, 7:115 - 133. * A.S. Samardak, A. Nogaret, N. B. Janson, A. G. Balanov, I. Farrer and D. A. Ritchie. "Noise-Controlled Signal Transmission in a Multithread Semiconductor Neuron" // Phys.Rev.Lett. 102 (2009) 226802, [http://prl.aps.org/abstract/PRL/v102/i22/e226802] {{refend}} == External links == * [http://www.mind.ilstu.edu/curriculum/modOverview.php?modGUI=212] A good general overview [[Category:Neural networks]] [[Category:American inventions]] {{Link GA|de}} [[de:Künstliches Neuron]] [[es:Neurona de McCulloch-Pitts]] [[fr:Neurone formel]] [[ko:인공 뉴런]] [[ja:人工神経]] [[pl:Neuron McCullocha-Pittsa]] [[pt:Neurônio artificial]] [[ru:Искусственный нейрон]] [[uk:Штучний нейрон]]</text> </page> <page> <id>2482</id> <title>Artificial psychology</title> <text>{{Orphan|date=February 2009}} {{Unreferenced|date=July 2008}} '''Artificial Psychology''' is a theoretical discipline proposed by Dan Curtis (b. 1963). The theory states that when the [[artificial intelligence]] approaches the level of complexity where the intelligence meets two conditions: '''Condition I''' * A Makes all of its decisions autonomously * B Is capable of making decisions based on information that is :# New :# [[Abstract]] :# Incomplete * C The artificial intelligence is capable of reprogramming itself based on the new data * D And is capable of resolving its own programming conflicts, even in the presence of incomplete data. This means that the intelligence autonomously makes value-based decisions, referring to values that the intelligence has created for itself. '''Condition II''' * All four criteria are met in situations that are not part of the original operating program When both conditions are met, then the possibility exists that the intelligence will reach irrational conclusions based on real or created information. At this point, the criteria is met for intervention which will not necessarily be resolved by simple re-coding of processes due to extraordinarily complex nature of the [[codebase]] 