have set up "Referral Sites" whereby students can access CyberMentors services from anywhere. Two of the most successful examples of this are [http://cybermentors.horbury.wakefield.sch.uk Horbury School's CyberMentors] and [http://samwhitcybermentors.org.uk SWCC CyberMentors]<ref name ="RefSites">{{cite web | title = Referral sites spring up all over the UK | url = http://www.beatbullying.org/dox/media-centre/news-archive/April%202010/cybermentors-referral-sites.html | accessdate = 2010-25-04 }}</ref>. == References == <!--- See [[Wikipedia:Footnotes]] on how to create references using <ref></ref> tags which will then appear here automatically --> {{Reflist}} == External links == * [http://cybermentors.org.uk/ http://cybermentors.org.uk] * [http://beatbullying.org/ http://beatbullying.org] * [http://cybermentors.horbury.wakefield.sch.uk/ http://cybermentors.horbury.wakefield.sch.uk] * [http://samwhitcybermentors.org.uk/index.html http://samwhitcybermentors.org.uk/] <!--- Categories ---> [[Category:Social network services]]</text> </page> <page> <id>8803</id> <title>Cybernetic revolt</title> <text>{{See also|Machine rule|Artificial intelligence in fiction}} '''Cybernetic revolt''' is a [[scenario]] in which an [[artificial intelligence]] (either a single [[supercomputer]], a computer network, or sometimes a "race" of intelligent machines) decide that [[human race|humans]] are a threat (either to the machines or to themselves) or are oppressors and try to destroy or to enslave them potentially leading to [[Machine rule]]. In this fictional scenario, humans are often depicted to prevail using "human" qualities, for example using [[emotion]]s, [[logic|illogic]], [[inefficiency]], [[duplicity]], unpredictability, or exploiting the supposedly rigid, rules-based thinking and lack of innovation of the computer's black/white mind. ==Relevance== Fear of humanity being made obsolete by technology taps into some of modern humans' deepest fears. This can be shown to have been the case even before the computer became prominent, as in [[Karel Capek]]'s play ''[[R.U.R. (Rossum's Universal Robots)]]''. However, even as they were slowly being displaced from most physical tasks, humans have always prided themselves on their brains, taking the mechanistic 'thoughts' of early computers as proof that they would not be overtaken by their [[Frankenstein's monster|'Frankenstein' creations]]. While [[artificial intelligence]], in terms of a replication of human intelligence, is still a remote concept, successes in certain parts of intelligence—as for example in the victories of the [[IBM Deep Blue|Deep Blue]] chess computer—have shaken mankind's certainty about its permanent place at the top of [[sapience]]. ==Reality== ===Computing power=== As [[Moore's law]] has shown, computer power has (seemingly) limitless growth potential. While there are physical constraints to the speed at which modern microprocessors can function, scientists are already developing means that might eventually supersede these limits, such as [[quantum computers]]. As [[Future studies|futurist]] and [[computer scientist]] [[Raymond Kurzweil]] has noted, "There are physical limits to computation, but they're not very limiting." If this process of growth continues, and existing problems in creating artificial intelligence are overcome, sentient machines are likely to immediately hold an enormous advantage in at least some forms of mental capability, including the capacity of [[perfect recall]], a vastly superior knowledge base, and the ability to [[Human multitasking|multitask]] in ways not possible to biological entities. This may give them the opportunity to— either as a single being or as a new [[species]] — become much more powerful than humans, and to displace them.<ref>{{cite book |last=Warwick |first=Kevin |authorlink=Kevin Warwick |title=March of the Machines: The Breakthrough in Artificial Intelligence |publisher=University of Illinois Press |year=2004 |isbn=0252072235}}</ref> ===Necessity of conflict=== For a cybernetic revolt to be inevitable, it has to be [[postulate]]d that two intelligent species cannot pursue mutually the goals of coexisting peacefully in an overlapping environment—especially if one is of much more advanced intelligence and power. While a cybernetic revolt (where the machine is the more advanced species) is thus a possible outcome of machines gaining sentience and/or [[sapience]], neither can it be disproven that a peaceful outcome is possible. The fear of a cybernetic revolt is often based on interpretations of humanity's history, which is rife with incidents of enslavement and genocide. Such fears stem from a belief that competitiveness and aggression are necessary in any intelligent being's goal system. Such human competitiveness stems from the evolutionary background to our intelligence, where the survival and reproduction of genes in the face of human and non-human competitors was the central goal.<ref>''[http://www.singinst.org/ourresearch/presentations/ Creating a New Intelligent Species: Choices and Responsibilities for Artificial Intelligence Designers]'' - [[Singularity Institute for Artificial Intelligence]], 2005</ref> In fact, an arbitrary intelligence could have arbitrary goals: there is no particular reason that an artificially-intelligent machine (not sharing humanity's evolutionary context) would be hostile—or friendly—unless its creator programs it to be such (and indeed military systems would be designed to be hostile, at least under certain circumstances). But the question remain what would happen if AI systems could interact and evolve (evolution in this context means self-modification or selection and reproduction) and need to compete over resources, would that create goals of self-preservation ? AIs goal of self-preservation could conflict them with some goals of humans. Some scientists dispute the likelihood of cybernetic revolts as depicted in science fiction such as ''[[The Matrix]]'', claiming that it is more likely that any artificial intelligences powerful enough to threaten humanity would probably be programmed not to attack it. This would not, however, protect against the possibility of a revolt initiated by terrorists, or by accident. Artificial General Intelligence researcher [[Eliezer Yudkowsky]] has stated on this note that, probabilistically, humanity is less likely to be threatened by deliberately aggressive AIs than by AIs which were programmed such that their [[unintended consequence|goals are unintentionally incompatible]] with human survival or well-being (as in the film ''[[I, Robot (film)|I, Robot]]'' and in the short story "[[The Evitable Conflict]]"). Another factor which may negate the likelihood of a cybernetic revolt is the vast difference between humans and AIs in terms of the resources necessary for survival. Humans require a "wet," organic, temperate, oxygen-laden environment while an AI might thrive essentially anywhere because their construction and energy needs would most likely be largely non-organic. With little or no competition for resources, conflict would perhaps be less likely no matter what sort of motivational architecture an artificial intelligence was given, especially provided with the superabundance of non-organic material resources in, for instance, the [[asteroid belt]]. This, however, does not negate the possibility of a disinterested or unsympathetic AI artificially [[Decomposition|decomposing]] all life on earth into mineral components for consumption or other purposes. Other scientists point 