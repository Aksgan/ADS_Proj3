and module to heuristically guess the encoding of a string.<ref>[http://gizmojo.org/code/decodeh/ Decodeh - heuristically decode a string or text file<!-- Bot generated title -->]</ref> * [[International Components for Unicode]] - A set of C and Java libraries to perform charset conversion. uconv can be used from ICU4C. * [http://chardet.feedparser.org/ chardet] - This is a translation of the [[Mozilla]] automatic-encoding-detection code into the Python computer language. * The newer versions of the unix [[File (command)|File]] command attempt to do a basic detection of character encoding. (also available on cygwin and mac) [[Linux]]: * recode – convert file contents from one encoding to another<ref>[http://www.gnu.org/software/recode/recode.html Recode - GNU Project - Free Software Foundation (FSF)<!-- Bot generated title -->]</ref> * utrac – convert file contents from one encoding to another.<ref>[http://utrac.sourceforge.net/ Utrac Homepage<!-- Bot generated title -->]</ref> * cstocs – convert file contents from one encoding to another * convmv – convert a filename from one encoding to another.<ref>[http://www.j3e.de/linux/convmv/man/ Convmv - converts filenames from one encoding to another<!-- Bot generated title -->]</ref> * enca – analyzes encodings for given text files.<ref>[http://directory.fsf.org/project/enca/ Extremely Naive Charset Analyser <!-- Bot generated title -->]</ref> [[Microsoft Windows|Windows]]: * Encoding.Convert - .NET API<ref>[http://msdn.microsoft.com/en-us/library/system.text.encoding.convert(VS.71).aspx Microsoft .NET Framework Class Library - Encoding.Convert Method]</ref> * MultiByteToWideChar/WideCharToMultiByte - Convert from ANSI to Unicode & Unicode to ANSI<ref>[http://support.microsoft.com/kb/138813 MultiByteToWideChar/WideCharToMultiByte - Convert from ANSI to Unicode & Unicode to ANSI]</ref> * cscvt – character set conversion tool<ref>[http://www.kalytta.com/tools.php Character Set Converter]</ref> == Terminology == ===Unicode encoding model=== [[Unicode]] and its parallel standard, the ISO/IEC 10646 [[Universal Character Set]], together constitute a modern, unified character encoding. Rather than mapping characters directly to octets ([[Byte|bytes]]), they separately define what characters are available, their numbering, how those numbers are encoded as a series of "code units" (limited-size numbers), and finally how those units are encoded as a stream of octets. The idea behind this decomposition is to establish a universal set of characters that can be encoded in a variety of ways.<ref name=utr17>{{cite web |url=http://www.unicode.org/reports/tr17/ |title=Unicode Technical Report #17: Unicode Character Encoding Model |date=2008-11-11 |accessdate=2009-08-08}}</ref> To correctly describe this model one needs more precise terms than "character set" and "character encoding". The terms used in the modern model follow:<ref name=utr17/> A '''character repertoire''' is the full set of abstract characters that a system supports. The repertoire may be closed, i.e. no additions are allowed without creating a new standard (as is the case with ASCII and most of the ISO-8859 series), or it may be open, allowing additions (as is the case with Unicode and to a limited extent the [[Windows code page]]s). The characters in a given repertoire reflect decisions that have been made about how to divide writing systems into linear information units. The basic variants of the [[Latin alphabet|Latin]], [[Greek alphabet|Greek]], and [[Cyrillic alphabet]]s, can be broken down into letters, digits, punctuation, and a few '''special characters''' like the space,{{citation needed|date=March 2010}} which can all be arranged in simple linear sequences that are displayed in the same order they are read. Even with these alphabets however [[diacritic]]s pose a complication: they can be regarded either as part of a single character containing a letter and diacritic (known in modern terminology as a precomposed character), or as separate characters. The former allows a far simpler text handling system but the latter allows any letter/diacritic combination to be used in text. Other writing systems, such as Arabic and Hebrew, are represented with more complex character repertoires due to the need to accommodate things like bidirectional text and [[glyph]]s that are joined together in different ways for different situations. {{anchor|CCS}} A '''coded character set''' (CCS) specifies how to represent a repertoire of characters using a number of non-negative integer codes called ''[[code point]]s''. For example, in a given repertoire, a character representing the capital letter "A" in the Latin alphabet might be assigned to the integer 65, the character for "B" to 66, and so on. A complete set of characters and corresponding integers is a coded character set. Multiple coded character sets may share the same repertoire; for example [[ISO/IEC 8859-1]] and IBM code pages 037 and 500 all cover the same repertoire but map them to different codes. In a coded character set, each code point only represents one character, i.e., a coded character set is a [[function (mathematics)|function]]. A '''character encoding form''' (CEF) specifies the conversion of a coded character set's integer codes into a set of limited-size integer ''code values'' that facilitate storage in a system that represents numbers in binary form using a fixed number of bits (i.e. practically any computer system). For example, a system that stores numeric information in 16-bit units would only be able to directly represent integers from 0 to 65,535 in each unit, but larger integers could be represented if more than one 16-bit unit could be used. This is what a CEF accommodates: it defines a way of mapping a ''single'' code ''point'' from a range of, say, 0 to 1.4 million, to a series of ''one or more'' code ''values'' from a range of, say, 0 to 65,535. The simplest CEF system is simply to choose large enough units that the values from the coded character set can be encoded directly (one code point to one code value). This works well for coded character sets that fit in 8 bits (as most legacy non-CJK encodings do) and reasonably well for coded character sets that fit in 16 bits (such as early versions of Unicode). However, as the size of the coded character set increases (e.g. modern Unicode requires at least 21 bits/character), this becomes less and less efficient, and it is difficult to adapt existing systems to use larger code values. Therefore, most systems working with later versions of Unicode use either [[UTF-8]], which maps Unicode code points to variable-length sequences of octets, or [[UTF-16/UCS-2]], which maps Unicode code points to variable-length sequences of 16-bit words. Next, a '''character encoding scheme''' (CES) specifies how the fixed-size integer code values should be mapped into an octet sequence suitable for saving on 