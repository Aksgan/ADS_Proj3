point that has a radius equal to the current nearest distance. Since the hyperplanes are all axis-aligned this is implemented as a simple comparison to see whether the difference between the splitting coordinate of the search point and current node is less than the distance (overall coordinates) from the search point to the current best. ### If the hypersphere crosses the plane, there could be nearer points on the other side of the plane, so the algorithm must move down the other branch of the tree from the current node looking for closer points, following the same recursive process as the entire search. ### If the hypersphere doesn't intersect the splitting plane, then the algorithm continues walking up the tree, and the entire branch on the other side of that node is eliminated. # When the algorithm finishes this process for the root node, then the search is complete. Generally the algorithm uses squared distances for comparison to avoid computing square roots. Additionally, it can save computation by holding the squared current best distance in a variable for comparison. ====Sample Lua - NN Search ==== <source lang="lua"> function kdsearchnn( here, point, best ) if here == nil then return best end if best == nil then best = here end -- consider the current node -- if distance(here,point) < distance(best,point) then best = here end -- search the near branch -- child = child_near(here,point) best = kdsearchnn( child, point, best ) -- search the away branch - maybe -- if distance_axis(here,point) < distance(best,point) then child = child_away(here,point) best = kdsearchnn( child, point, best ) end return best end </source> Finding the nearest point is an O(log N) operation in the case of randomly distributed points. Analyses of binary search trees has found that the worst case search time for an k-dimensional KD tree containing N nodes is given by the following equation.<ref name=Lee1977>{{Cite journal | last1 = Lee | first1 = D. T. | author1-link = Der-Tsai Lee | last2 = Wong | first2 = C. K. | year = 1977 | title = Worst-case analysis for region and partial region searches in multidimensional binary search trees and balanced quad trees | journal = Acta Informatica | volume = 9 | issue = 1 | pages = 23â€“29 | doi = 10.1007/BF00263763 }}</ref> :<math>t_{worst} = O(k \cdot N^{1-\frac{1}{k}})</math> In very high dimensional spaces, the [[curse of dimensionality]] causes the algorithm to need to visit many more branches than in lower dimensional spaces. In particular, when the number of points is only slightly higher than the number of dimensions, the algorithm is only slightly better than a linear search of all of the points. The algorithm can be extended in several ways by simple modifications. It can provide the ''k''-Nearest Neighbors to a point by maintaining k current bests instead of just one. Branches are only eliminated when they can't have points closer than any of the k current bests. It can also be converted to an approximation algorithm to run faster. For example, approximate nearest neighbour searching can be achieved by simply setting an upper bound on the number points to examine in the tree, or by interrupting the search process based upon a real time clock (which may be more appropriate in hardware implementations). Nearest neighbour for points that are in the tree already can be achieved by not updating the refinement for nodes that give zero distance as the result, this has the downside of discarding points that are not unique, but are co-located with the original search point. Approximate nearest neighbor is useful in real time applications such as robotics due to the significant speed increase gained by not searching for the best point exhaustively. One of its implementations is [[Best Bin First]]... ==High-Dimensional Data== ''k''d-trees are not suitable for efficiently finding the nearest neighbour in high dimensional spaces. As a general rule, if the dimensionality is ''k'', then number of points in the data, ''N'', should be ''N >> 2<sup>k</sup>''. Otherwise, when ''k''d-trees are used with high-dimensional data, most of the points in the tree will be evaluated and the efficiency is no better than exhaustive search,<ref>{{cite book|author=Jacob E. Goodman, Joseph O'Rourke and Piotr Indyk (Ed.) | title=Handbook of Discrete and Computational Geometry|chapter=Chapter 39 : Nearest neighbors in high-dimensional spaces|publisher=CRC Press |edition=2nd|year=2004}}</ref> and approximate nearest-neighbour methods are used instead. ==Complexity== * Building a static ''k''d-tree from ''n'' points takes [[Big O notation|O]](''n'' log <sup>2</sup> ''n'') time if an [[Big O notation|O]](''n'' log ''n'') sort is used to compute the median at each level. The complexity is [[Big O notation|O]](''n'' log ''n'') if a linear [[Selection algorithm|median-finding]] algorithm such as the one described in Cormen ''et al.''<ref>{{Introduction to Algorithms}} Chapter 10.</ref> is used. * Inserting a new point into a balanced ''k''d-tree takes O(log ''n'') time. * Removing a point from a balanced ''k''d-tree takes O(log ''n'') time. * Querying an axis-parallel range in a balanced ''k''d-tree takes O(''n''<sup>1-1/k</sup> +''m'') time, where m is the number of the reported points, and k the dimension of the ''k''d-tree. ==Variations== ===Volumetric objects=== Instead of points, a ''k''d-tree can also contain [[rectangle]]s or hyperrectangles.<ref>J. L. Bentley. [http://doi.acm.org/10.1145/361002.361007 Multidimensional binary search trees used for associative searching]. Communications of the ACM, 18(9):509-517, 1975.</ref> A 2D rectangle is considered a 4D object (x<sub>low</sub>, x<sub>high</sub>, y<sub>low</sub>, y<sub>high</sub>). Thus range search becomes the problem of returning all rectangles intersecting the search rectangle. The tree is constructed the usual way with all the rectangles at the leaves. In an [[orthogonal range search]], the ''opposite'' coordinate is used when comparing against the median. For example, if the current level is split along x<sub>high</sub>, we check the x<sub>low</sub> coordinate of the search rectangle. If the median is less than the x<sub>low</sub> coordinate of the search rectangle, then no rectangle in the left branch can ever intersect with the search rectangle and so can be pruned. Otherwise both branches should be traversed. See also [[interval tree]], which is a 1-dimensional special case. ===Points only in leaves=== It is also 