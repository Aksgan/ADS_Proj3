a labeled [[directed acyclic graph]] the nodes of which evaluate to sets of integers, the leaves are finite sets, and the gates are set operations or arithmetic operations. As an [[algorithm]]ic problem, the possible question are to find if a given integer is an element is in the output node or if two circuits compute the same set. The decidability is still an open question, but there are results on restriction of thoses circuits. Finding answers to some questions about this model could serve as a proof to many important mathematical conjectures, like [[Goldbach's conjecture]]. It is a natural extension of the [[circuits over sets of natural numbers]] when the considered set contains also negative integers, the definitions, which does not change, will not be repeated on this page. Only the differences will be mentioned. == Complexity results == === Membership problem === The membership problem ask if, given an element <math>n</math> and a circuit, if <math>n</math> is in the output gate of the circuit. When the class of authorized gate is restricted, the membership problem lay inside well kwown complexity classes<ref>{{Citation | author = Stephen Travers | title = The complexity of membership problems for circuits over sets of integers | journal =Theoretical Computer Science | volume =369 | edition= (what is called "number" in bibtex) | issue = 1 | year =2006 | issn =0304-3975 | pages =211&ndash;229 | publisher =Elsevier Science Publishers Ltd | place = Essex, UK | url = http://portal.acm.org/citation.cfm?id=1238761 }}</ref>. {| class="wikitable" style="text-align:center; width:80%;" |+ Complexity |- ! scope=col | O ! scope=col | MC<math>_{\mathbb Z}</math>(O) ! scope=col | MF<math>_{\mathbb Z}</math>(O) |- ! scope=row | ∪,∩,&minus;,+,× | [[NEXPTIME]]-hard | [[PSPACE]]-hard |- ! scope=row | ∪,∩,+,× | [[NEXPTIME]]-complete | [[NP-complete]] |- ! scope=row | ∪,+,× | [[NEXPTIME]]-complete | [[NP-complete]] |- ! scope=row | ∩,+,× | [[P (complexity)|P]]-hard, in [[co-NP]] | [[L (complexity)|L]]-hard, in [[LOGCFL]] |- ! scope=row | +,× | [[P (complexity)|P]]-hard, in [[co-NP]] | [[L (complexity)|L]]-hard, in [[LOGCFL]] |- ! scope=row | ∪,∩,&minus;,+ | [[PSPACE]]-complete | [[PSPACE]]-complete |- ! scope=row | ∪,∩,+ | [[PSPACE]]-complete | [[NP-complete]] |- ! scope=row | ∪,+ | [[NP-complete]] | [[NP-complete]] |- ! scope=row | ∩,+ | [[CL (complexity)|C<sub>=</sub>L]]-complete | [[L (complexity)|L]]-complete |- ! scope=row | + | [[CL (complexity)|C<sub>=</sub>L]]-complete | [[L (complexity)|L]]-complete |- ! scope=row | ∪,∩,&minus;,× | [[PSPACE]]-complete | [[PSPACE]]-complete |- ! scope=row | ∪,∩,× | [[PSPACE]]-complete | [[NP-complete]] |- ! scope=row | ∪,× | [[NP-complete]] | [[NP-complete]] |- ! scope=row | ∩,× | ([[CL (complexity)|C<sub>=</sub>L]]<math>\land\oplus</math>L)-hard, in [[P (complexity)|P]] | [[L (complexity)|L]]-complete |- ! scope=row | × | ([[NL (complexity)|NL]]-complete<math>\land\oplus</math>L)-complete | [[L (complexity)|L]]-complete |- ! scope=row | ∪,∩,&minus; | [[P (complexity)|P]]-complete | [[L (complexity)|L]]-complete |- ! scope=row | ∪,∩ | [[P (complexity)|P]]-complete | [[L (complexity)|L]]-complete |- ! scope=row | ∪ | [[NL (complexity)|NL]]-complete | [[L (complexity)|L]]-complete |- ! scope=row | ∩ | [[NL (complexity)|NL]]-complete | [[L (complexity)|L]]-complete |} == References == {{Reflist}} [[Category:Computational complexity theory]] [[Category:Arithmetic]]</text> </page> <page> <id>18630</id> <title>Integral transform</title> <text>In [[mathematics]], an '''integral transform''' is any [[list of transforms|transform]] ''T'' of the following form: :<math> Tf(u) = \int_{t_1}^{t_2} K(t, u)\, f(t)\, dt</math> The input of this transform is a [[function (mathematics)|function]] ''f'', and the output is another function ''Tf''. An integral transform is a particular kind of mathematical [[Operator (mathematics)|operator]]. There are numerous useful integral transforms. Each is specified by a choice of the function ''K'' of two [[Variable (mathematics)|variables]], the '''kernel function''' or '''nucleus''' of the transform. Some kernels have an associated ''inverse kernel'' <math>K^{-1}( u,t )</math> which (roughly speaking) yields an inverse transform: :<math> f(t) = \int_{u_1}^{u_2} K^{-1}( u,t )\, (Tf(u))\, du</math> A ''symmetric kernel'' is one that is unchanged when the two variables are [[Permutation|permuted]]<!--Correct link?-->. == Motivation == Mathematical notation aside, the motivation behind integral transforms is easy to understand. There are many classes of problems that are difficult to solve—or at least quite unwieldy algebraically—in their original representations. An integral transform "maps" an equation from its original "domain" into another domain. Manipulating and solving the equation in the target domain can be much easier than manipulation and solution in the original domain. The solution is then mapped back to the original domain with the inverse of the integral transform. == History == The precursor of the transforms were the [[Fourier series]] to express functions in finite intervals. Later the [[Fourier transform]] was developed to remove the requirement of finite intervals. Using the Fourier series, just about any practical function of time (the [[voltage]] across the terminals of an [[electronic device]] for example) can be represented as a sum of [[sine]]s and [[cosine]]s, each suitably scaled (multiplied by a constant factor), shifted (advanced or retarded in time) and "squeezed" or "stretched" (increasing or decreasing the frequency). The sines and cosines in the Fourier series are an example of an orthonormal basis. ==Importance of orthogonality== The individual basis functions have to be [[orthogonal]]. That is, the product of two dissimilar basis functions—integrated over their domain—must be zero. An integral transform, in actuality, just changes the representation of a function from one orthogonal basis to another. Each point in the representation of the transformed function in the target domain corresponds to the contribution of a given orthogonal basis function to the expansion. The process of expanding a function from its "standard" representation to a sum of a number of orthonormal basis functions, suitably scaled and shifted, is termed "[[spectral factorization]]." This is similar in concept to the description of a point in space in terms of three discrete components, namely, its ''x'', ''y'', and ''z'' coordinates. Each axis correlates only to itself and nothing to the other orthogonal axes. Note the terminological consistency: the determination of the amount by which an individual orthonormal basis function must be scaled in the spectral factorization of a function, ''F'', is termed the "projection" of ''F'' onto that basis function. The normal Cartesian graph ''per se'' of a function can be thought of as an orthonormal expansion. Indeed, each point just reflects the contribution of a given orthonormal basis function to the sum. Intuitively, the point (3,5) on 