to calculate the currents of the linear part, <math>I_\mbox{linear}</math> in the frequency domain. # Voltages <math>V</math> are then used to calculate the currents in the nonlinear part, <math>I_\mbox{nonlinear}</math>. Since nonlinear devices are described in the time domain, the frequency-domain voltages <math>V</math> are transformed into the time domain, typically using inverse fast Fourier transforms. The nonlinear devices are then evaluated using the time-domain voltage waveforms to produce their time-domain currents. The currents are then transformed back into the frequency domain. # According to [[Kirchhoff's current law|Kirchhoff's circuit laws]], the sum of the currents must be zero, <math>\epsilon = I_\mbox{linear} + I_\mbox{nonlinear} = 0</math>. An iterative process, usually [[Newton iteration]], is used to update the network voltages <math>V</math> such that the current residual <math>\epsilon</math> is reduced. This step requires formulation of the [[Jacobian matrix and determinant|Jacobian]] <math>\tfrac{d\epsilon}{dV}</math>. Convergence is reached when <math>\epsilon</math> is acceptably small, at which point all voltages and currents of the steady-state solution are known, most often represented as Fourier coefficients. ==References== <references /> {{DEFAULTSORT:Harmonic Balance}} [[Category:Electronic design]] [[Category:Electronic circuits]] [[Category:Electrical engineering]]</text> </page> <page> <id>16311</id> <title>Harmonic pitch class profiles</title> <text>'''Harmonic pitch class profiles (HPCP''') is a vector of features extracted from an [[audio signal]], based on the ''Pitch Class Profile'' descriptor proposed by Fujishima in the context of a chord recognition system<ref>Fujishima, T. ''Realtime chord recognition of musical sound: a system using Common Lisp Music'', ICMC, Beijing, China, 1999, pp. 464–467.</ref>. HPCP is an enhanced pitch distribution feature which are sequences of feature vectors describing [[Tonality|tonality]] measuring the intensity of each of the 12 pitch classes of the temperate scale within an analysis frame <ref>Gomez, E. Herrera, P. (2004). ''Estimating The Tonality Of Polyphonic Audio Files: Cognitive Versus Machine Learning Modelling Strategies''. ISMIR 2004 – 5th International Conference on Music Information Retrieval.</ref>. It is also called '''Chroma'''. By doing some process on musical signals, HPCP feature can be found and be used to measure pitch similarity by computed in a frame-by-frame basis, and only uses the local maxima of the [[Spectrum|spectrum]] within a certain frequency band. The process is related to [[Time-frequency analysis|time-frequency analysis]]. In general, chroma features is robust to noise (e.g., ambient noise or percussive sounds), independent of timbre and played instruments and independent of loudness and dynamics. HPCPs are tuning independent and consider the presence of harmonic frequencies, so that the reference frequency can be different from the standard A 440 Hz. The result of HPCP computation is a 12, 24, or 36-bin octave-independent [[Histogram|histogram]] depending on the desired resolution, representing the relative intensity of each 1, 1/2, or 1/3 of the 12 [[Semitone|semitones]] of the equal tempered scale. <br/> ==General HPCP feature extraction procedure== [[File:HPCP_block_diagram.jpg|thumb|Fig.1 General HPCP feature extraction block diagram]] The block diagram of the procedure is shown in '''Fig.1'''<ref>Joan Serra, Emilia Gomez, Perfecto Herrera, and Xavier Serra ''Chroma Binary Similarity and Local Alignment Applied to Cover Song Identification'' August, 2008</ref>. The General HPCP feature extraction procedure is summarized as follows:<ref>Gomez, E. ''Tonal description of polyphonic audio for music content processing''. INFORMS Journal on Computing. Special Cluster on Music Computing. Chew, E., Guest Editor, 2004.</ref> #Input musical signal. #Do '''spectral analysis''' to know the frequency components of the music signal. #Use '''[[Constant Q transform|constant Q transform]]''' to convert the signal into a spectrogram. (The constant-Q transform is a type of '''[[Time-frequency analysis|time-frequency analysis]]'''.) #Do '''[[Filter (signal processing)|frequency filtering]]'''. Only a frequency band between 100 and 5000 Hz is used. #Do '''peak detection'''. Only the local maximum values of spectrum are considered. #Do '''reference frequency computation''' procedure. Estimate the '''deviation''' with respect to 440Hz. #'''Normalize''' the feature frame by frame dividing through the maximum value in order to eliminate dependency on global loudness. And then we can get a result HPCP sequence like Fig.2. :'''Pitch class mapping''' is a procedure for determining the pitch class value from frequency values. A weighting scheme with cosine function is used. It considers the presence of harmonic frequency, taking account a total of 8 harmonics for each frequency. In order to map the value on a one-third of a [[Semitone|semitone]], the size of the pitch class distribution vectors has to be equal to '''36'''. [[File:HPCP_output.jpg|thumb|Fig.2 Example of a high-resolution HPCP sequence]] ==System of measuring similarity between two songs== [[File:Compare_songs.jpg|thumb|Fig.3 System of measuring similarity between two songs]] After getting the '''HPCP feature''', the pitch of the signal in a time section is known. The HPCP feature has been used to compute similarity between two songs in many research. A system of measuring similarity between two songs is shown in '''Fig.3'''. First, '''time-frequency analysis''' is needed to extract the HPCP feature. And then set two songs’ HPCP feature to a global HPCP, so there is a standard of comparing. The next step is to use the two features to construct a '''binary similarity matrix'''. '''[[Smith–Waterman algorithm]]''' is used to construct a local alignment matrix H in the '''Dynamic Programming Local Alignment'''. Finally, after doing post processing, the distance between two songs can be computed. <br/> ==See also== *[[Time-frequency analysis]] *[[Time-frequency analysis for music signal]] *[[Pitch]] *[[Musical theory]] ==References== {{Reflist}} {{DEFAULTSORT:Time–Frequency Analysis}} [[Category:Time–frequency analysis| ]]</text> </page> <page> <id>16316</id> <title>Harmony search</title> <text>In [[computer science]] and [[operations research]], '''harmony search''' (HS) is a phenomenon-mimicking algorithm (also known as [[metaheuristic]] [[algorithm]], [[soft computing]] algorithm or [[evolutionary algorithm]]) inspired by the improvisation process of musicians. In the HS algorithm, each musician (= decision variable) plays (= generates) a note (= a value) for finding a best harmony (= global optimum) all together. The Harmony Search algorithm has the following merits: * HS does not require differential gradients, thus it can consider discontinuous functions as well as continuous functions. * HS can handle [http://sim.sagepub.com/cgi/content/abstract/76/2/60 discrete variables] as well as [http://dx.doi.org/10.1016/j.cma.2004.09.007 continuous variables]. * HS does not require initial value setting for the variables. * HS is free from divergence. * HS may escape local optima. * HS may overcome the drawback of GA's [[Genetic_algorithms#The building_block_hypothesis|building block theory]] which works well only if the relationship among variables in a chromosome is carefully considered. If neighbor variables in a 