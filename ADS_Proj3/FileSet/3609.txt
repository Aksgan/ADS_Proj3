with subtleties of every language under the sun. Feel free to add examples here: http://en.wikibooks.org/wiki/Computer_Science_Design_Patterns/Proxy --> {{wikibooks|Computer Science Design Patterns|Proxy|Proxy implementations in various languages}} The following [[Java (programming language)|Java]] example illustrates the "virtual proxy" pattern. The <code>ProxyImage</code> class is used to access a remote method. <source lang="java"> interface Image { public abstract void displayImage(); } //on System A class RealImage implements Image { private String filename; public RealImage(String filename) { this.filename = filename; loadImageFromDisk(); } private void loadImageFromDisk() { System.out.println("Loading " + filename); } public void displayImage() { System.out.println("Displaying " + filename); } } //on System B class ProxyImage implements Image { private String filename; private RealImage image; public ProxyImage(String filename) { this.filename = filename; } public void displayImage() { if (image == null) { image = new RealImage(filename); } image.displayImage(); } } class ProxyExample { public static void main(String[] args) { Image image1 = new ProxyImage("HiRes_10MB_Photo1"); Image image2 = new ProxyImage("HiRes_10MB_Photo2"); image1.displayImage(); // loading necessary image2.displayImage(); // loading necessary image1.displayImage(); // loading unnecessary } } </source> The program's output is: Loading HiRes_10MB_Photo1 Displaying HiRes_10MB_Photo1 Loading HiRes_10MB_Photo2 Displaying HiRes_10MB_Photo2 Displaying HiRes_10MB_Photo1 ==See also== *[[Composite pattern]] *[[Decorator pattern]] *[[Lazy initialization]] ==External links== *[http://wiki.java.net/bin/view/Javapedia/ProxyPattern Proxy pattern in Java] *[http://www.lepus.org.uk/ref/companion/Proxy.xml Proxy pattern in UML and in LePUS3 (a formal modelling language)] *[http://www.javaworld.com/javaworld/jw-02-2002/jw-0222-designpatterns.html Take control with the Proxy design pattern] by [[David Geary, JavaWorld.com]] *[http://perfectjpattern.sourceforge.net/dp-proxy.html PerfectJPattern Open Source Project], Provides componentized implementation of the Proxy Pattern in Java *[http://www.netobjectives.com/PatternRepository/index.php?title=AdapterVersusProxyVersusFacadePatternComparison Adapter vs. Proxy vs. Facade Pattern Comparison] *[http://sourcemaking.com/design_patterns/proxy Proxy Design Pattern] {{Design Patterns Patterns}} [[Category:Software design patterns]] [[Category:Articles with example Java code]] [[Category:Articles with example C Sharp code]] [[ar:نمط الوكيل]] [[bg:Пълномощно (шаблон)]] [[ca:Proxy (patró de disseny)]] [[de:Stellvertreter (Entwurfsmuster)]] [[es:Proxy (patrón de diseño)]] [[fr:Proxy (patron de conception)]] [[ko:프록시 패턴]] [[it:Proxy pattern]] [[lt:Proxy (objektas)]] [[ja:Proxy パターン]] [[pl:Pełnomocnik (wzorzec projektowy)]] [[pt:Proxy (padrões de projeto)]] [[ru:Proxy (шаблон проектирования)]] [[uk:Замісник (шаблон проектування)]] [[zh:代理模式]]</text> </page> <page> <id>30416</id> <title>Pruning (decision trees)</title> <text>{{Cleanup|date=May 2008}} {{expert-subject-multiple|Mathematics|Computer science|date=August 2009}} '''Pruning''' is a technique in [[machine learning]] that reduces the size of [[Decision_tree_learning|decision tree]]s by removing sections of the tree that provide little power to classify instances. The dual goal of pruning is reduced complexity of the final classifier as well as better predictive accuracy by the reduction of [[overfitting]] and removal of sections of a classifier that may be based on [[Errors and residuals in statistics | noisy or erroneous]] data. ==Introduction== One of the questions that arises in a decision tree algorithm is the optimal size of the final tree. A tree that is too large risks [[overfitting]] the training data and poorly generalizing to new samples. A small tree might not capture important structural information about the sample space. However, it is hard to tell when a tree algorithm should stop because it is impossible to tell if the addition of a single extra node will dramatically decrease error. This problem is known as the [[horizon effect]]. A common strategy is to grow the tree until each node contains a small number of instances then use pruning to remove nodes that do not provide additional information<ref name="tib">Tevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning. Springer: 2001, pp. 269-272</ref>. Pruning should reduce the size of a learning tree without reducing predictive accuracy as measured by a test set or using [[cross-validation_(statistics)|cross-validation]]. There are many techniques for tree pruning that differ in the measurement that is used to optimize performance. ==Techniques== Pruning can occur in a top down or bottom up fashion. A top down pruning will traverse nodes and trim subtrees starting at the root, while a bottom up pruning will start at the leaf nodes. Below are several popular pruning algorithms. ===Reduced error pruning=== One of the simplest forms of pruning is reduced error pruning. Starting at the leaves, each node is replaced with its most popular class. If the prediction accuracy is not affected then the change is kept. While somewhat naive, reduced error pruning has the advantage of simplicity and speed. ===Cost complexity pruning=== Cost complexity pruning generates a series of trees <math>T_0 \dots T_m</math> where <math>T_0</math> is the initial tree and <math>T_m</math> is the root alone. At step <math>i</math> the tree is created by removing a subtree from tree <math>i-1</math> and replacing it with a leaf node with value chosen as in the tree building algorithm. The subtree that is removed is chosen as follows. Define the error rate of tree <math>T</math> over data set <math>S</math> as <math>err(T,S)</math>. The subtree that minimizes <math>\frac{err(prune(T,t),S)-\epsilon(T,S)}{|leaves(T)|-|leaves(prune(T,t)|}</math> is chosen for removal. The function <math>prune(T,t)</math> defines the tree gotten by pruning the subtrees <math>t</math> from the tree <math>T</math>. Once the series of trees has been created, the best tree is chosen by generalized accuracy as measured by a training set or cross-validation. ==See also== * [[Alpha-beta pruning]] * [[Decision_tree_learning|Decision tree]] * [[Artificial neural network]] * [[Null-move heuristic]] ==References== * Pessimistic Decision tree pruning based on Tree size<ref name=Mansour1997>{{citation | last = Mansour | first = Y. | year = 1997 | title = Pessimistic decision tree pruning based on tree size | journal = Proc. 14th International Conference on Machine Learning | pages = 195–201 | url = http://citeseer.ist.psu.edu/76752.html }}</ref> {{reflist}} ==Further reading== * MDL based decision tree pruning * Decision tree pruning using backpropagation * Neural networks ==External links== * [http://www.cis.upenn.edu/~mkearns/papers/pruning.pdf Fast, Bottom-Up Decision Tree Pruning Algorithm] * [http://www.math.tau.ac.il/~mansour/ml-course/scribe11.ps Introduction to Decision tree pruning] [[Category:Decision trees]] [[de:Pruning]] [[pt:Poda (computação)]] [[ru:Вербализация нейронных сетей]]</text> </page> <page> <id>30418</id> <title>Prussian semaphore system</title> <text>{{multiple issues|cleanup=August 2009|primarysources=August 2009|unreferenced=August 2009}} [[Image:Telegraf-flittard.jpg|thumb|Station #50 in [[Cologne]]-Flittard]] The '''Prussian Semaphore System''' was a [[telegraphy|telegraphic communications system]] used between [[Berlin]] and the [[Rhine Province]] from 1832 to 1849. It could transmit administrative and military messages by [[optical telegraph|optical signal]] over a distance of nearly {{km to mi|550}}. The telegraph line comprised 62 stations each furnished with a signal mast with six cable-operated arms. The stations were equipped with telescopes that operators used to copy coded messages and forward them to the next station. Three dispatch departments (telegraphische Expeditionen) located in [[Berlin]], [[Cologne]] and [[Koblenz]] handled the coding and decoding of official 