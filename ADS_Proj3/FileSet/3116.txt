types, respectively, as witnessed by their introduction and elimination rules. <table style="margin-left: 2em;"><tr><td> Γ, x:A {{Unicode|⊢}} π : B -------------------- ΠI Γ {{Unicode|⊢}} λx. π : Πx:A. B </td><td width="10%"></td><td> Γ {{Unicode|⊢}} π<sub>1</sub> : Πx:A. B Γ {{Unicode|⊢}} π<sub>2</sub> : A ----------------------------- ΠE Γ {{Unicode|⊢}} π<sub>1</sub> π<sub>2</sub> : [π<sub>2</sub>/x] B </td></tr></table> <table style="margin-left: 2em;"><tr><td> Γ {{Unicode|⊢}} π<sub>1</sub> : A Γ, x:A {{Unicode|⊢}} π<sub>2</sub> : B ----------------------------- ΣI Γ {{Unicode|⊢}} (π<sub>1</sub>, π<sub>2</sub>) : Σx:A. B </td><td width="10%"></td><td> Γ {{Unicode|⊢}} π : Σx:A. B ---------------- ΣE<sub>1</sub> Γ {{Unicode|⊢}} '''fst''' π : A </td><td width="10%"></td><td> Γ {{Unicode|⊢}} π : Σx:A. B ------------------------ ΣE<sub>2</sub> Γ {{Unicode|⊢}} '''snd''' π : ['''fst''' π/x] B </td></tr></table> Dependent type theory in full generality is very powerful: it is able to express almost any conceivable property of programs directly in the types of the program. This generality comes at a steep price &mdash; checking that a given program is of a given type is undecidable. For this reason, dependent type theories in practice do not allow quantification over arbitrary programs, but rather restrict to programs of a given decidable ''index domain'', for example integers, strings, or linear programs. Since dependent type theories allow types to depend on programs, a natural question to ask is whether it is possible for programs to depend on types, or any other combination. There are many kinds of answers to such questions. A popular approach in type theory is to allow programs to be quantified over types, also known as ''parametric polymorphism''; of this there are two main kinds: if types and programs are kept separate, then one obtains a somewhat more well-behaved system called ''predicative polymorphism''; if the distinction between program and type is blurred, one obtains the type-theoretic analogue of higher-order logic, also known as ''impredicative polymorphism''. Various combinations of dependency and polymorphism have been considered in the literature, the most famous being the [[lambda cube]] of [[Henk Barendregt]]. The intersection of logic and type theory is a vast and active research area. New logics are usually formalised in a general type theoretic setting, known as a [[logical framework]]. Popular modern logical frameworks such as the [[calculus of constructions]] and [[LF (logical framework)|LF]] are based on higher-order dependent type theory, with various trade-offs in terms of decidability and expressive power. These logical frameworks are themselves always specified as natural deduction systems, which is a testament to the versatility of the natural deduction approach. ==Classical and modal logics== For simplicity, the logics presented so far have been [[intuitionistic logic|intuitionistic]]. [[Classical logic]] extends intuitionistic logic with an additional [[axiom]] or principle of [[excluded middle]]: :''For any proposition p, the proposition p ∨ ¬p is true.'' This statement is not obviously either an introduction or an elimination; indeed, it involves two distinct connectives. Gentzen's original treatment of excluded middle prescribed one of the following three (equivalent) formulations, which were already present in analogous forms in the systems of [[David Hilbert|Hilbert]] and [[Arend Heyting|Heyting]]: <table style="margin-left: 2em;"><tr><td> -------------- XM<sub>1</sub> A ∨ ¬A true </td><td width="5%"></td><td> ¬¬A true ---------- XM<sub>2</sub> A true </td><td width="5%"></td><td> -------- ''u'' ¬A true {{Unicode|⋮}} ''p'' true ------ XM<sub>3</sub><sup>''u, p''</sup> A true </td></tr></table> (XM<sub>3</sub> is merely XM<sub>2</sub> expressed in terms of E.) This treatment of excluded middle, in addition to being objectionable from a purist's standpoint, introduces additional complications in the definition of normal forms. A comparatively more satisfactory treatment of classical natural deduction in terms of introduction and elimination rules alone was first proposed by [[Michel Parigot|Parigot]] in 1992 in the form of a classical [[lambda calculus]] called [[Lambda-mu calculus|λμ]]. The key insight of his approach was to replace a truth-centric judgement ''A true'' with a more classical notion, reminiscent of the [[sequent calculus]]: in localised form, instead of Γ {{Unicode|⊢}} ''A'', he used Γ {{Unicode|⊢}} Δ, with Δ a collection of propositions similar to Γ. Γ was treated as a conjunction, and Δ as a disjunction. This structure is essentially lifted directly from classical [[sequent calculus|sequent calculi]], but the innovation in λμ was to give a computational meaning to classical natural deduction proofs in terms of a [[callcc]] or a throw/catch mechanism seen in [[LISP]] and its descendants. (See also: [[first class control]].) Another important extension was for [[modal logic|modal]] and other logics that need more than just the basic judgement of truth. These were first described, for the alethic modal logics S4 and S5, in a natural deduction style by [[Dag Prawitz|Prawitz]] in 1965, and have since accumulated a large body of related work. To give a simple example, the modal logic S4 requires one new judgement, "''A valid''", that is categorical with respect to truth: :''If "A true" under no assumptions of the form "B true", then "A valid".'' This categorical judgement is internalised as a unary connective {{Unicode|◻}}''A'' (read "''necessarily A''") with the following introduction and elimination rules: <table style="margin-left: 2em;"><tr><td> A valid -------- {{Unicode|◻}}I {{Unicode|◻}} A true </td><td width="5%"></td><td> {{Unicode|◻}} A true -------- {{Unicode|◻}}E A true </td></tr></table> Note that the premise "''A valid''" has no defining rules; instead, the categorical definition of validity is used in its place. This mode becomes clearer in the localised form when the hypotheses are explicit. We write "Ω;Γ {{Unicode|⊢}} ''A true''" where Γ contains the true hypotheses as before, and Ω contains valid hypotheses. On the right there is just a single judgement "''A true''"; validity is not needed here since "Ω {{Unicode|⊢}} ''A valid''" is by definition the same as "Ω;{{Unicode|⋅}} {{Unicode|⊢}} ''A true''". The introduction and elimination forms are then: <table style="margin-left: 2em;"><tr><td> Ω;{{Unicode|⋅}} {{Unicode|⊢}} π : A true -------------------- {{Unicode|◻}}I Ω;{{Unicode|⋅}} {{Unicode|⊢}} '''box''' π : {{Unicode|◻}} A true </td><td width="5%"></td><td> Ω;Γ {{Unicode|⊢}} π : {{Unicode|◻}} A true ---------------------- {{Unicode|◻}}E Ω;Γ {{Unicode|⊢}} '''unbox''' π : A true </td></tr></table> The modal hypotheses have their own version of the hypothesis rule and substitution theorem. <table style="margin-left: 2em;"><tr><td> ------------------------------- valid-hyp Ω, u: (A valid) ; Γ {{Unicode|⊢}} u : A true </td></tr></table> ; Modal substitution theorem : ''If'' Ω;{{Unicode|⋅}} {{Unicode|⊢}} π<sub>1</sub> : ''A true'' ''and'' Ω, ''u'': (''A valid'') ; Γ {{Unicode|⊢}} 