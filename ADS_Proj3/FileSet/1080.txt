of [[data mining]] to uncover misleading relationships in data. '''Data-snooping bias''' is a form of [[statistical bias]] that arises from this [[misuse of statistics]]. Any relationships found might appear to be valid within the [[test set]] but they would have no [[statistical significance]] in the wider population. Data dredging and data-snooping bias can occur when researchers either do not form a hypothesis in advance or narrow the data used to reduce the probability of the sample refuting a specific hypothesis. Although data-snooping bias can occur in any field that uses data mining, it is of particular concern in [[finance]] and [[medical research]], both of which make heavy use of data mining techniques. The process of data mining involves automatically testing huge numbers of hypotheses about a single [[data set]] by exhaustively searching for combinations of variables that might show a correlation. Conventional tests of [[statistical significance]] are based on the probability that an observation arose by chance, and neccessarilly accept some risk of mistaken test results, called the [[statistical significance|''significance'']]. When large numbers of tests are performed, it is always expected that some will produce false results, hence 5% of randomly chosen hypotheses will turn out to be significant at the 5% level, 1% will turn out to be significant at the 1% significance level, and so on, by chance alone. If enough hypotheses are tested, it is virtually certain that some will falsely appear to be statistically significant, since every data set with any degree of randomness contains some bogus correlations. Researchers using data mining techniques can be easily misled by these apparently significant results, even though they are mere artifacts of random variation. Circumventing the traditional scientific approach of conducting an experiment without a hypothesis can lead to premature conclusions. Data mining can be used negatively to seek more information from a data set than it actually contains. Failure to adjust existing statistical models when applying them to new datasets can also result in the occurrences of new patterns between different attributes that would otherwise have not shown up. [[Overfit]]ting, [[search algorithm|oversearching]], [[estimation theory|overestimation]], and attribute [[selection error]]s are all actions that can lead to data dredging. ==Types of problem== ===Drawing conclusions from data=== The conventional [[frequency probability|frequentist]] [[statistical hypothesis testing]] procedure is to formulate a research hypothesis, such as "people in higher social classes live longer", then collect relevant data, followed by carrying out a statistical [[significance test]] to see whether the results could be due to the effects of chance. (The last step is called testing against the [[null hypothesis]]). A key point in proper statistical analysis is to test a hypothesis with evidence (data) that was not used in constructing the hypothesis. This is critical because every [[data set]] will contain some patterns due entirely to chance. If the hypothesis is not tested on a different data set from the same population, it is impossible to determine if the patterns found are chance patterns. See [[testing hypotheses suggested by the data]]. Here is a simplistic example. Throwing five coins, with a result of 2 heads and 3 tails, might lead one to ask why the coin favors tails by fifty percent. On the other hand, forming the hypothesis might lead one to conclude that only a 5-0 or 0-5 result would be very surprising, since the odds are 93.75% against this happening by chance. As a more visual example, on a cloudy day, try the experiment of looking for figures in the clouds; if one looks long enough one may see castles, cattle, and all sort of fanciful images; but the images are not really in the clouds, as can be easily confirmed by looking at other clouds. It is important to realize that the alleged statistical significance here is completely spurious â€“ significance tests do not protect against data dredging. When testing a data set on which the hypothesis is known to be true, the data set is by definition not a representative data set, and any resulting significance levels are meaningless. === Hypothesis suggested by non-representative data === {{main|Testing hypotheses suggested by the data}} In a list of 367 people, at least two will have the same day and month of birth. Suppose Mary and John both celebrate birthdays on August 7. Data snooping would, by design, try to find additional similarities between Mary and John, such as: * Are they the youngest and the oldest persons in the list? * Have they met in person once? Twice? Three times? * Do their fathers have the same first name, or mothers have the same maiden name? By going through hundreds or thousands of potential similarities between John and Mary, each having a low probability of being true, we may eventually find proof of virtually any hypothesis. Perhaps John and Mary are the only two persons in the list who switched minors three times in college, a fact we found out by exhaustively comparing their lives' histories. Our data-snooping bias hypothesis can then become, "People born on August 7 have a much higher chance of switching minors more than twice in college." The data itself very strongly supports that correlation, since no one with a different birthday had switched minors three times in college. However, when we turn to the larger sample of the general population and attempt to reproduce the results, we find that there is no statistical correlation between August 7 birthdays and changing college minors more than once. The "fact" exists only for a very small, specific sample, not for the public as a whole. === Narrowing the sample to match hypothesis === Suppose medical researchers examine a pool of data representing 10,000 lung cancer patients. They want to find information that suggests non-smokers who develop lung cancer have a better chance of survival than smokers with lung cancer do. The researchers notice that 90 percent of the patients (9,000) smoked cigarettes. About 4 percent (360 people) went into remission with no chemotherapy. Of the 10 percent (1,000) of patients who 