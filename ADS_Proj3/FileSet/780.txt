or more data managers) caused by data-access locking are resolved automatically. Thus the following corollary is concluded: *'''The CO Based Distributed Serializability Theorem''' :Let a ''distributed transactional system'' (e.g., a [[distributed database]] system) comprise ''transactional data managers'' (also called ''resource managers'') that manage all the system's ''recoverable data''. The data managers meet three conditions: # '''Data partition:''' Recoverable data are partitioned among the data managers, i.e., each recoverable datum (data item) is controlled by a single data manager (e.g., as common in a [[Shared nothing architecture]]; even copies of a same datum under different data managers are physically distinct, ''replicated''). # '''Participants in atomic commitment protocol:''' These data managers are the participants in the system's atomic commitment protocol for coordinating distributed transactions' atomicity. # '''CO compliance:''' Each such data manager is CO compliant (or some CO variant compliant; see below). :Then # The entire distributed system guarantees (distributed CO and) ''serializability'', and # Data-access based ''distributed deadlocks'' (deadlocks involving two or more data managers with at least one non-materialized conflict) are resolved automatically. :Furthermore: The data managers being CO compliant is a ''necessary condition'' for (distributed) serializability in a system meeting conditions 1, 2 above, when the data managers are ''autonomous'', i.e., do not share concurrency control information beyond unmodified messages of atomic commitment protocol. This theorem also means that when SS2PL (or any other CO variant) is used locally in each transactional data manager, and each data manager has exclusive control of its data, no distributed lock manager (which is often utilized to enforce distributed SS2PL) is needed for distributed SS2PL and serializability. It is relevant to a wide range of distributed transactional applications, which can be easily designed to meet the theorem's conditions. ===Distributed optimistic CO (DOCO)=== For implementing Distributed [[Optimistic concurrency control|Optimistic]] CO (DOCO) the [[Commitment ordering#A generic local CO algorithm|generic local CO algorithm]] above is utilized in all the atomic commitment protocol participants in the system with no data access blocking and thus with no local deadlocks. The previous theorem has the following corollary: *'''The Distributed optimistic CO (DOCO) Theorem''' :If DOCO is utilized, then: :# No local deadlocks occur, and :# Global (voting) deadlocks are resolved automatically (and all are serializability related (with non-blocking conflicts) rather than locking related (with blocking and possibly also non-blocking conflicts)). :Thus, no deadlock handling is needed. ===Examples=== ====Distributed SS2PL==== A distributed database system that utilizes [[Two-phase locking#Strong strict two-phase locking|SS2PL]] resides on two remote nodes, A and B. The database system has two ''transactional data managers'' (''resource managers''), one on each node, and the database data are partitioned between the two data managers in a way that each has an exclusive control of its own (local to the node) portion of data: Each handles its own data and locks without any knowledge on the other manager's. For each distributed transaction such data managers need to execute the available [[atomic commitment]] protocol. Two distributed transactions, <math>T_{1}</math> and <math>T_{2}</math>, are running concurrently, and both access data x and y. x is under the exclusive control of the data manager on A (B's manager cannot access x), and y under that on B. :<math>T_{1}</math> reads x on A and writes y on B, i.e., <math>T_{1} = R_{1A}(x)</math> <math>W_{1B}(y)</math> when using notation common for concurrency control. :<math>T_{2}</math> reads y on B and writes x on A, i.e., <math>T_{2} = R_{2B}(y)</math> <math>W_{2A}(x)</math> The respective ''local sub-transactions'' on A and B (the portions of <math>T_{1}</math> and <math>T_{2}</math> on each of the nodes) are the following: :{| class="wikitable" style="text-align:center;" |+Local sub-transactions |- ! Transaction \ Node !! A !! B |- ! <math>T_{1}</math> | <math>T_{1A}=R_{1A}(x)</math> || <math>T_{1B}=W_{1B}(y)</math> |- ! <math>T_{2}</math> | <math>T_{2A}=W_{2A}(x)</math> || <math>T_{2B}=R_{2B}(y)</math> |} The database system's [[Schedule (computer science)|schedule]] at a certain point in time is the following: :<math>R_{1A}(x)</math> <math>R_{2B}(y)</math> :(also <math>R_{2B}(y)</math> <math>R_{1A}(x)</math> is possible) <math>T_{1}</math> holds a read-lock on x and <math>T_{2}</math> holds read-locks on y. Thus <math>W_{1B}(y)</math> and <math>W_{2A}(x)</math> are blocked by the [[Two-phase locking#Data-access locks|lock compatibility]] rules of SS2PL and cannot be executed. This is a distributed [[deadlock]] situation, which is also a voting-deadlock (see below) with a distributed (global) cycle of length 2 (number of edges, conflicts; 2 is the most frequent length). The local sub-transactions are in the following states: :<math>T_{1A}</math> is ''ready'' (execution has ended) and ''voted'' (in atomic commitment) :<math>T_{1B}</math> is ''running'' and blocked (a non-materialized conflict situation; no vote on it can occur) :<math>T_{2B}</math> is ''ready'' and ''voted'' :<math>T_{2A}</math> is ''running'' and blocked (a non-materialized conflict; no vote). Since the atomic commitment protocol cannot receive votes for blocked sub-transactions (a voting-deadlock), it will eventually abort some transaction with a missing vote(s) by [[Timeout (computing)|timeout]], either <math>T_{1}</math>, or <math>T_{2}</math>, (or both, if the timeouts fall very close). This will resolve the global deadlock. The remaining transaction will complete running, be voted on, and committed. An aborted transaction is immediately ''restarted'' and re-executed. '''Comments:''' # The data partition (x on A; y on B) is important since without it, for example, x can be accessed directly from B. If a transaction <math>T_{3}</math> is running on B concurrently with <math>T_{1}</math> and <math>T_{2}</math> and directly writes x, then, without a [[distributed lock manager]] the read-lock for x held by <math>T_{1}</math> on A is not visible on B and cannot block the write of <math>T_{3}</math> (or signal a materialized conflict for a non-blocking CO variant; see below). Thus serializability can be violated. # Due to data partition, x cannot be accessed directly from B. However, functionality is not limited, and a transaction running on B still can issue a write or read request of x (not common). This request is communicated to the transaction's local sub-transaction on A (which is generated, if does not exist already) which issues this request to the local data manager on A. ====Variations==== In the scenario above both conflicts are ''non-materialized'', and the global voting-deadlock is reflected as a cycle in the global ''wait-for graph'' (but not in the global ''conflict graph''; see [[Commitment ordering#Exact characterization of voting-deadlocks by global cycles|Exact characterization of voting-deadlocks by global 