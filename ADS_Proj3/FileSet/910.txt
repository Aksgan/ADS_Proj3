parameter θ, θ = 0 against the alternative that <math>\theta \neq 0</math>, then this test can be performed by finding if the confidence interval for θ contains 0. More generally, given the availability of a hypothesis testing procedure that can test the null hypothesis θ = θ<sub>0</sub> against the alternative that <math>\theta \neq \theta_0</math> for any value of θ<sub>0</sub>, then a confidence interval with confidence level &gamma;= 1 &minus; α can be defined as containing any number θ<sub>0</sub> for which the corresponding null hypothesis is not rejected at significance level α.<ref name=CH7>Cox DR, Hinkley DV. (1974) Theoretical Statistics, Chapman & Hall, Section 7.2(iii)</ref> In consequence,{{clarify|date=November 2010}} if the estimates of two parameters (for example, the mean values of a variable in two independent groups of objects) have confidence intervals at a given ''&gamma;'' value that do not overlap, then the difference between the two values is [[statistical significance|significant]] at the corresponding value of ''α''. However, this test is too conservative. If two confidence intervals overlap, the difference between the two means still may be significantly different.<ref name="gh95">Goldstein, H., & Healey, M.J.R. (1995). [http://www.jstor.org/stable/view/2983411 "The graphical presentation of a collection of means."] ''Journal of the Royal Statistical Society'', '''158''', 175–77.</ref><ref>{{cite journal |author=Wolfe R, Hanley J |title=If we're so different, why do we keep overlapping? When 1 plus 1 doesn't make 2 |journal=CMAJ |volume=166 |issue=1 |pages=65–6 |year=2002 |month=Jan |pmid=11800251 |pmc=99228 |doi= |url=http://www.cmaj.ca/cgi/pmidlookup?view=long&pmid=11800251}}</ref> [[Confidence region]]s generalize the confidence interval concept to deal with multiple quantities. Such regions can indicate not only the extent of likely [[sampling error]]s but can also reveal whether (for example) it is the case that if the estimate for one quantity is unreliable then the other is also likely to be unreliable. See also [[confidence band]]s. In applied practice, confidence intervals are typically stated at the 95% confidence level.<ref>Zar, J.H. (1984) ''Biostatistical Analysis.'' Prentice Hall International, New Jersey. pp 43–45</ref> However, when presented graphically, confidence intervals can be shown at several confidence levels, for example 50%, 95% and 99%. ==Statistical theory== ===Definition=== Let ''X'' be a [[random sample]] from a [[probability distribution]] with [[parameter]]s ''θ'', which is a quantity to be estimated, and ''φ'' which are not of immediate interest. A ''confidence interval'' for the parameter ''θ'', with [[confidence level]] or [[confidence coefficient]] <math>\scriptstyle \gamma</math>, is an interval with random endpoints <math>\scriptstyle (u(X),v(X))</math>, determined by the pair of statistics (i.e., observable [[random variable]]s) <math>u(X)</math> and <math>v(X)</math>, with the property: :<math>\!\gamma={\Pr}_{\theta,\phi}(u(X)<\theta<v(X)).</math> The quantities ''φ'' in which there is no immediate interest are called [[nuisance parameter]]s, as statistical theory still needs to find some way to deal with them. The number <math>\scriptstyle \gamma</math>, with typical values close to 1 is sometimes given in the form 1 &minus; ''α'' (or as a percentage 100%·(1 &minus; ''α'')), where ''α'' is a small number, close to 0. Here Pr<sub>''θ'',''&phi;''</sub> is used to indicate the probability when the random variable ''X'' has the distribution characterised by (''θ'', ''φ''). An important part of this specification is that the random interval (''U'', ''V'') covers the unknown value θ with a high probability no matter what the true value of θ actually is. Note that here Pr<sub>''&theta;'',''&phi;''</sub> need not refer to an explicitly given parameterised family of distributions, although it often does. Just as the random variable ''X'' notionally corresponds to other possible realisations of ''x'' from the same population or from the same version of reality, the parameters (''θ'', ''φ'') indicate that we need to consider other versions of reality in which the distribution of ''X'' might have different characteristics. In a specific situation, when ''x'' is the outcome of the sample ''X'', the interval <math>(u(x),v(x))</math> is also referred to as an confidence interval for ''θ''. Note that it is no longer possible to say that the (observed) interval <math>(u(x),v(x))</math> has probability <math>\scriptstyle \gamma</math> to contain the parameter ''θ''. This observed interval is just one realization of all possible intervals for which the probability statement holds. ====Intervals for random outcomes==== Confidence intervals can be defined for random quantities as well as for fixed quantities as in the above. See [[prediction interval]]. For this, consider an additional single-valued random variable ''Y'' which may or may not be statistically dependent on ''X''. Then the rule for constructing the interval (''u''(''x''), ''v''(''x'')) provides a confidence interval for the as-yet-to-be observed value ''y'' of ''Y'' if :<math>{\Pr}_{\theta,\phi}(u(X) < Y < v(X)) = 1-\alpha\text{ for all }(\theta,\phi).\,</math> Here Pr<sub>''&theta;'',''&phi;''</sub> is used to indicate the probability over the joint distribution of the random variables (''X'', ''Y'') when this is characterised by parameters (''θ'', ''φ''). ==== Approximate confidence intervals==== For non-standard applications it is sometimes not possible to find rules for constructing confidence intervals that have exactly the required properties. But practically useful intervals can still be found. The coverage probability ''c''(''θ'', ''φ'') for a random interval is defined by :<math>{\Pr}_{\theta,\phi}(u(X)<\theta<v(X))=c(\theta,\phi)</math> and the rule for constructing the interval may be accepted as providing a confidence interval if :<math>c(\theta,\phi)\approxeq 1-\alpha\text{ for all }(\theta,\phi)\,</math> to an acceptable level of approximation. ==== Comparison to Bayesian interval estimates ==== A Bayesian interval estimate is called a [[credible interval]]. Using much of the same notation as above, the definition of a credible interval for the unknown true value of ''θ'' is, for a given ''α''<ref>{{cite book |author=Bernardo JE, Smith, Adrian |title=Bayesian theory |publisher=Wiley |location=New York |year=2000 |pages=259 |isbn=0-471-49464-X |oclc= |doi= |accessdate=}}</ref>, :<math>\Pr(u(x)<\Theta<v(x) | X = x)=1-\alpha. \, </math> Here Θ is used to emphasize that the unknown value of ''θ'' is being treated as a random variable. The definitions of the two types of intervals may be compared as follows. *The definition of a confidence interval involves probabilities calculated from the distribution of ''X'' for given (''θ'', ''φ'') (or conditional on these values) and the condition needs to hold for all values of (''θ'', ''φ''). *The definition of a credible interval involves probabilities calculated from the distribution of Θ conditional on the observed values of ''X'' = ''x'' and marginalised (or averaged) over the values of &Phi;, where this last quantity is the random variable corresponding to the uncertainty 