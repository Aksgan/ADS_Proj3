systems periodically attempt to guess which pages will soon be needed, and start loading them into RAM. There are various heuristics in use, such as ''"if a program references one virtual address which causes a page fault, perhaps the next few pages' worth of virtual address space will soon be used"'' and ''"if one big program just finished execution, leaving lots of free RAM, perhaps the user will return to using some of the programs that were recently paged out"''. === Pre-cleaning === Unix operating systems periodically use [[sync (Unix)|sync]] to pre-clean all dirty pages, that is, to save all modified pages to hard disk. Windows operating systems do the same thing via "modified page writer" threads. Pre-cleaning makes starting a new program or opening a new data file much faster. The hard drive can immediately seek to that file and consecutively read the whole file into pre-cleaned page frames. Without pre-cleaning, the hard drive is forced to seek back and forth between writing a dirty page frame to disk, and then reading the next page of the file into that frame. ==Thrashing== {{Main|Thrashing (computer science)}} Most programs reach a steady state in their demand for memory [[locality of reference|locality]] both in terms of instructions fetched and data being accessed. This steady state is usually much less than the total memory required by the program. This steady state is sometimes referred to as the [[working set]]: the set of memory pages that are most frequently accessed. Virtual memory systems work most efficiently when the ratio of the working set to the total number of pages that can be stored in RAM is low enough that the time spent resolving [[page fault]]s is not a dominant factor in the workload's performance. A program that works with huge data structures will sometimes require a working set that is too large to be efficiently managed by the page system resulting in constant page faults that drastically slow down the system. This condition is referred to as [[Thrashing (computer science)|thrashing]]: pages are swapped out and then accessed causing frequent faults. An interesting characteristic of thrashing is that as the working set grows, there is very little increase in the number of faults until the critical point (when faults go up dramatically and majority of system's processing power is spent on handling them). An extreme example of this sort of situation occurred on the [[IBM System/360 Model 67]] and [[IBM System/370]] series mainframe computers, in which a particular instruction could consist of an execute instruction, which crosses a page boundary, that the instruction points to a move instruction, that itself also crosses a page boundary, targeting a move of data from a source that crosses a page boundary, to a target of data that also crosses a page boundary. The total number of pages thus being used by this particular instruction is eight, and all eight pages must be present in memory at the same time. If the operating system will allocate less than eight pages of actual memory in this example, when it attempts to swap out some part of the instruction or data to bring in the remainder, the instruction will again page fault, and it will thrash on every attempt to restart the failing instruction. To decrease excessive paging, and thus possibly resolve thrashing problem, a user can do any of the following: * Increase the amount of RAM in the computer (generally the best long-term solution). * Decrease the number of programs being concurrently run on the computer. The term ''thrashing'' is also used in contexts other than virtual memory systems, for example to describe [[cache]] issues in computing or [[silly window syndrome]] in networking. ==Terminology== Historically, ''paging'' sometimes referred to a [[memory allocation]] scheme that used fixed-length pages as opposed to variable-length [[segmentation (memory)|segments]], without implicit suggestion that virtual memory technique were employed at all or that those pages were transferred to disk.<ref>{{Cite book | first = Harvey M. | last = Deitel | title = An Introduction to Operating Systems | publisher = Addison-Wesley | pages = 181, 187 | year = 1983 | isbn = 0201144735 | postscript = <!--None--> }}</ref> <ref>{{Cite book | contribution = Operating systems | title = Encyclopedia of computer science and technology | editor1-last = Belzer | editor1-first = Jack | editor2-last = Holzman | editor2-first = Albert G. | editor3-last = Kent | editor3-first = Allen | publisher = CRC Press | volume=11 | page = 433 | year = 1981 | url = http://books.google.com/?id=uTFirmDlSL8C&printsec=frontcover | isbn = 0824722612 | doi = 10.1002/ | postscript = <!--None--> }}</ref> Such usage is rare today. Some modern systems use the term ''swapping'' along with ''paging''. Historically, ''swapping'' referred to moving from/to secondary storage a whole program at a time, in a scheme known as [[roll-in/roll-out]]. <ref>{{Cite book | contribution = Operating systems | title = Encyclopedia of computer science and technology | editor1-last = Belzer | editor1-first = Jack | editor2-last = Holzman | editor2-first = Albert G. | editor3-last = Kent | editor3-first = Allen | publisher = CRC Press | volume=11 | page = 442 | year = 1981 | url = http://books.google.com/?id=uTFirmDlSL8C&printsec=frontcover | isbn = 0824722612 | postscript = <!--None--> }}</ref> <ref>{{Cite book | first = Harvey G. | last = Cragon | title = Memory Systems and Pipelined Processors | publisher = Jones and Bartlett Publishers | page = 109 | year = 1996 | url = http://books.google.com/?id=q2w3JSFD7l4C | isbn = 0867204745 | postscript = <!--None--> }}</ref> In the 1960s, after the concept of virtual memory was introduced&mdash;in two variants, either using segments or pages&mdash;the term ''swapping'' was applied to moving, respectively, either segments or pages, between disk and memory. Today with the virtual memory mostly based on pages, not segments, ''swapping'' became a fairly close synonym of ''paging'', although with one difference.{{Dubious|Paging vs. swapping|reason=swapping still refers to movement of an entire address space.|date=November 2010}} In many popular systems, there is a concept known as [[page cache]], of using the 