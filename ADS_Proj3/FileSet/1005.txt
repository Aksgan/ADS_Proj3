well it meets intended performance criteria. Continuing with the aircraft example, several [[World War I]] [[fighter aircraft]] designs only barely flew, while others flew well (at least one design flew well, but its wings broke off with some regularity) though with insufficient agility (turning, climbing, ..., rates) or insufficient stability (too frequent inescapable spins and so on) to be useful or survivable. To a considerable extent, good agility in aircraft is inversely related to inadequate stability, so fighter aircraft designs are, in this respect, inevitable compromises. The same considerations have continued in more recent times, as for instance the necessity for computer 'fly-by-wire' control in some fighters with great agility. Cryptographic designs also have performance goals (eg, unbreakability of encryption), but must perform in a more complex, and more complexly hostile, environment than merely high (but not too low) in the Earth's atmosphere under war conditions. Some aspects of the conditions under which crypto designs must work (to be successful and so worth bothering with) have been long recognized. Sensible cipher designers (of which there were fewer than their users would have wanted) attempted to find ways to prevent [[frequency analysis]] success, starting, it must be assumed, almost immediately after that cryptanalytic technique was first used. The most effective way to defeat frequency analysis attacks was the polyalphabetic substitution cipher, invented by [[Leon Battista Alberti|Alberti]] about 1465. For the next several hundred years, other designers also tried to evade frequency analysis, usually poorly, demonstrating that few had a clear understanding of the problem. What is probably the best known (and likely the widest used) of those attempts is the (misnamed) [[Vigenère cipher]] which is a partial implementation of Alberti's idea. [[Edgar Allan Poe]] famously, and rashly, boasted that no cipher could defeat his cryptanalytic talents (essentially frequency analysis); that he was almost entirely correct about the ciphertexts submitted to him suggests a low level of cryptographic awareness some 400 (!) years after Alberti. As this history suggests, an important part of crypto engineering is understanding the techniques the Opposition may have available. In addition, it has been explicitly realized since the mid-19th century that the Opposition must be credited with certain kinds of knowledge, lest one's design efforts address too little. [[Kerckhoffs' Law]] -- "The security of a cipher must reside entirely in the key", and the equivalent, and somewhat less obscure, [[Claude Shannon|Shannon]]'s Maxim -- "The enemy knows the system", put it more or less clearly. A crypto design must achieve its goals (eg, confidentiality, or message integrity—see 'goals' in the article [[cryptography]]), not only despite active intelligent Opposition, but in spite of uncomfortably well informed Opposition. ===Inherent zero-defect requirement=== Many failures in cryptographic engineering are catastrophic. That is, success in breaking one message leads to reading all messages. Most cryptographic algorithms and protocols make certain assumptions (random [[key (cryptography)|key]] or [[cryptographic nonce|nonce]] choices, for example), and when those assumptions are violated, all security is lost. Examples: Netscape random bug found at UC Berkeley, Microsoft's PPTP protocol implementation problems found by Schneier. ===Invisibility of most failure modes=== Success in cryptographic engineering is unclear at best. Not crashing is a quite prominent ''[[sine qua non]]'' in aircraft design. Not allowing the Opposition access (to protected message traffic, for instance) is the design goal, but it is far less obvious when this goal has been achieved than in other engineering. Essentially no Opponents will ever make their access to message content public, and so neither designers nor implementors nor users of crypto systems will ever learn from them that their design is insecure. It is certainly irrational to count on Opponents as a quality control resource. One tempting measure of security is 'I can't figure out how to break it, so I will assume Opponents will not be able to do so either'. This may be true, but there is no way to actually know your Opponents have the same limitations you do. In a modern environment, in which messages travel over public networks, it is not even possible to detect eavesdropping, much less to prevent it. Accordingly, most message traffic must be presumed to be entirely in an Opponent's possession. Known cryptographic failures fall into several classes. Future failures may also, or may find new categories. Examples include: Design errors: *cryptographic protocol errors *user operational procedure errors *algorithm implementation errors *associated system failures User errors: *misunderstanding of correct operations *arbitrary user actions Implementation errors: *programming errors (bugs) *precision arithmetic errors *[[random]] data errors *[[software library]] routine errors Environment errors: *operating system insecurities with effects on cryptographic software (eg, keys retained in [[swap file]] data) *operating system insecurities with regard to [[plaintext]] access *operating system vulnerabilities ([[viruses]], [[Trojan horse (computing)|Trojan horse]]s, etc) The effect of most of these will not be apparent to end users, generally not to the computer system's administrators, and often not even to the cryptographic system's designers. For instance, a [[buffer overflow]] vulnerability in an obligatory operating system component may not have been present in version 5.1 (used during crypto system testing), but appear only at version 5.3, available only after release of the crypto system. Or that particular vulnerability may have been removed in all operating system releases later than version 5.3, but the crytographic system is being used in this case with version 5.1. The invisibility of many such errors makes finding and removing them more difficult than in many other kinds of engineering. {{DEFAULTSORT:Cryptographic Engineering}} [[Category:Cryptography]]</text> </page> <page> <id>8627</id> <title>Cryptography in Japan</title> <text>{{Unreferenced|date=December 2009}} {{Sections|date=October 2009}} {{Essay-like|article|date=December 2007}} {{Merge|Japanese cryptology from the 1500s to Meiji|date=December 2008}} There is not much [[history of cryptography|cryptological history]] in [[Japan]] - prior to the 20th century, only a few simple codes were used and there seems to have been no practice of [[cryptanalysis]] at all. There seems to be almost no [[cryptology]] in Japan before the [[Sengoku period|Warring States Period]] (''senkokujidai''), during which [[Uesugi Kenshin]] and [[Oda Nobunaga]] are believed to have used simple [[substitution ciphers]]. In the context of world cryptological history, this is very late. [[Julius 