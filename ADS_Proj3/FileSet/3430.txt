the following functions, which demonstrate several kinds of dependencies: 1: function Dep(a, b) 2: c := a·b 3: d := 2·c 4: end function Operation 3 in Dep(a, b) cannot be executed before (or even in parallel with) operation 2, because operation 3 uses a result from operation 2. It violates condition 1, and thus introduces a flow dependency. 1: function NoDep(a, b) 2: c := a·b 3: d := 2·b 4: e := a+b 5: end function In this example, there are no dependencies between the instructions, so they can all be run in parallel. Bernstein’s conditions do not allow memory to be shared between different processes. For that, some means of enforcing an ordering between accesses is necessary, such as [[semaphore (programming)|semaphores]], [[barrier (computer science)|barriers]] or some other [[Synchronization (computer science)|synchronization method]]. ===Race conditions, mutual exclusion, synchronization, and parallel slowdown=== Subtasks in a parallel program are often called [[Thread (computer science)|threads]]. Some parallel computer architectures use smaller, lightweight versions of threads known as [[Fiber (computer science)|fibers]], while others use bigger versions known as [[Process (computing)|processes]]. However, "threads" is generally accepted as a generic term for subtasks. Threads will often need to update some [[variable (programming)|variable]] that is shared between them. The instructions between the two programs may be [[interleave]]d in any order. For example, consider the following program: {| class="wikitable" |- |Thread A |Thread B |- |1A: Read variable V |1B: Read variable V |- |2A: Add 1 to variable V |2B: Add 1 to variable V |- |3A Write back to variable V |3B: Write back to variable V |} If instruction 1B is executed between 1A and 3A, or if instruction 1A is executed between 1B and 3B, the program will produce incorrect data. This is known as a [[race condition]]. The programmer must use a [[Lock (computer science)|lock]] to provide [[mutual exclusion]]. A lock is a programming language construct that allows one thread to take control of a variable and prevent other threads from reading or writing it, until that variable is unlocked. The thread holding the lock is free to execute its [[critical section]] (the section of a program that requires exclusive access to some variable), and to unlock the data when it is finished. Therefore, to guarantee correct program execution, the above program can be rewritten to use locks: {| class="wikitable" |- |Thread A |Thread B |- |1A: Lock variable V |1B: Lock variable V |- |2A: Read variable V |2B: Read variable V |- |3A: Add 1 to variable V |3B: Add 1 to variable V |- |4A Write back to variable V |4B: Write back to variable V |- |5A: Unlock variable V |5B: Unlock variable V |} One thread will successfully lock variable V, while the other thread will be [[Software lockout|locked out]]—unable to proceed until V is unlocked again. This guarantees correct execution of the program. Locks, while necessary to ensure correct program execution, can greatly slow a program. Locking multiple variables using [[Atomic operation|non-atomic]] locks introduces the possibility of program [[deadlock]]. An atomic lock locks multiple variables all at once. If it cannot lock all of them, it does not lock any of them. If two threads each need to lock the same two variables using non-atomic locks, it is possible that one thread will lock one of them and the second thread will lock the second variable. In such a case, neither thread can complete, and deadlock results. Many parallel programs require that their subtasks [[Synchronization (computer science)|act in synchrony]]. This requires the use of a [[barrier (computer science)|barrier]]. Barriers are typically implemented using a software lock. One class of algorithms, known as [[lock-free and wait-free algorithms]], altogether avoids the use of locks and barriers. However, this approach is generally difficult to implement and requires correctly designed data structures. Not all parallelization results in speed-up. Generally, as a task is split up into more and more threads, those threads spend an ever-increasing portion of their time communicating with each other. Eventually, the overhead from communication dominates the time spent solving the problem, and further parallelization (that is, splitting the workload over even more threads) increases rather than decreases the amount of time required to finish. This is known as [[parallel slowdown]]. ===Fine-grained, coarse-grained, and embarrassing parallelism=== Applications are often classified according to how often their subtasks need to synchronize or communicate with each other. An application exhibits fine-grained parallelism if its subtasks must communicate many times per second; it exhibits coarse-grained parallelism if they do not communicate many times per second, and it is [[embarrassingly parallel]] if they rarely or never have to communicate. Embarrassingly parallel applications are considered the easiest to parallelize. ===Consistency models=== {{Main|Consistency model}} Parallel programming languages and parallel computers must have a [[consistency model]] (also known as a memory model). The consistency model defines rules for how operations on [[Computer data storage|computer memory]] occur and how results are produced. One of the first consistency models was [[Leslie Lamport]]'s [[sequential consistency]] model. Sequential consistency is the property of a parallel program that its parallel execution produces the same results as a sequential program. Specifically, a program is sequentially consistent if "... the results of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program".<ref>Lamport, Leslie (September 1979). "How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs", IEEE Transactions on Computers, C-28,9, pp. 690–91.</ref> [[Software transactional memory]] is a common type of consistency model. Software transactional memory borrows from [[Database management system|database theory]] the concept of [[Atomic commit|atomic transactions]] and applies them to memory accesses. Mathematically, these models can be represented in several ways. [[Petri net]]s, which were introduced in Carl Adam Petri's 1962 doctoral thesis, were an early attempt to codify the rules of consistency models. Dataflow theory later built upon these, and [[Dataflow architecture]]s were created to physically implement the ideas of dataflow theory. 