rows in the [[dual problem|dual linear program]]. The equivalent dual linear program of LPBoost is the following linear program. :<math>\begin{array}{cl} \underset{\boldsymbol{\lambda},\gamma}{\max} & \gamma\\ \textrm{sb.t.} & \sum_{n=1}^{\ell} y_n h(\boldsymbol{x}_n ; \omega) \lambda_n + \gamma \leq 0,\qquad \omega \in \Omega,\\ & 0 \leq \lambda_n \leq D,\qquad n=1,\dots,\ell,\\ & \sum_{n=1}^{\ell} \lambda_n = 1,\\ & \gamma \in \mathbb{R}. \end{array}</math> For [[Linear program|linear programs]] the optimal value of the primal and [[dual problem]] are equal. For the above primal and dual problems, the optimal value is equal to the negative 'soft margin'. The soft margin is the size of the margin separating positive from negative training instances minus positive slack variables that carry penalties for margin-violating samples. Thus, the soft margin may be positive although not all samples are linearly separated by the classification function. The later is called the 'hard margin' or 'realized margin'. ==== Convergence criterion ==== Consider a subset of the satisfied constraints in the dual problem. For any finite subset we can solve the linear program and thus satisfy all constraints. If we could prove that of all the constraints which we did not add to the dual problem no single constraint is violated, we would have proven that solving our restricted problem is equivalent to solving the original problem. More formally, let <math>\gamma^*</math> be the optimal objective function value for any restricted instance. Then, we can formulate a search problem for the 'most violated constraint' in the original problem space, namely finding <math>\omega^* \in \Omega</math> as :<math>\omega^* = \underset{\omega \in \Omega}{\textrm{argmax}} \sum_{n=1}^{\ell} y_n h(\boldsymbol{x}_n;\omega) \lambda_n.</math> That is, we search the space <math>\mathcal{H}</math> for a single [[decision stump]] <math>h(\cdot;\omega^*)</math> maximizing the left hand side of the dual constraint. If the constraint cannot be violated by any choice of decision stump, none of the corresponding constraint can be active in the original problem and the restricted problem is equivalent. ==== Penalization constant <math>D</math> ==== The positive value of penalization constant <math>D</math> has to be found using [[model selection]] techniques. However, if we choose <math>D=\frac{1}{\ell \nu}</math>, where <math>\ell</math> is the number of training samples and <math>0 < \nu < 1</math>, then the new parameter <math>\nu</math> has the following properties. * <math>\nu</math> is an upper bound on the fraction of training errors; that is, if <math>k</math> denotes the number of misclassified training samples, then <math>\frac{k}{\ell} \leq \nu</math>. * <math>\nu</math> is a lower bound on the fraction of training samples outside or on the margin. == Algorithm == * Input: ** Training set <math>X = \{\boldsymbol{x}_1, \dots, \boldsymbol{x}_{\ell}\}</math>, <math>\boldsymbol{x}_i \in \mathcal{X}</math> ** Training labels <math>Y = \{y_1,\dots,y_{\ell}\}</math>, <math>y_i \in \{-1,1\}</math> ** Convergence threshold <math>\theta \geq 0</math> * Output: ** Classification function <math>f: \mathcal{X} \to \{-1,1\}</math> # Initialization ## Weights, uniform <math>\lambda_n \leftarrow \frac{1}{\ell},\quad n=1,\dots,\ell</math> ## Edge <math>\gamma \leftarrow 0</math> ## Hypothesis count <math>J \leftarrow 1</math> # Iterate ## <math>\hat h \leftarrow \underset{\omega \in \Omega}{\textrm{argmax}} \sum_{n=1}^{\ell} y_n h(\boldsymbol{x}_n;\omega) \lambda_n</math> ## if <math>\sum_{n=1}^{\ell} y_n \hat h(\boldsymbol{x}_n) \lambda_n + \gamma \leq \theta</math> then ### break ## <math>h_J \leftarrow \hat h</math> ## <math>J \leftarrow J + 1</math> ## <math>(\boldsymbol{\lambda},\gamma) \leftarrow</math> solution of the LPBoost dual ## <math>\boldsymbol{\alpha} \leftarrow</math> Lagrangian multipliers of solution to LPBoost dual problem # <math>f(\boldsymbol{x}) := \textrm{sign} \left(\sum_{j=1}^J \alpha_j h_j (\boldsymbol{x})\right)</math> Note that if the convergence threshold is set to <math>\theta = 0</math> the solution obtained is the global optimal solution of the above linear program. In practise, <math>\theta</math> is set to a small positive value in order obtain a good solution quickly. ==== Realized margin ==== The actual margin separating the training samples is termed the ''realized margin'' and is defined as :<math>\rho(\boldsymbol{\alpha}) := \min_{n=1,\dots,\ell} y_n \sum_{\alpha_{\omega} \in \Omega} \alpha_{\omega} h(\boldsymbol{x}_n ; \omega).</math> The realized margin can and will usually be negative in the first iterations. For a hypothesis space that allows to single out any single sample, as is commonly the case, the realized margin will eventually converge to some positive value. ==== Convergence guarantee ==== While the above algorithm is proven to converge, in contrast to other [[Boosting]] formulations, such as [[AdaBoost]] and [[TotalBoost]], there are no known convergence bounds for LPBoost. In practise however, LPBoost is known to converge quickly, often faster than other formulations. == Base learners == LPBoost is an [[ensemble learning]] method and thus does not dictate the choice of base learners, the space of hypotheses <math>\mathcal{H}</math>. Demiriz et al. showed that under mild assumptions, any base learner can be used. If the base learners are particularly simple, they are often referred to as ''[[decision stump]]s''. The number of base learners commonly used with Boosting in the literature is large. For example, if <math>\mathcal{X} \subseteq {\mathbb R}^n</math>, a base learner could be a linear soft margin [[support vector machine]]. Or even more simple, a simple stump of the form :<math>h(\boldsymbol{x} ; \omega \in \{1,-1\}, p \in \{1,\dots,n\}, t \in {\mathbb R}) := \left\{\begin{array}{cl} \omega & \textrm{if~} \boldsymbol{x}_p \leq t\\ -\omega & \textrm{otherwise}\end{array}\right..</math> The above decision stumps looks only along a single dimension <math>p</math> of the input space and simply thresholds the respective column of the sample using a constant threshold <math>t</math>. Then, it can decide in either direction, depending on <math>\omega</math> for a positive or negative class. Given weights for the training samples, constructing the optimal decision stump of the above form simply involves searching along all sample columns and determining <math>p</math>, <math>t</math> and <math>\omega</math> in order to optimize the gain function. ==References== [http://www.boosting.org/papers/upload_27160_mlj.ps.gz Linear Programming Boosting via Column Generation], A. Demiriz and K.P. Bennett and J. Shawe-Taylor. Published 2002 in Kluwer Machine Learning 46, pages 225â€“254. [[Category:Ensemble learning]]</text> </page> <page> <id>21029</id> <title>LaFarr Stuart</title> <text>{{BLP unsourced|date=January 2011}} {{Infobox_person | image = Replace this image male.svg <!-- Only freely-licensed images may be used to depict living people. See [[WP:NONFREE]]. --> | | image_size = 150px | |name=LaFarr Stuart ||caption= |birth_date={{Birth date and age|1934|07|06}} |birth_place=[[Clarkston, Utah]], [[United States|U.S.A.]] |occupation=Computer engineer (retired) |salary= |networth= |spouse= |children= }} '''LaFarr Stuart''' (born July 6, 1934 in [[Clarkston, Utah|Clarkston]], [[Utah]]), now retired, was an early [[computer music]] pioneer, computer engineer and member of the [[Homebrew Computer Club]]. ==Career== ===Computer music=== In 1961, Stuart programmed [[Iowa 