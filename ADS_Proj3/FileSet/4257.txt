pack the SRFs. Commonly, this cache and DMA management can take up the majority of a project's schedule, something the stream processor (or at least Imagine) totally automates. Tests done at Stanford showed that the compiler did an as well or better job at scheduling memory than if you hand tuned the thing with much effort. There is proof, there can be only a lot of clusters because inter-cluster communication is assumed to be rare. Internally however, each cluster can efficiently exploit a much lower amount of ALUs because inter-cluster communication is common and thus needs to be highly efficient. To keep those ALUs fetched with data, each ALU is equipped with Local Register Files (LRFs), which are basically its usable registers. This three-tiered data access pattern, makes it easy to keep temporary data away from slow memories, thus making the silicon implementation highly efficient and power-saving. === Hardware-in-the-loop issues === {{Confusing|date=January 2008}} <!-- In a revision (as of 07:40, 8 January 2008) an user noted this was considered not relevant. Since those issues are slightly covered in the references, it seems they are. Most of the statements here can be inferred from the references while others are simply involved in using PCIe transactions (so referencing them here doesn't seem a wise idea) - keeping the tag anyway to gain more attention. --> Although an order of magnitude speedup can be reasonably expected (even from mainstream GPUs when computing in a streaming manner), not all applications benefit from this. Communication latencies are actually the biggest problem. Although [[PCI Express]] improved this with full-duplex communications, getting a GPU (and possibly a generic stream processor) to work will possibly take long amounts of time. This means it's usually counter-productive to use them for small datasets. Because changing the kernel is a rather expensive operation the stream architecture also incurs penalties for small streams, a behaviour referred to as the ''short stream effect''. [[Instruction pipeline|Pipelining]] is a very widespread and heavily-used practice on stream processors, with GPUs featuring pipelines exceeding 200 stages. The cost for switching settings is dependent on the setting being modified but it's now considered to always be expensive. To avoid those problems at various levels of the pipeline, many techniques have been deployed such as "Ã¼ber shaders" and "texture atlases". Those techniques are game-oriented because of the nature of GPUs, but the concepts are interesting for generic stream processing as well. == Notable Stream Processors == *[http://cva.stanford.edu/projects/imagine/ Imagine], headed by Professor [[Bill Dally|William Dally]] of [[Stanford University]], is a flexible architecture intended to be both fast and energy efficient. The project, originally conceived in 1996, included architecture, software tools, a VLSI implementation and a development board, was funded by [[DARPA]], [[Intel]] and [[Texas Instruments]]. * Another [[Stanford]] project called [http://merrimac.stanford.edu/ Merrimac] is aimed at developing a stream-based supercomputer. Merrimac intends to use a stream architecture and advanced interconnection networks to provide more performance per unit cost than cluster-based scientific computers built from the same technology. * The '''Storm-1''' Family from [[Stream Processors, Inc]], a commercial spinoff of Stanford's '''Imagine''' project, was announced during a feature presentation at [[ISSCC]] 2007. The family contains four members ranging from 30 GOPS to 220 16-bit GOPS (billions of operations per second), all fabricated at [[TSMC]] in a 130 nanometer process. The devices target the high end of the [[digital signal processor|DSP]] market including [[video conferencing]], [[multifunction printer]]s and digital [[video surveillance]] equipment. *[[GPU]]s are widespread, consumer-grade stream processors{{ref|GPUasSTREAM}} designed mainly by [[ATI]] (now a division of [[AMD]]) and [[Nvidia]]. Various generations to be noted from a stream processing point of view: **Pre-R2xx/NV2x: no explicit support for stream processing. Kernel operations were hidden in the [[API]] and provided too little flexibility for general use. **R2xx/NV2x: kernel stream operations became explicitly under the programmer's control but only for vertex processing (fragments were still using old paradigms). No branching support severely hampered flexibility but some types of algorithms could be run (notably, low-precision fluid simulation). **R3xx/NV4x: flexible branching support although some limitations still exist on the number of operations to be executed and strict recursion depth, as well as array manipulation. **R8xx: Supports append/consume buffers and atomic operations. This generation is the state of the art.<!-- What does this mean? It means it's a TODO. Remember we should track functionalities here rather than performance improvements. --> *The [[Cell processor]] from '''STI''', an alliance of [[Sony Computer Entertainment]], [[Toshiba Corporation]], and [[IBM]], is a hardware architecture that can function like a stream processor with appropriate software support. It consists of a controlling processor, the PPE (Power Processing Element, an IBM [[PowerPC]]) and a set of SIMD coprocessors, called SPEs (Synergistic Processing Elements), each with independent program counters and instruction memory, in effect a [[MIMD]] machine. In the native programming model all DMA and program scheduling is left up to the programmer. The hardware provides a fast ring bus among the processors for local communication. Because the local memory for instructions and data is limited the only programs that can exploit this architecture effectively either require a tiny memory footprint or adhere to a stream programming model. With a suitable algorithm the performance of the Cell can rival that of pure stream processors, however this nearly always requires a complete redesign of algorithms and software. == Stream Programming Languages == Most programming languages for stream processors start with C or C++ and add extensions which provide specific instructions to allow application developers to tag kernels and/or streams. This also applies to most [[shading language]]s, which can be considered stream programming languages to a certain degree. Non-commercial examples of stream programming languages include: * [http://www.hitech-projects.com/euprojects/ACOTES/ ACOTES] Programming Model: language from [[Polytechnic University of Catalonia]] based on [[OpenMP]] * [http://graphics.stanford.edu/projects/brookgpu/lang.html Brook] language from [[Stanford]] * [http://dupsystem.org/ DUP] language from [[Technical University of Munich]] and [[University of Denver]] * [[OpenCL]], an open standard * [[Lib Sh|Sh]] library from the [[University of Waterloo]] * [http://shallows.sourceforge.net/ Shallows], an open source project * [http://www.snet-home.org/ S-Net] coordination language from the [[University of Hertfordshire]], which provides 