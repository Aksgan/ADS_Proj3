effects. Smaller levels of α increase confidence in the determination of significance, but run an increased risk of failing to reject a false null hypothesis (a [[Type II error]], or "false negative determination"), and so have less [[statistical power]]. The selection of an α-level thus inevitably involves a compromise between significance and power, and consequently between the [[Type I error]] and the [[Type II error]]. More [[statistical power|powerful]] experiments – usually experiments with more subjects or replications – can obviate this choice to an arbitrary degree. In some fields, for example nuclear and particle physics, it is common to express statistical significance in units of "σ" (sigma), the [[standard deviation]] of a [[Gaussian distribution]]. A statistical significance of "<math>n\sigma</math>" can be converted into a value of α via use of the [[error function]]: :<math>\alpha = 1 - \operatorname{erf}\left(n/\sqrt{2}\right) \, </math> The use of σ implicitly assumes a Gaussian distribution of measurement values. For example, if a theory predicts a parameter to have a value of, say, 100, and one measures the parameter to be 109 ± 3, then one might report the measurement as a "3σ deviation" from the theoretical prediction. In terms of α, this statement is equivalent to saying that "assuming the theory is true, the likelihood of obtaining the experimental result by coincidence is 0.27%" (since 1 &minus; erf(3/√2) = 0.0027). Fixed significance levels such as those mentioned above may be regarded as useful in exploratory data analyses. However, modern statistical advice is that, where the outcome of a test is essentially the final outcome of an experiment or other study, the p-value should be quoted explicitly. And, importantly, it should be quoted whether the p-value is judged to be significant. This is to allow maximum information to be transferred from a summary of the study into [[meta-analysis|meta-analyses]]. == Pitfalls and criticism == The scientific literature contains extensive discussion of the use of the concept of statistical significance and in particular of its pitfalls and criticism of its use: see [[Statistical hypothesis testing#Pitfalls|pitfalls]] and [[Statistical hypothesis testing#Criticism|criticism]] for details of these opinions. == Signal–noise ratio conceptualisation of significance == Statistical significance can be considered to be the confidence one has in a given result. In a comparison study, it is dependent on the relative difference between the groups compared, the amount of measurement and the noise associated with the measurement. In other words, the confidence one has in a given result being non-random (i.e. it is not a consequence of [[Randomness|chance]]) depends on the [[signal-to-noise ratio]] (SNR) and the sample size. Expressed mathematically, the confidence that a result is not by random chance is given by the following formula by Sackett:<ref>{{cite journal |author=Sackett DL |title=Why randomized controlled trials fail but needn't: 2. Failure to employ physiological statistics, or the only formula a clinician-trialist is ever likely to need (or understand!) |journal=CMAJ |volume=165 |issue=9 |pages=1226–37 |year=2001 |month=October |pmid=11706914 |pmc=81587 |doi= |url=http://www.cmaj.ca/cgi/pmidlookup?view=long&pmid=11706914}}</ref> :<math>\mathrm{confidence} = \frac{\mathrm{signal}}{\mathrm{noise}} \times \sqrt{\mathrm{sample\ size}}.</math> For clarity, the above formula is presented in tabular form below. '''Dependence of confidence with noise, signal and sample size (tabular form)''' {| class="wikitable" !Parameter !Parameter increases !Parameter decreases |- |Noise |Confidence decreases |Confidence increases |- |Signal |Confidence increases |Confidence decreases |- |Sample size |Confidence increases |Confidence decreases |} In words, the dependence of confidence is high if the noise is low and/or the sample size is large and/or the [[effect size]] (signal) is large. The confidence of a result (and its associated [[confidence interval]]) is ''not'' dependent on effect size alone. If the sample size is large and the noise is low a small effect size can be measured with great confidence. Whether a small effect size is considered important is dependent on the context of the events compared. In medicine, small effect sizes (reflected by small increases of risk) are often considered clinically relevant and are frequently used to guide treatment decisions (if there is great confidence in them). Whether a given treatment is considered a worthy endeavour is dependent on the risks, benefits and costs. ==See also== {{Portal|Statistics}} {{Wikiversity}} * [[Statistical hypothesis testing]] * [[A/B testing]] * [[ABX test]] * [[Fisher's method]] for combining [[statistical independence|independent]] [[statistical hypothesis testing|test]]s of significance * [[Legal burden of proof|Reasonable doubt]] ==References== {{Reflist}} ==Further reading== *Ziliak, Stephen, and McCloskey, Deirdre, (2008). ''[http://www.press.umich.edu/titleDetailDesc.do?id=186351 The Cult of Statistical Significance: How the Standard Error Costs Us Jobs, Justice, and Lives]''. Ann Arbor, [[University of Michigan Press]], 2009. *Thompson, Bruce, (2004). The "significance" crisis in psychology and education. ''Journal of Socio-Economics'', 33, pp. 607–613. * Chow, Siu L. , (1996). ''Statistical Significance: Rationale, Validity and Utility,'' Volume 1 of series ''Introducing Statistical Methods,'' Sage Publications Ltd, ISBN 978-0-76195205-3 – argues that statistical significance is useful in certain circumstances ==External links== * [http://jeff560.tripod.com/s.html Earliest Uses: The entry on Significance has some historical information.] * Raymond Hubbard, M.J. Bayarri, ''[http://ftp.isds.duke.edu/WorkingPapers/03-26.pdf P Values are not Error Probabilities]''. A working paper that explains the difference between Fisher's evidential p-value and the Neyman-Pearson Type I error rate <math>\alpha</math>. *[http://www.ericdigests.org/1995-1/testing.htm The Concept of Statistical Significance Testing] – Article by Bruce Thompon of the ERIC Clearinghouse on Assessment and Evaluation, Washington, D.C. {{Statistics}} {{DEFAULTSORT:Statistical Significance}} [[Category:Hypothesis testing]] [[ca:Significació estadística]] [[da:Signifikansniveau]] [[de:Statistische Signifikanz]] [[es:Significancia estadística]] [[fa:معناداری آماری]] [[fr:Statistiquement significatif]] [[ko:통계적 유의성]] [[it:Significatività]] [[he:מובהקות סטטיסטית]] [[lt:Reikšmingumo lygmuo]] [[nl:Significantie]] [[ja:有意]] [[no:Statistisk signifikans]] [[pl:Poziom istotności]] [[pt:Significância estatística]] [[ru:Статистическая значимость]] [[fi:Tilastollinen merkitsevyys]] [[sv:Signifikans]] [[th:นัยสำคัญทางสถิติ]] [[tr:Anlamlılık seviyesi]] [[zh:显著性差异]]</text> </page> <page> <id>35672</id> <title>Statsit</title> <text>{{unreferenced|date=August 2010}} {{Infobox Company | name = Statsit | type = [[social media]] | foundation = 2008 | founder = Mikko Kotila, Juha Rantala | location_city = [[Kuala Lumpur]] | location_country = [[Malaysia]] | services = Social Media Monitoring | num_employees = 15 | homepage = http://www.statsit.com/ }} '''Statsit''' is a social media monitoring and insight company founded in 2008, based in Kuala Lumpur, Malaysia. The company specializes in measuring the effectiveness of marketing activities and providing brand insights via comments and conversations on social media sites including [[blogs]], [[forums]], [[Twitter]], [[Facebook]] and [[Digg]] to [[advertising agencies]]. Statsit's clients include leading media, PR and advertising agencies, publishers 