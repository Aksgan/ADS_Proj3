Council <ref>[http://www-306.ibm.com/software/tivoli/governance/servicemanagement/data-governance.html IBM Data Governance<!-- Bot generated title -->]</ref> :The IBM Data Governance Council is an organization formed by IBM consisting of companies, institutions and technology solution providers with the stated objective to build consistency and quality control in governance, which will help companies better protect critical data." ;The Data Governance and Stewardship Community of Practice (DGS-COP)<ref>[http://www.datastewardship.com The Data Governance & Stewardship Community of Practice<!-- Bot generated title -->]</ref> :The Data Governance and Stewardship Community of Practice is a vendor-neutral organization open to practitioners, stakeholders and academics, as well as vendors and consultants. The DGS-COP offers a large collection of data governance artifacts to members including case studies, metrics, dashboards, and maturity models as well as on-line events. ;Data Governance Conferences :Two major conferences are held annually, the Data Governance Conference, held in the USA<ref>[http://dg-conference.com/ Data Governance Conference<!-- Bot generated title -->]</ref>, and the Data Governance Conference Europe<ref>[http://www.irmuk.co.uk/dg2010/ Data Governance Conference Europe<!-- Bot generated title -->]</ref>, held in London, England. ;Master Data Management & Data Governance Conferences<ref>[http://www.tcdii.com/events/cdimdmsummitseries.html MDM SUMMIT Conference<!-- Bot generated title -->]</ref> :Six major conferences are held annually, London, San Francisco, Sydney and Toronto in the spring, and Madrid, Frankfurt, and New York City in the fall. 2009 was the 4th annual iteration with more than 2,000 attendees per year receiving their data governance and master data management updates via this 2-3 day event. ==See also== * [[Information technology governance]] * [[Semantics of Business Vocabulary and Business Rules]] * [[Master data management]] * [[COBIT]] * [[ISO/IEC 38500]] * [[ISO/TC 215]] * [[Operational risk management]] * [[Basel II Accord]] * [[HIPAA]] * [[Sarbanes-Oxley Act]] * [[Information technology controls]] * [[Data Protection Directive]] (EU) ==References== <!--See http://en.wikipedia.org/wiki/Wikipedia:Footnotes for an explanation of how to generate footnotes using the <ref(erences/)> tags--> <!--to cite a web resource, use this template <ref>{{cite web | url = MANDATORY | title = MANDATORY | last = | first = | authorlink = | coauthors = | work = | publisher = | date = | format = | language= | doi = | accessdate = | archiveurl = SHOULD BE USED ON PAGES ALLOWING ARCHIVING - USE A SERVICE LIKE webcitation.org or archive.org | archivedate = MANDATORY IF archiveurl | quote = }}</ref> --> {{reflist|1}} [[Category:Information technology governance]] [[Category:Data management]]</text> </page> <page> <id>9390</id> <title>Data masking</title> <text>{{Refimprove|date=July 2009}} {{Cleanup|date=September 2009}} '''Data masking''' is the process of obscuring (masking) specific data elements within data stores. It ensures that sensitive data is replaced with realistic but not real data. The goal is that sensitive customer information is not available outside of the authorized environment. Data masking is typically done while provisioning non-production environments so that copies created to support test and development processes are not exposing sensitive information and thus avoiding risks of [[data breach |leaking]]. Masking algorithms are designed to be repeatable so referential integrity is maintained. Common business applications require constant patch and upgrade cycles and require that 6-8 copies of the application and data be made for testing. While organizations typically have strict controls on production systems, data security in non-production instances is often left up to trusting the employee, with potentially disastrous results. Creating test and development copies in an automated process reduces the exposure of sensitive data. Database layout often changes, it is useful to maintain a list of sensitive columns in a without rewriting application code. Data masking is an effective strategy in reducing the risk of data exposure from inside and outside of an organization and should be considered a best practice for curing non-production databases. ==Requirements== Effective data masking requires data to be altered in a way that the actual values cannot be determined or reengineered, functional appearance is maintained, so effective testing is possible. Data can be encrypted and decrypted, relational integrity is maintained, security polices can be established and separation of duties between security and administration established. Common methods of data masking includes: encryption/decryption, shuffling, masking (i.e. numbers letters), [[substitution]] (i.e. All female names = Julie), [[nulling]] (####) or [[shuffling]] (zip code12345 = 53412). ==Data Masking Techniques== ===Substitution=== The Substitution technique replaces the existing data with random values from a pre-prepared dataset. ===Shuffling=== The Shuffling technique uses the existing data as its own substitution dataset and moves the values between rows in such a way that the no values are present in their original rows. ===Number and Date Variance=== The Number and Date Variance technique varies the existing values in a specified range in order to obfuscate them. For example, birth date values could be changed within a range of +/- 60 days. ===Encryption=== The Encryption technique algorythmically scrambles the data. This usually does not leave the data looking realistic and can sometimes make the data larger. ===Nulling Out Or Deletion=== The Nulling Out technique simply removes the sensitive data by deleting it. ===Masking Out=== The Masking Out technique sanitizes the data by replacing certain specified characters with mask characters. For example, a credit card number might be masked as 4929 1344 XXXX XXXX. ===Row-Internal Synchronization=== If a row in a database table contains denormalized data derived from other columns in that row and those columns are masked then the denormalized data row will need to be rebuilt. This technique is called Row-Internal Synchronization. ===Table-Internal Synchronization=== If a database table contains multiple rows containing identical columns and those columns are masked then the denormalized data rows will need to be set to the same value. This technique is called Table-Internal Synchronization. ===Table-To-Table Synchronization=== If two tables contain the columns with the same denormalized data values and those columns are masked in one table then the second table will need to be updated with the changes. This technique is called Table-To-Table Synchronization. ==References== {{reflist}} == External links == * [http://www.DataMasker.com/DataMasking_WhatYouNeedToKnow.pdf Data Masking - What You Need To Know Before You Begin] {{DEFAULTSORT:Data Masking}} [[Category:Database management systems]] [[Category:Databases]] [[cs:Maskování dat]]</text> </page> <page> <id>9393</id> <title>Data mining agent</title> <text>{{Wikify|date=November 2009}} [[Image:PDMA.jpg|thumb|280px|Diagram of Parallel Data Mining Agents]] A '''data mining agent''' is a software program built for the primary purpose of finding information efficiently. 