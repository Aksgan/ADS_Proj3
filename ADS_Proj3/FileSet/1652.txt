statistically independent and equally efficient in different parameter directions. This condition may be approximately fulfilled when the moment matrix of the Gaussian has been adapted for maximum [[average information]] to some region of acceptability, because linear transformations of the whole process do not have an impact on efficiency. 2 All individuals have equal cost and the derivative at ''P'' = 1 is < 0. Then, the following theorem may be proved: <blockquote>All measures of efficiency, that satisfy the conditions above, are asymptotically proportional to –''P'' log(''P/q'') when the number of dimensions increases, and are maximized by ''P'' = ''q'' exp(-1) (Kjellström, 1996 and 1999).</blockquote> [[Image:Efficiency.GIF]] The figure above shows a possible efficiency function for a random search process such as Gaussian adaptation. To the left the process is most chaotic when ''P'' = 0, while there is perfect order to the right where ''P'' = 1. In an example by Rechenberg, 1971, 1973, a random walk is pushed thru a corridor maximizing the parameter ''x''<sub>1</sub>. In this case the region of acceptability is defined as a (''n'' &minus; 1)-dimensional interval in the parameters ''x''<sub>2</sub>, ''x''<sub>3</sub>, ..., ''x''<sub>''n''</sub>, but a ''x''<sub>1</sub>-value below the last accepted will never be accepted. Since ''P'' can never exceed 0.5 in this case, the maximum speed towards higher ''x''<sub>1</sub>-values is reached for ''P'' = 0.5/''e'' = 0.18, in agreement with the findings of Rechenberg. A point of view that also may be of interest in this context is that no definition of information (other than that sampled points inside some region of acceptability gives information about the extension of the region) is needed for the proof of the theorem. Then, because, the formula may be interpreted as information divided by the work needed to get the information, this is also an indication that &minus;log(''P'') is a good candidate for being a measure of information. ==The Stauffer and Grimson algorithm== Gaussian adaptation has also been used for other purposes as for instance shadow removal by "The Stauffer-Grimson algorithm" which is equivalent to Gaussian adaptation as used in the section "Computer simulation of Gaussian adaptation" above. In both cases the maximum likelihood method is used for estimation of mean values by adaptation at one sample at a time. But there are differences. In the Stauffer-Grimson case the information is not used for the control of a random number generator for centering, maximization of mean fitness, [[average information]] or manufacturing yield. The adaptation of the moment matrix also differs very much as compared to "the evolution in the brain" above. ==See also== * [[Entropy in thermodynamics and information theory]] * [[Fisher's fundamental theorem of natural selection]] * [[Free will]] * [[Genetic algorithm]] * [[Hebbian learning]] * [[Information content]] * [[Simulated annealing]] * [[Stochastic optimization]] * [[CMA-ES|Covariance matrix adaptation evolution strategy (CMA-ES)]] * [[Unit of selection]] ==References== *Bergström, R. M. An Entropy Model of the Developing Brain. ''[[Developmental Psychobiology]]'', 2(3): 139&ndash;152, 1969. *Brooks, D. R. & Wiley, E. O. ''Evolution as Entropy, Towards a unified theory of Biology''. The University of Chicago Press, 1986. *Brooks, D. R. Evolution in the Information Age: Rediscovering the Nature of the Organism. Semiosis, Evolution, Energy, Development, Volume 1, Number 1, March 2001 *Gaines, Brian R. Knowledge Management in Societies of Intelligent Adaptive Agents. ''Journal of intelligent Information systems'' 9, 277&ndash;298 (1997). *Hartl, D. L. ''A Primer of Population Genetics''. Sinauer, Sunderland, Massachusetts, 1981. *Hamilton, WD. 1963. The evolution of altruistic behavior. American Naturalist 97:354&ndash;356 *Kandel, E. R., Schwartz, J. H., Jessel, T. M. ''Essentials of Neural Science and Behavior''. Prentice Hall International, London, 1995. *S. Kirkpatrick and C. D. Gelatt and M. P. Vecchi, Optimization by Simulated Annealing, Science, Vol 220, Number 4598, pages 671&ndash;680, 1983. *Kjellström, G. Network Optimization by Random Variation of component values. ''Ericsson Technics'', vol. 25, no. 3, pp. 133&ndash;151, 1969. *Kjellström, G. Optimization of electrical Networks with respect to Tolerance Costs. ''Ericsson Technics'', no. 3, pp. 157&ndash;175, 1970. *Kjellström, G. & Taxén, L. Stochastic Optimization in System Design. IEEE Trans. on Circ. and Syst., vol. CAS-28, no. 7, July 1981. *Kjellström, G., Taxén, L. and Lindberg, P. O. Discrete Optimization of Digital Filters Using Gaussian Adaptation and Quadratic Function Minimization. IEEE Trans. on Circ. and Syst., vol. CAS-34, no 10, October 1987. *Kjellström, G. On the Efficiency of Gaussian Adaptation. ''Journal of Optimization Theory and Applications'', vol. 71, no. 3, December 1991. *Kjellström, G. & Taxén, L. Gaussian Adaptation, an evolution-based efficient global optimizer; Computational and Applied Mathematics, In, C. Brezinski & U. Kulish (Editors), Elsevier Science Publishers B. V., pp 267&ndash;276, 1992. *Kjellström, G. Evolution as a statistical optimization algorithm. ''Evolutionary Theory'' 11:105&ndash;117 (January, 1996). *Kjellström, G. The evolution in the brain. ''Applied Mathematics and Computation'', 98(2&ndash;3):293&ndash;300, February, 1999. *Kjellström, G. Evolution in a nutshell and some consequences concerning valuations. EVOLVE, ISBN 91-972936-1-X, Stockholm, 2002. *Levine, D. S. Introduction to Neural & Cognitive Modeling. Laurence Erlbaum Associates, Inc., Publishers, 1991. *MacLean, P. D. ''A Triune Concept of the Brain and Behavior''. Toronto, Univ. Toronto Press, 1973. *Maynard Smith, J. 1964. Group Selection and Kin Selection, Nature 201:1145&ndash;1147. *Maynard Smith, J. ''Evolutionary Genetics''. Oxford University Press, 1998. *Mayr, E. ''What Evolution is''. Basic Books, New York, 2001. *Müller, Christian L. and Sbalzarini Ivo F. Gaussian Adaptation revisited - an entropic view on Covariance Matrix Adaptation. Institute of Theoretical Computer Science and Swiss Institute of Bioinformatics, ETH Zurich, CH-8092 Zurich, Switzerland. *Pinel, J. F. and Singhal, K. Statistical Design Centering and Tolerancing Using Parametric Sampling. IEEE Transactions on Circuits and Systems, Vol. Das-28, No. 7, July 1981. *Rechenberg, I. (1971): Evolutionsstrategie &mdash; Optimierung technischer Systeme nach Prinzipien der biologischen Evolution (PhD thesis). Reprinted by Fromman-Holzboog (1973). *Ridley, M. ''Evolution''. Blackwell Science, 1996. *Stauffer, C. & Grimson, W.E.L. Learning Patterns of Activity Using Real-Time Tracking, IEEE Trans. on PAMI, 22(8), 2000. *Stehr, G. On the Performance Space Exploration of Analog Integrated Circuits. Technischen Universität Munchen, Dissertation 2005. *Taxén, L. A Framework for the Coordination of Complex Systems’ Development. Institute of Technology, Linköping University, Dissertation, 2003. *Zohar, D. ''The quantum self : 