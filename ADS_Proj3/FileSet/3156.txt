Taylor]] (Dept. of Mathematics, King's College, University of London, UK). '' Neural Networks'' is abstracted and indexed in [[Scopus]] and [[Science Citation Index]]. According to the 2008 [[Journal Citation Reports]] its [[impact factor]] is 2.656 and the 5-year impact factor is 2.838. ==References== {{Reflist}} [[Category:Neural networks]] [[Category:Artificial intelligence publications]] [[Category:Elsevier academic journals]] [[Category:Publications with year of establishment missing]] [[Category:Neuroscience journals]] {{journal-stub}}</text> </page> <page> <id>26242</id> <title>Neural Workflow</title> <text>{{Orphan|date=November 2006}} '''Neural Workflow''' is a concept for a [[workflow]] system to be used in [[Computer software|software]], which is based upon the [[neuron|neural]] function of a [[human brain]] as opposed to a more traditional workflow system. In a neural workflow system, the following holds true: # There are no sources or sinks. # All nodes or gates may have the ability to action or be actioned by any other gate or node. # Actions or stimuli which cause flows to be unresolved are placed in a 'too hard' status until the system or an administrator creates a series of nodes to resolve these stimuli. # The system tracks which stratagems or node pathways most successfully resolve a stimuli with a given or partially given set of characteristics. ==External links== *[http://workflow.wordpress.com/2006/02/28/neural-workflow/ Workflow Blog article] {{Soft-eng-stub}} [[Category:Workflow technology]]</text> </page> <page> <id>26252</id> <title>Neural modeling fields</title> <text>'''Neural modeling field (NMF)''' is a mathematical framework for [[machine learning]] which combines ideas from [[neural networks]], [[fuzzy logic]], and [[model based recognition]]. It has also been referred to as '''modeling fields''', '''modeling fields theory''' (MFT), '''Maximum likelihood artificial neural networks''' (MLANS). <ref>[http://www.oup.com/us/catalog/he/subject/Engineering/ElectricalandComputerEngineering/ComputerEngineering/NeuralNetworks/?view=usa&ci=9780195111620]: Perlovsky, L.I. 2001. Neural Networks and Intellect: using model based concepts. New York: Oxford University Press</ref> <ref> Perlovsky, L.I. (2006). Toward Physics of the Mind: Concepts, Emotions, Consciousness, and Symbols. Phys. Life Rev. 3(1), pp.22-55.</ref> <ref>[http://ieeexplore.ieee.org/xpl/absprintf.jsp?arnumber=713700&page=FREE]: Deming, R.W., Automatic buried mine detection using the maximum likelihoodadaptive neural system (MLANS), in Proceedings of ''Intelligent Control (ISIC)'', 1998. Held jointly with ''IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA), Intelligent Systems and Semiotics (ISAS)''</ref> <ref>[http://www.mdatechnology.net/techprofile.aspx?id=227 ]: MDA Technology Applications Program web site</ref> <ref>[http://ieeexplore.ieee.org/search/wrapper.jsp?arnumber=4274797]: Cangelosi, A.; Tikhanoff, V.; Fontanari, J.F.; Hourdakis, E., Integrating Language and Cognition: A Cognitive Robotics Approach, Computational Intelligence Magazine, IEEE, Volume 2, Issue 3, Aug. 2007 Page(s):65 - 70</ref> <ref>[http://spie.org/x648.xml?product_id=521387&showAbstracts=true&origin_id=x648]: Sensors, and Command, Control, Communications, and Intelligence (C3I) Technologies for Homeland Security and Homeland Defense III (Proceedings Volume),Editor(s): Edward M. Carapezza, Date: 15 September 2004,ISBN 9780819453266, See Chapter: ''Counter-terrorism threat prediction architecture''</ref> This framework has been developed by [[Leonid Perlovsky]] at the [[AFRL]]. NMF is interpreted as a mathematical description of mindâ€™s mechanisms, including [[concepts]], [[emotions]], [[instincts]], [[imagination]], [[thinking]], and [[understanding]]. NMF is a multi-level, hetero-hierarchical system. At each level in NMF there are concept-models encapsulating the knowledge; they generate so-called top-down signals, interacting with input, bottom-up signals. These interactions are governed by dynamic equations, which drive concept-model learning, adaptation, and formation of new concept-models for better correspondence to the input, bottom-up signals. ==Concept models and similarity measures== In the general case, NMF system consists of multiple processing levels. At each level, output signals are the concepts recognized in (or formed from) input, bottom-up signals. Input signals are associated with (or recognized, or grouped into) concepts according to the models and at this level. In the process of learning the concept-models are adapted for better representation of the input signals so that similarity between the concept-models and signals increases. This increase in similarity can be interpreted as satisfaction of an instinct for knowledge, and is felt as [[aesthetic emotions]]. Each hierarchical level consists of N "neurons" enumerated by index n=1,2..N. These neurons receive input, bottom-up signals, '''X(n)''', from lower levels in the processing hierarchy. '''X'''(n) is a field of bottom-up neuronal synaptic activations, coming from neurons at a lower level. Each neuron has a number of synapses; for generality, each neuron activation is described as a set of numbers, :<math> \vec X(n) = \{ X_d(n) \}, d = 1..D.</math> ,where D is the number or dimensions necessary to describe individual neuron's activation. Top-down, or priming signals to these neurons are sent by concept-models, '''M'''<sub>m</sub>('''S'''<sub>m</sub>,n) :<math> \vec M_m(\vec S_m, n), m = 1..M.</math> ,where M is the number of models. Each model is characterized by its parameters, '''S<sub>m</sub>'''; in the neuron structure of the brain they are encoded by strength of synaptic connections, mathematically, they are given by a set of numbers, :<math> \vec S_m = \{ S_m^a \}, a = 1..A.</math> ,where A is the number of dimensions necessary to describe invividual model. Models represent signals in the following way. Suppose that signal '''X(''n'')''' is coming from sensory neurons n activated by object m, which is characterized by parameters '''S<sub>m</sub>'''. These parameters may include position, orientation, or lighting of an object m. Model '''M<sub>m</sub>'''('''S<sub>m</sub>''',n) predicts a value '''X'''(n) of a signal at neuron n. For example, during visual perception, a neuron n in the visual cortex receives a signal '''X'''(n) from retina and a [[priming]] signal '''M<sub>m</sub>'''('''S<sub>m</sub>''',n) from an object-concept-model ''m''. Neuron ''n'' is activated if both the bottom-up signal from lower-level-input and the top-down priming signal are strong. Various models compete for evidence in the bottom-up signals, while adapting their parameters for better match as described below. This is a simplified description of perception. The most benign everyday visual perception uses many levels from retina to object perception. The NMF premise is that the same laws describe the basic interaction dynamics at each level. Perception of minute features, or everyday objects, or cognition of complex abstract concepts is due to the same mechanism described below. Perception and cognition involve concept-models and learning. In perception, concept-models correspond to objects; in cognition models correspond to relationships and situations. Learning is an essential part of perception and cognition, and in NMF theory it is driven by the dynamics that increase a similarity measure between the sets of models and signals, L({'''X'''},{'''M'''}). The similarity measure is a function of model parameters and associations between the input bottom-up signals and top-down, concept-model signals. In constructing a mathematical description of the similarity measure, it is important to acknowledge two principles: 