that its critics cite but feels that, in contrast, the Original Imitation Game Test (OIG Test) so defined is immune to many of them, due to a crucial difference: Unlike the STT, it does not make similarity to human performance the criterion, even though it employs human performance in setting a criterion for machine intelligence. A man can fail the OIG Test, but it is argued that it is a virtue of a test of intelligence that failure indicates a lack of resourcefulness: The OIG Test requires the resourcefulness associated with intelligence and not merely "simulation of human conversational behaviour." The general structure of the OIG Test could even be used with non-verbal versions of imitation games.<ref>{{Harvnb|Sterrett|2000}}</ref> Still other writers<ref>{{Harvnb|Genova|1994}}, {{Harvnb|Hayes|Ford|1995}}, {{Harvnb|Heil|1998}}, {{Harvnb|Dreyfus|1979}}</ref> have interpreted Turing as proposing that the imitation game itself is the test, without specifying how to take into account Turing's statement that the test that he proposed using the party version of the imitation game is based upon a criterion of comparative frequency of success in that imitation game, rather than a capacity to succeed at one round of the game. Saygin has suggested that maybe the original game is a way of proposing a less biased experimental design as it hides the participation of the computer.<ref>R.Epstein, G. Roberts, G. Poland, (eds.) Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer. Springer: Dordrecht, Netherlands</ref> ===Should the interrogator know about the computer?=== Turing never makes clear whether the interrogator in his tests is aware that one of the participants is a computer. To return to the Original Imitation Game, he states only that player A is to be replaced with a machine, not that player C is to be made aware of this replacement.<ref name=T434 /> When Colby, FD Hilf, S Weber and AD Kramer tested PARRY, they did so by assuming that the interrogators did not need to know that one or more of those being interviewed was a computer during the interrogation.<ref>{{harvnb|Colby|Hilf|Weber|Kraemer|1972}}</ref> As Ayse Saygin and others have highlighted, this makes a big difference to the implementation and outcome of the test.<ref name="Saygin 2000"/> Huma Shah & [[Kevin Warwick]], who have organised practical Turing tests, argue knowing/not knowing ''may'' make a difference in some judges' verdict. Judges in the finals of the parallel-paired Turing tests, staged in the [http://www.loebner.net/Prizef/2008_Contest/loebner-prize-2008.html 18th Loebner Prize] were not explicitly told, some did assume each hidden pair contained one human and one machine. Spelling errors gave away the hidden-humans; machines were identified by 'speed of response' and lengthier utterances.<ref> {{Citation|url=http://www.rdg.ac.uk/research/Highlights-News/featuresnews/res-featureloebner.asp | title=Can a machine think? -Results from the 18th Loebner Prize | place=University of Reading|year=2008}}</ref> In an experimental study looking at [[Paul_Grice#Conversational_Maxims|Gricean maxim violations]] that also used the Loebner transcripts, Ayse Saygin found significant differences between the responses of participants who knew and did not know about computers being involved.<ref>Saygin, A.P. & Cicekli, I. (2002) Pragmatics in human-computer conversation. Journal of Pragmatics, 34(3): 227-258</ref> ==Strengths of the test== ===Tractability=== The [[philosophy of mind]], [[psychology]], and modern [[neuroscience]] have been unable to provide definitions of "intelligence" and "thinking" that are sufficiently precise and general to be applied to machines. Without such definitions, the central questions of the [[philosophy of artificial intelligence]] cannot be answered. The Turing test, even if imperfect, at least provides something that can actually be measured. As such, it is a pragmatic solution to a difficult philosophical question. ===Breadth of subject matter=== The power of the Turing test derives from the fact that it is possible to talk about anything. Turing wrote that "the question and answer method seems to be suitable for introducing almost any one of the fields of human endeavor that we wish to include."<ref>{{Harvnb|Turing|1950}} under "Critique of the New Problem"</ref> [[John Haugeland]] adds that "understanding the words is not enough; you have to understand the ''topic'' as well."<ref>{{Harvnb|Haugeland|1985|p=8}}</ref> In order to pass a well-designed Turing test, the machine must use [[natural language processing|natural language]], [[commonsense reasoning|reason]], have [[knowledge representation|knowledge]] and [[machine learning|learn]]. The test can be extended to include video input, as well as a "hatch" through which objects can be passed: this would force the machine to demonstrate the skill of [[computer vision|vision]] and [[robotics]] as well. Together, these represent almost all of the major problems of artificial intelligence.<ref>"These six disciplines," write [[Stuart J. Russell]] and [[Peter Norvig]], "represent most of AI." {{Harvnb|Russell|Norvig|2003|p=3}}</ref> The [[Feigenbaum test]] is designed to take advantage of the broad range of topics available to a Turing test. It compares the machine against the abilities of experts in specific fields such as [[literature]] or [[chemistry]]. ==Weaknesses of the test== The Turing test is based on the assumption that human beings can judge a machine's intelligence by comparing its behaviour with human behaviour. Every element of this assumption has been questioned: the human's judgement, the value of comparing only behaviour and the value of comparing against a human. Because of these and other considerations, some AI researchers have questioned the usefulness of the test. In practice, the test's results can easily be dominated not by the computer's (pseudo-?) intelligence, but by the attitudes, skill or naivet√© of the questioner. ===Human intelligence vs intelligence in general=== [[Image:Weakness of Turing test 1.svg|right|250px]] The Turing test does not directly test whether the computer behaves intelligently - it tests only whether the computer behaves like a human being. Since human behavior and intelligent behavior are not exactly the same thing, the test can fail to accurately measure intelligence in two ways: ;Some human behavior is unintelligent: The Turing test requires that the machine be able to execute ''all'' human behaviors, regardless of whether they are intelligent. It even tests for behaviors that we may not consider intelligent at all, such as the susceptibility to insults,<ref>Saygin, A.P. & Cicekli, I. (2002). Journal of Pragmatics, 34, 227-258.</ref> the temptation to [[lie]] or, simply, a high frequency of [[typographical error|typing mistakes]]. If a machine cannot imitate human behavior in detail, it fails the test. :This objection was raised by ''[[The Economist]],'' 