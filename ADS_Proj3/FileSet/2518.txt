into all of <code>t</code>, and so <code>d[n,m]</code> holds our result. This proof fails to validate that the number placed in <code>d[i,j]</code> is in fact minimal; this is more difficult to show, and involves an [[Reductio ad absurdum|argument by contradiction]] in which we assume <code>d[i,j]</code> is smaller than the minimum of the three, and use this to show one of the three is not minimal. ===Possible improvements=== Possible improvements to this algorithm include: * We can adapt the algorithm to use less space, [[Big O notation|''O'']](''m'') instead of ''O''(''mn''), since it only requires that the previous row and current row be stored at any one time. * We can store the number of insertions, deletions, and substitutions separately, or even the positions at which they occur, which is always <code>j</code>. * We can normalize the distance to the interval <code>[0,1]</code>. * If we are only interested in the distance if it is smaller than a threshold ''k'', then it suffices to compute a diagonal stripe of width ''2k+1'' in the matrix. In this way, the algorithm can be run in [[Big O notation|''O'']](''kl'') time, where ''l'' is the length of the shortest string.<ref>{{cite book |author=Gusfield, Dan |title=Algorithms on strings, trees, and sequences: computer science and computational biology |publisher=Cambridge University Press |location=Cambridge, UK |year=1997 |isbn=0-521-58519-8 }}</ref> * We can give different penalty costs to insertion, deletion and substitution. We can also give penalty costs that depend on which characters are inserted, deleted or substituted. * By initializing the first row of the matrix with ''0'', the algorithm can be used for [[fuzzy string searching|fuzzy string search]] of a string in a text.<ref>{{cite journal |author=Navarro G |title=A guided tour to approximate string matching |journal=ACM Computing Surveys |volume=33 |issue=1 |pages=31–88 |year=2001 |doi=10.1145/375360.375365}}</ref> This modification gives the end-position of matching substrings of the text. To determine the start-position of the matching substrings, the number of insertions and deletions can be stored separately and used to compute the start-position from the end-position.<ref>Bruno Woltzenlogel Paleo. [http://www.logic.at/people/bruno/Papers/2007-GATE-ESSLLI.pdf An approximate gazetteer for GATE based on levenshtein distance]. Student Section of the European Summer School in Logic, Language and Information ([[European Summer School in Logic, Language and Information|ESSLLI]]), 2007.</ref> * This algorithm [[parallel computing|parallelizes]] poorly, due to a large number of [[data dependency|data dependencies]]. However, all the <code>cost</code> values can be computed in parallel, and the algorithm can be adapted to perform the <code>minimum</code> function in phases to eliminate dependencies. * By examining diagonals instead of rows, and by using [[lazy evaluation]], we can find the Levenshtein distance in ''O''(''m'' (1 + ''d'')) time (where ''d'' is the Levenshtein distance), which is much faster than the regular dynamic programming algorithm if the distance is small.<ref>{{cite journal |author=Allison L |title=Lazy Dynamic-Programming can be Eager |journal=Inf. Proc. Letters |volume=43 |issue=4 |pages=207–12 |year=1992 |month=September |url=http://www.csse.monash.edu.au/~lloyd/tildeStrings/Alignment/92.IPL.html |doi=10.1016/0020-0190(92)90202-7}}</ref> ===Upper and lower bounds=== The Levenshtein distance has several simple upper and lower bounds that are useful in applications which compute many of them and compare them. These include: * It is always at least the difference of the sizes of the two strings. * It is at most the length of the longer string. * It is zero if and only if the strings are identical. * If the strings are the same size, the [[Hamming distance]] is an upper bound on the Levenshtein distance. ==See also== {{Wikibooks| Algorithm implementation|Strings/Levenshtein distance|Levenshtein distance}} {{Wikibooks| R_Programming|Text_Processing#Edit_distance|Levenshtein distance in R}} <div class= style="-moz-column-count:2; column-count:2;"> *[[agrep]] *[[Bitap algorithm]] *[[Damerau–Levenshtein distance]] *[[diff]] *[[Dynamic time warping]] *[[Euclidean distance]] *[[Fuzzy string searching]] *[[Hamming weight]] *[[Hirschberg's algorithm]] *[[Homology (biology)#Homology of sequences in genetics|Homology of sequences in genetics]] *[[Hunt–McIlroy algorithm]] *[[Jaccard index]] *[[Jaro–Winkler distance]] *[[Levenshtein automaton]] *[[Longest common subsequence problem]] *[[Lucene]] (an open source search engine that implements edit distance) *[[Manhattan distance]] *[[Metric space]] *[[Needleman–Wunsch algorithm]] *[[Sequence alignment]] *[[Similarity (mathematics)]] *[[Similarity space]] on [[Numerical taxonomy]] *[[Smith–Waterman algorithm]] *[[Sørensen similarity index]] </div> ==Notes== <references/> ==External links== *[http://www.miislita.com/searchito/levenshtein-edit-distance.html Dr. E. Garcia's example of Levenshtein edit distance calculation] *[http://www.merriampark.com/ld.htm Levenshtein Distance, in Three Flavors] *[http://www.postgresql.org/docs/current/static/fuzzystrmatch.html Levenshtein in PostgreSQL] {{DEFAULTSORT:Levenshtein Distance}} [[Category:Algorithms on strings]] [[Category:String similarity measures]] [[Category:Dynamic programming]] [[Category:Articles with example pseudocode]] [[af:Levenshteinafstand]] [[de:Levenshtein-Distanz]] [[es:Distancia de Levenshtein]] [[fa:فاصله لون‌اشتاین]] [[fr:Distance de Levenshtein]] [[he:מרחק לוינשטיין]] [[it:Distanza di Levenshtein]] [[lv:Levenšteina attālums]] [[nl:Levenshteinafstand]] [[ja:レーベンシュタイン距離]] [[nn:Levenshtein-distanse]] [[pl:Odległość Levenshteina]] [[pt:Distância Levenshtein]] [[ru:Расстояние Левенштейна]] [[sr:Левенштајново растојање]] [[fi:Levenšteinin etäisyys]] [[sv:Levenshteinavstånd]] [[tg:Масофаи Левенштейн]] [[uk:Відстань Левенштейна]] [[vi:Khoảng cách Levenshtein]] [[zh:編輯距離]]</text> </page> <page> <id>21539</id> <title>Lexalytics</title> <text>{{Infobox Company | | company_name = Lexalytics, Inc. | company_logo = [[Image:Lexalytics.png|200px|Lexalytics, Inc. Logo]] | company_type = [[Private company|Private]] | foundation = 2003 | location = [[Boston, MA]] [[Image:Flag of the United States.svg|20px]]| | key_people = Jeff Catlin, CEO <br /> Mike Marshall, CTO <br /> | industry = [[Computer Software]] | | products = [[Text analytics]] | | homepage = http://www.lexalytics.com }} Lexalytics, Inc. provides enterprise and hosted [[text analytics]] software to transform unstructured text into structured data.<ref>{{cite news |url=http://www.xconomy.com/boston/2010/03/29/lexalytics-moves-to-boston-to-exploit-new-market-for-sentiment-analysis/ |title=Lexalytics Moves to Boston to Exploit New Market for Sentiment Analysis |publisher=Xconomy Boston |date= 2010-03-10 |accessdate=2010-07-10 | first=Wade | last=Roush}}</ref> The software extracts entities (people, places, companies, products, etc), [[sentiment analysis|sentiment]], quotes, opinions, and themes (generally noun phrases) from text. Text is considered [[unstructured data]] which comprises somewhere between 31% and 85% of what is stored in any given enterprise.<ref>{{cite web |url=http://tdwi.org/articles/2007/09/05/unstructured-data-attacking-a-myth.aspx |title=Unstructured Data: Attacking a Myth |publisher=twdi.org |date=2007-09-05 |accessdate=2010-07-10 |first=Stephen |Last=Swoyer}}</ref><ref>{{cite web |url=http://ikt.hia.no/perep/eip_ind.pdf |first=Christopher |last= Shilakes |first=Julie |last=Tylman |title=Enterprise Information Portals |publisher=[[Merrill Lynch]] |date=1998-11-16 |accessdate=2010-07-12}}</ref> The software uses [[natural language processing]] technology to extract the above-mentioned items from [[social media]] and forums; the [[voice of the customer]] in surveys, emails, and call-center feedback, traditional media, pharmaceutical research and development, internal enterprise documents, and others.<ref>{{cite web |url=http://www.bbc.co.uk/blogs/thereporters/rorycellanjones/2010/04/the_tv_debate_what_did_twitter.html |title = The TV debate: What did Twitterers think and feel? |first=Rory |last=Clelland |publisher=[[BBC News]] |date=2010-04-16 |accessdate=2010-07-12}}</ref><ref>{{cite web |url=http://arnoldit.com/wordpress/2010/05/26/lexalytics-pushes-into-pharma/ |title = Lexalytics Pushes into Pharma |first=Stephen |last=Arnold |publisher=Arnold IT |date=2010-05-26 |accessdate=2010-07-10}}</ref><ref>{{cite web |url=http://www.socialmediaexplorer.com/2009/10/23/understanding-natural-language-processing-for-social-media-monitoring/ |title=Understanding Natural Language Processing for Social Media Monitoring |first=Jason |last=Falls |publisher=Social Media Explorer |date=2009-10-23 |accessdate=2010-07-12}}</ref><ref>{{cite web |url=http://blogs.idc.com/ie/?page_id=150 |title=IDC Predictions 2008: The Post-Disruption Marketplace Takes Shape |first=Frank |Last=Gens |publisher=IDC |date=2008-04-07 |accessdate=2010-07-12}}</ref> Corporate customers include [[Cisco Systems]], [[Lithium Technologies]], [[Vocus]], [[Thomson Reuters]], and [[ProQuest]].<ref>{{cite 