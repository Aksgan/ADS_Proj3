* '''Real-time backup''': [[Backup]] should be scheduled between low times of activity to prevent lag of the server. * '''High [[Database normalization|normalization]]''': This lowers redundant information to increase the speed and improve concurrency, this also improves backups. * '''Archiving of historical data''': Uncommonly used data are moved into other databases or backed up tables. This keeps tables small and also improves backup times. * '''Good hardware configuration''': [[Hardware]] must be able to handle many users and provide quick response times. In a TPS, there are 5 different types of files. The TPS uses the files to store and organize its transaction data: * '''Master file''': Contains information about an organization’s business situation. Most transactions and databases are stored in the master file. * '''Transaction file''': It is the collection of transaction records. It helps to update the master file and also serves as audit trails and transaction history. * '''Report file''': Contains data that has been formatted for presentation to a user. * '''Work file''': Temporary files in the system used during the processing. * '''Program file''': Contains the instructions for the processing of data. ===Data warehouse=== {{main|Data warehouse}} A data warehouse is a [[database]] that collects information from different sources. When it's gathered in real-time transactions it can be used for analysis efficiently if it's stored in a data warehouse. It provides data that are ''consolidated'', ''subject-oriented'', ''historical'' and ''read-only'': * '''Consolidated''': Data are organised with consistent naming conventions, measurements, attributes and semantics. It allows data from a data warehouse from across the organization to be effectively used in a consistent manner. * '''Subject-oriented''': Large amounts of data are stored across an organization, some data could be irrelevant for reports and makes [[Information retrieval|querying]] the data difficult. It organizes only key business information from operational sources so that it's available for analysis. * '''Historical''': Real-time TPS represent the current value at any time, an example could be stock levels. If past data are kept, querying the database could return a different response. It stores series of snapshots for an organisation's operational data generated over a period of time. * '''Read-only''': Once data are moved into a data warehouse, it becomes read-only, unless it was incorrect. Since it represents a snapshot of a certain time, it must never be updated. Only operations which occur in a data warehouse are loading and querying data. ===Backup procedures=== [[Image:Backup-DFD.png|thumb|200px|right|A Dataflow Diagram of backup and recovery procedures.]] Since business organizations have become very dependent on TPSs, a breakdown in their TPS may stop the business' regular routines and thus stopping its operation for a certain amount of time. In order to prevent data loss and minimize disruptions when a TPS breaks down a well-designed [[backup]] and recovery procedure is put into use. The recovery process can rebuild the system when it goes down. ====Recovery process==== A TPS may fail for many reasons. These reasons could include a system failure, human errors, [[hardware]] failure, incorrect or invalid data, [[computer viruses]], [[software]] application errors or natural or man-made disasters. As it's not possible to prevent all TPS failures, a TPS must be able to cope with failures. The TPS must be able to detect and correct errors when they occur. A TPS will go through a recovery of the [[database]] to cope when the system fails, it involves the [[backup]], journal, checkpoint, and recovery manager: * Journal: A journal maintains an audit trail of transactions and database changes. Transaction logs and Database change logs are used, a transaction log records all the essential data for each transactions, including data values, time of transaction and terminal number. A database change log contains before and after copies of records that have been modified by transactions. * Checkpoint: ''The purpose of checkpointing'' is to provide a snapshot of the data within the database. A checkpoint, in general, is any identifier or other reference that identifies at a point in time the state of the database. Modifications to database pages are performed in memory and are not necessarily written to disk after every update. Therefore, periodically, the database system must perform a checkpoint to write these updates which are held in-memory to the storage disk. Writing these updates to storage disk creates a point in time in which the database system can apply changes contained in a transaction log during recovery after an unexpected shut down or crash of the database system. If a checkpoint is interrupted and a recovery is required, then the database system must start recovery from a previous successful checkpoint. ''Checkpointing  can be either transaction-consistent or non-transaction-consistent'' (called also fuzzy checkpointing). ''Transaction-consistent checkpointing'' produces a persistent database image that is sufficient to recover the database to the state that was externally perceived at the moment of starting the checkpointing. ''A non-transaction-consistent checkpointing'' results in a persistent database image that is insufficient to perform a recovery of the database state. To perform the database recovery, additional information is needed, typically contained in transaction logs. Transaction consistent checkpointing refers to a consistent database, which doesn't necessarily include all the latest committed transactions, but all modifications made by transactions, that were committed at the time checkpoint creation was started, are fully present. A non-consistent transaction refers to a checkpoint which is not necessarily a consistent database, and can't be recovered to one without all log records generated for open transactions included in the checkpoint. Depending on the type of database management system implemented ''a checkpoint may incorporate indexes or storage pages (user data), indexes and storage pages''. If no indexes are incorporated into the checkpoint, indexes must be created when the database is restored from the checkpoint image.  * Recovery Manager: A recovery manager is a program which restores the database to a correct condition which can restart the transaction processing. Depending on how the system failed, there can be two different recovery procedures used. Generally, the procedures involves restoring data that has been collected from a backup device and then running the transaction processing again. Two types of recovery are ''backward recovery'' and ''forward recovery'': * Backward recovery: used to [[undo]] unwanted changes to the database. It reverses the changes made by transactions which have been aborted. It involves the logic of reprocessing each transaction, which is very time-consuming. * Forward recovery: it starts with a [[backup]] copy of the database. The transaction will then reprocess according to the transaction journal that occurred between the time the backup was made and the present time. It's much faster and more accurate. {{See also|Checkpoint restart}} ====Types of back-up procedures==== There are two main types of Back-up Procedures: '''Grandfather-father-son''' and '''Partial backups''': =====Grandfather-father-son===== This procedure refers to at least three generations of [[backup]] master files. thus, the most recent backup is the son, the oldest backup is the grandfather. It's commonly used for a ''batch transaction processing system'' with a [[magnetic tape]]. If the system fails during a batch run, the master file is recreated by using the son backup and then restarting the batch. However if the son backup fails, is corrupted or destroyed, then the next generation up backup (father) is required. Likewise, if that fails, then the next generation up backup (grandfather) is required. Of course the older the generation, the more the data may be out 