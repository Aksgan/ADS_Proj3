} else { // insert right if (root.getRight() == null) { root.setRight(new TreeNode(data, null, null)); return; } else { root = root.getRight(); } } } } </source> Below is a recursive approach to the insertion method. <source lang="java"> public static void insert(Node root, int data){ if (root==null) { root = TreeNode(data, null, null); }else{ internalInsert(root, data); } } private static void internalInsert(Node node, int data){ // Not the same value twice if (data == node.getValue()) { return; } if (data < node.mValue) { if (node.getLeft() == null) { node.setLeft(new TreeNode(data, null, null)); }else{ internalInsert(current.getLeft(), data); } }else{ if (node.getRight() == null) { node.setRight(TreeNode(data, null, null)); }else{ internalInsert(current.getRight(), data); } } } </source> ===Deletion===<!--This section is linked from [[Red-black tree]]--> There are three possible cases to consider: * '''Deleting a leaf (node with no children):''' Deleting a leaf is easy, as we can simply remove it from the tree. * '''Deleting a node with one child:''' Remove the node and replace it with its child. * '''Deleting a node with two children:''' Call the node to be deleted ''N''. Do not delete ''N''. Instead, choose either its in-order successor node or its in-order predecessor node, ''R''. Replace the value of ''N'' with the value of ''R'', then delete ''R''. As with all binary trees, a node's in-order successor is the left-most child of its right subtree, and a node's in-order predecessor is the right-most child of its left subtree. In either case, this node will have zero or one children. Delete it according to one of the two simpler cases above. [[Image:binary search tree delete.svg|frame|center|Deleting a node with two children from a binary search tree. The triangles represent subtrees of arbitrary size, each with its leftmost and rightmost child nodes at the bottom two vertices.]] Consistently using the in-order successor or the in-order predecessor for every instance of the two-child case can lead to an [[Balanced tree|unbalanced]] tree, so good implementations add inconsistency to this selection. Running Time Analysis: Although this operation does not always traverse the tree down to a leaf, this is always a possibility; thus in the worst case it requires time proportional to the height of the tree. It does not require more even when the node has two children, since it still follows a single path and does not visit any node twice. Here is the code in Python: <source lang="python"> def findMin(self): ''' Finds the smallest element that is a child of *self* ''' current_node = self while current_node.left_child: current_node = current_node.left_child return current_node def replace_node_in_parent(self, new_value=None): ''' Removes the reference to *self* from *self.parent* and replaces it with *new_value*. ''' if self == self.parent.left_child: self.parent.left_child = new_value else: self.parent.right_child = new_value if new_value: new_value.parent = self.parent def binary_tree_delete(self, key): if key < self.key: self.left_child.binary_tree_delete(key) elif key > self.key: self.right_child.binary_tree_delete(key) else: # delete the key here if self.left_child and self.right_child: # if both children are present # get the smallest node that's bigger than *self* successor = self.right_child.findMin() self.key = successor.key # if *successor* has a child, replace it with that # at this point, it can only have a *right_child* # if it has no children, *right_child* will be "None" successor.replace_node_in_parent(successor.right_child) elif self.left_child or self.right_child: # if the node has only one child if self.left_child: self.replace_node_in_parent(self.left_child) else: self.replace_node_in_parent(self.right_child) else: # this node has no children self.replace_node_in_parent(None) </source> ===Traversal=== {{main|Tree traversal}} Once the binary search tree has been created, its elements can be retrieved [[in-order traversal|in-order]] by [[recursion|recursively]] traversing the left subtree of the root node, accessing the node itself, then recursively traversing the right subtree of the node, continuing this pattern with each node in the tree as it's recursively accessed. As with all binary trees, one may conduct a [[pre-order traversal]] or a [[post-order traversal]], but neither are likely to be useful for binary search trees. The code for in-order traversal in Python is given below. It will call '''callback''' for every node in the tree. <source lang="python"> def traverse_binary_tree(node, callback): if node is None: return traverse_binary_tree(node.leftChild, callback) callback(node.value) traverse_binary_tree(node.rightChild, callback) </source> Traversal requires [[Big O notation#Related asymptotic notations|Î©(''n'')]] time, since it must visit every node. This algorithm is also O(''n''), so it is [[asymptotically optimal]]. ===Sort=== A binary search tree can be used to implement a simple but efficient [[sorting algorithm]]. Similar to [[heapsort]], we insert all the values we wish to sort into a new ordered data structure&mdash;in this case a binary search tree&mdash;and then traverse it in order, building our result: <source lang="python"> def build_binary_tree(values): tree = None for v in values: tree = binary_tree_insert(tree, v) return tree def get_inorder_traversal(root): ''' Returns a list containing all the values in the tree, starting at *root*. Traverses the tree in-order(leftChild, root, rightChild). ''' result = [] traverse_binary_tree(root, lambda element: result.append(element)) return result </source> The worst-case time of <code>build_binary_tree</code> is <math>O(n^2)</math>&mdash;if you feed it a sorted list of values, it chains them into a [[linked list]] with no left subtrees. For example, <code>traverse_binary_tree([1, 2, 3, 4, 5])</code> yields the tree <code>(1 (2 (3 (4 (5)))))</code>. There are several schemes for overcoming this flaw with simple binary trees; the most common is the [[self-balancing binary search tree]]. If this same procedure is done using such a tree, the overall worst-case time is [[Big O notation|O]](''n''log ''n''), which is [[asymptotically optimal]] for a [[comparison sort]]. In practice, the poor [[CPU cache|cache]] performance and added overhead in time and space for a tree-based sort (particularly for node [[dynamic memory allocation|allocation]]) make it inferior to other asymptotically optimal sorts such as [[heapsort]] for static list sorting. On the other hand, it is one of the most efficient methods of ''incremental sorting'', adding items to a list over time while keeping the list sorted at all times. ==Types== There are many types of binary search trees. [[AVL tree]]s and [[red-black tree]]s are both forms of [[self-balancing binary search tree]]s. A [[splay tree]] is a binary search tree that automatically moves frequently accessed elements nearer to the root. In a [[treap]] ("tree [[heap (data structure)|heap]]"), each node also holds 