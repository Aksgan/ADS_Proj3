|align=center|''3'', ''3'' |- |} This can be illustrated by a two-player game in which both players simultaneously choose an integer from 0 to 3 and they both win the smaller of the two numbers in points. In addition, if one player chooses a larger number than the other, then he/she has to give up two points to the other. This game has a unique pure-strategy Nash equilibrium: both players choosing 0 (highlighted in light red). Any other choice of strategies can be improved if one of the players lowers his number to one less than the other player's number. In the table to the right, for example, when starting at the green square it is in player 1's interest to move to the purple square by choosing a smaller number, and it is in player 2's interest to move to the blue square by choosing a smaller number. If the game is modified so that the two players win the named amount if they both choose the same number, and otherwise win nothing, then there are 4 Nash equilibria (0,0...1,1...2,2...and 3,3). === Nash equilibria in a payoff matrix === There is an easy numerical way to identify Nash equilibria on a payoff matrix. It is especially helpful in two-person games where players have more than two strategies. In this case formal analysis may become too long. This rule does not apply to the case where mixed (stochastic) strategies are of interest. The rule goes as follows: if the first payoff number, in the duplet of the cell, is the maximum of the column of the cell and if the second number is the maximum of the row of the cell - then the cell represents a Nash equilibrium. {| align="left" border="1" cellpadding="4" cellspacing="0" style="margin: 1em; background: #f9f9f9; border: 1px #aaa solid; border-collapse: collapse; font-size: 95%;" |++ align=bottom |''A Payoff Matrix - Nash Equlibria in bold'' | !Option A !Option B !Option C |- !Option A |align=center|0, 0 |align=center|'''25, 40''' |align=center|5, 10 |- !Option B |align=center|'''40, 25''' |align=center|0, 0 |align=center|5, 15 |- !Option C |align=center|10, 5 |align=center|15, 5 |align=center|'''10, 10''' |- |} We can apply this rule to a 3×3 matrix: Using the rule, we can very quickly (much faster than with formal analysis) see that the Nash Equlibria cells are (B,A), (A,B), and (C,C). Indeed, for cell (B,A) 40 is the maximum of the first column and 25 is the maximum of the second row. For (A,B) 25 is the maximum of the second column and 40 is the maximum of the first row. Same for cell (C,C). For other cells, either one or both of the duplet members are not the maximum of the corresponding rows and columns. This said, the actual mechanics of finding equilibrium cells is obvious: find the maximum of a column and check if the second member of the pair is the maximum of the row. If these conditions are met, the cell represents a Nash Equilibrium. Check all columns this way to find all NE cells. An N×N matrix may have between 0 and N×N [[pure strategy]] Nash equilibria. == Stability == The concept of [[Stability theory|stability]], useful in the analysis of many kinds of equilibria, can also be applied to Nash equilibria. A Nash equilibrium for a mixed strategy game is stable if a small change (specifically, an infinitesimal change) in probabilities for one player leads to a situation where two conditions hold: # the player who did not change has no better strategy in the new circumstance # the player who did change is now playing with a strictly worse strategy. If these cases are both met, then a player with the small change in his mixed-strategy will return immediately to the Nash equilibrium. The equilibrium is said to be stable. If condition one does not hold then the equilibrium is unstable. If only condition one holds then there are likely to be an infinite number of optimal strategies for the player who changed. [[John Forbes Nash|John Nash]] showed that the latter situation could not arise in a range of well-defined games. In the "driving game" example above there are both stable and unstable equilibria. The equilibria involving mixed-strategies with 100% probabilities are stable. If either player changes his probabilities slightly, they will be both at a disadvantage, and his opponent will have no reason to change his strategy in turn. The (50%,50%) equilibrium is unstable. If either player changes his probabilities, then the other player immediately has a better strategy at either (0%, 100%) or (100%, 0%). Stability is crucial in practical applications of Nash equilibria, since the mixed-strategy of each player is not perfectly known, but has to be inferred from statistical distribution of his actions in the game. In this case unstable equilibria are very unlikely to arise in practice, since any minute change in the proportions of each strategy seen will lead to a change in strategy and the breakdown of the equilibrium. The Nash equilibrium defines stability only in terms of unilateral deviations. In cooperative games such a concept is not convincing enough. [[Strong Nash equilibrium]] allows for deviations by every conceivable coalition <ref name="CoalitionProof">{{Citation|doi = 10.1016/0022-0531(87)90099-8|title = Coalition-Proof Equilibria I. Concepts| author = B. D. Bernheim, B. Peleg, M. D. Whinston |journal = Journal of Economic Theory |volume = 42 |year =1987| pages = 1&ndash;12|postscript = .}}</ref>. Formally, a [[Strong Nash equilibrium]] is a Nash equilibrium in which no coalition, taking the actions of its complements as given, can cooperatively deviate in a way that benefits all of its members <ref name="SNE">{{Citation| author = R. Aumann, |title = Acceptable points in general cooperative n-person games in "Contributions to the Theory of Games IV" | publisher = Princeton Univ. Press, Princeton, N.J. |year =1959|postscript = .}}</ref>. However, the Strong Nash concept is sometimes perceived as too "strong" in that the environment allows for unlimited private communication. In fact, Strong Nash equilibrium has to be Pareto efficient. As a result of these requirements, Strong Nash almost never exists. 