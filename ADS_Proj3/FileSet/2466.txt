into (iii) yields <math>2x^2=1</math>, so <math>x=y=\pm \sqrt{2}/2</math> and <math>\lambda = \mp \sqrt{2}/2</math>, showing the stationary points are <math>(\sqrt{2}/2,\sqrt{2}/2)</math> and <math>(-\sqrt{2}/2,-\sqrt{2}/2)</math>. Evaluating the objective function ''f'' on these yields :<math>f(\sqrt{2}/2,\sqrt{2}/2)=\sqrt{2}\mbox{ and } f(-\sqrt{2}/2, -\sqrt{2}/2)=-\sqrt{2},</math> thus the maximum is <math>\sqrt{2}</math>, which is attained at <math>(\sqrt{2}/2,\sqrt{2}/2)</math> and the minimum is <math>-\sqrt{2}</math>, which is attained at <math>(-\sqrt{2}/2,-\sqrt{2}/2)</math>. === Simple example === [[Image:Lagrange simple.jpg|thumb|right|300px|Fig. 4. Illustration of the constrained optimization problem]] Suppose you want to find the maximum values for :<math> f(x, y) = x^2 y \, </math> with the condition that the ''x'' and ''y'' coordinates lie on the circle around the origin with radius √3, that is, :<math> g(x,y) = x^2 + y^2 = 3. \, </math> As there is just a single condition, we will use only one multiplier, say λ. The constraint ''g''(''x'', ''y'')-3 is identically zero on the circle of radius √3. So any multiple of ''g''(''x'', ''y'')-3 may be added to ''f''(''x'', ''y'') leaving ''f''(''x'', ''y'') unchanged in the region of interest (above the circle where our original constraint is satisfied). Let :<math>\Lambda(x, y, \lambda) = f(x,y) + \lambda (g(x, y)-3) = x^2y + \lambda (x^2 + y^2 - 3). \, </math> The critical values of <math>\Lambda</math> occur when its gradient is zero. The partial derivatives are :<math>\begin{align} \frac{\partial \Lambda}{\partial x} &= 2 x y + 2 \lambda x &&= 0, \qquad \text{(i)} \\ \frac{\partial \Lambda}{\partial y} &= x^2 + 2 \lambda y &&= 0, \qquad \text{(ii)} \\ \frac{\partial \Lambda}{\partial \lambda} &= x^2 + y^2 - 3 &&= 0. \qquad \text{(iii)} \end{align}</math> Equation (iii) is just the original constraint. Equation (i) implies <math> x = 0 </math> ''or'' λ = &minus;''y''. In the first case, if ''x'' = 0 then we must have <math>y = \pm \sqrt{3}</math> by (iii) and then by (ii) λ = 0. In the second case, if λ = &minus;''y'' and substituting into equation (ii) we have that, :<math>x^2 - 2y^2 = 0. \, </math> Then ''x''<sup>2</sup> = 2''y''<sup>2</sup>. Substituting into equation (iii) and solving for ''y'' gives this value of ''y'': :<math>y = \pm 1. \, </math> Thus there are six critical points: :<math> (\sqrt{2},1); \quad (-\sqrt{2},1); \quad (\sqrt{2},-1); \quad (-\sqrt{2},-1); \quad (0,\sqrt{3}); \quad (0,-\sqrt{3}). </math> Evaluating the objective at these points, we find :<math> f(\pm\sqrt{2},1) = 2; \quad f(\pm\sqrt{2},-1) = -2; \quad f(0,\pm \sqrt{3})=0. </math> Therefore, the objective function attains a [[global maximum]] (with respect to the constraints) at <math>(\pm\sqrt{2},1)</math> and a [[global minimum]] at <math>(\pm\sqrt{2},-1).</math> The point <math>(0,\sqrt{3})</math> is a [[local minimum]] and <math>(0,-\sqrt{3})</math> is a [[local maximum]], as may be determined by consideration of the [[Hessian (mathematics)#Bordered_Hessian| Hessian matrix]] of <math>\Lambda</math>. === Example: entropy === Suppose we wish to find the finite [[probability distribution]] ([[Without loss of generality]], say on the points <math>\{1, 2, \cdots, n\}</math>) with maximal [[information entropy]]. Then :<math>f(p_1,p_2,\ldots,p_n) = -\sum_{k=1}^n p_k\log_2 p_k.</math> Of course, the sum of these probabilities equals 1, so our constraint is ''g''('''p''') = 1 with :<math>g(p_1,p_2,\ldots,p_n)=\sum_{k=1}^n p_k.</math> We can use Lagrange multipliers to find the point of maximum entropy (depending on the probabilities). For all ''k'' from 1 to ''n'', we require that :<math>\frac{\partial}{\partial p_k}(f+\lambda (g-1))=0,</math> which gives :<math>\frac{\partial}{\partial p_k}\left(-\sum_{k=1}^n p_k \log_2 p_k + \lambda \left(\sum_{k=1}^n p_k - 1\right) \right) = 0.</math> Carrying out the differentiation of these ''n'' equations, we get :<math>-\left(\frac{1}{\ln 2}+\log_2 p_k \right) + \lambda = 0.</math> This shows that all ''p''<sub>''k''</sub> are equal (because they depend on λ only). By using the constraint ∑<sub>''k''</sub> ''p''<sub>''k''</sub> = 1, we find :<math>p_k = \frac{1}{n}.</math> Hence, the uniform distribution is the distribution with the greatest entropy, among distributions on ''n'' points. === Example: numerical optimization === [[Image:lagnum1.png|thumb|right|300px|Lagrange multipliers cause the critical points to occur at saddle points.]] [[Image:lagnum2.png|thumb|right|300px|The magnitude of the gradient can be used to force the critical points to occur at local minima.]] With Lagrange multipliers, the critical points occur at [[saddle point]]s, rather than at local maxima (or minima). Unfortunately, many numerical optimization techniques, such as [[hill climbing]], [[gradient descent]], some of the [[quasi-Newton method]]s, among others, are designed to find local maxima (or minima) and not saddle points. For this reason, one must either modify the formulation to ensure that it's a minimization problem (for example, by extremizing the square of the [[gradient]] of the Lagrangian as below), or else use an optimization technique that finds [[stationary points]] (such as [[Newton's method in optimization|Newton's method]] without an extremum seeking [[line search]]) and not necessarily extrema. As a simple example, consider the problem of finding the value of ''x'' that minimizes <math>f(x)=x^2</math>, constrained such that <math>x^2=1</math>. (This problem is somewhat pathological because there are only two values that satisfy this constraint, but it is useful for illustration purposes because the corresponding unconstrained function can be visualized in three dimensions.) Using Lagrange multipliers, this problem can be converted into an unconstrained optimization problem: :<math>\Lambda(x,\lambda)=x^2+\lambda(x^2-1)</math> The two critical points occur at saddle points where <math>x=1</math> and <math>x=-1</math>. In order to solve this problem with a numerical optimization technique, we must first transform this problem such that the critical points occur at local minima. This is done by computing the magnitude of the gradient of the unconstrained optimization problem. First, we compute the partial derivative of the unconstrained problem with respect to each variable: :<math>\frac{\partial \Lambda}{\partial x}=2x+2x\lambda</math> :<math>\frac{\partial \Lambda}{\partial \lambda}=x^2-1</math> If the target function is not easily differentiable, the differential with respect to each variable can be measured empirically: :<math>\frac{\partial \Lambda}{\partial x}\approx\frac{\Lambda(x+\epsilon,\lambda)-\Lambda(x,\lambda)}{\epsilon}</math> :<math>\frac{\partial \Lambda}{\partial \lambda}\approx\frac{\Lambda(x,\lambda+\epsilon)-\Lambda(x,\lambda)}{\epsilon}</math> where <math>\epsilon</math> is a small value. Next, we compute the magnitude of the gradient, which is the square root of the sum of the squares of the partial derivatives: :<math>h(x,\lambda)=\sqrt{(2x+2x\lambda)^2+(x^2-1)^2}\approx\sqrt{\left(\frac{\Lambda(x+\epsilon,\lambda)-\Lambda(x,\lambda)}{\epsilon}\right)^2+\left(\frac{\Lambda(x,\lambda+\epsilon)-\Lambda(x,\lambda)}{\epsilon}\right)^2}</math> Alternatively, one may use the magnitude squared, which is the sum of the squares of the partials, without taking a square root – this has the advantage of being smooth if the partials are, while the square root may not be differentiable at the zeros. The critical points of ''h'' occur at <math>x=1</math> and <math>x=-1</math>, just as in <math>\Lambda</math>. Unlike the critical points in <math>\Lambda</math>, however, the critical points in ''h'' occur at local minima, so numerical 