the animal usually experiences both the CS (Conditioned Stimulus) and the US (Unconditioned Stimulus), showing the operant response to terminate the aversive US. During later trials, the animal will learn to perform the response already during the presentation of the CS thus preventing the aversive US from occurring. Such trials are called "avoidance trials." ===Free-operant avoidance learning=== In this experimental session, no discrete stimulus is used to signal the occurrence of the aversive stimulus. Rather, the aversive stimulus (mostly shocks) are presented without explicit warning stimuli. There are two crucial time intervals determining the rate of avoidance learning. This first one is called the S-S-interval (shock-shock-interval). This is the amount of time which passes during successive presentations of the shock (unless the operant response is performed). The other one is called the R-S-interval (response-shock-interval) which specifies the length of the time interval following an operant response during which no shocks will be delivered. Note that each time the organism performs the operant response, the R-S-interval without shocks begins anew. ==Two-process theory of avoidance== This theory was originally established to explain learning in discriminated avoidance learning. It assumes two processes to take place: ; ''a) Classical conditioning of fear.'' : During the first trials of the training, the organism experiences both CS and aversive US (escape-trials). The theory assumed that during those trials classical conditioning takes place by pairing the CS with the US. Because of the aversive nature of the US the CS is supposed to elicit a conditioned emotional reaction (CER) – fear. In classical conditioning, presenting a CS conditioned with an aversive US disrupts the organism's ongoing behavior. ; ''b) Reinforcement of the operant response by fear-reduction.'' : Because during the first process, the CS signaling the aversive US has itself become aversive by eliciting fear in the organism, reducing this unpleasant emotional reaction serves to motivate the operant response. The organism learns to make the response during the US, thus terminating the aversive internal reaction elicited by the CS. An important aspect of this theory is that the term "avoidance" does not really describe what the organism is doing. It does not "avoid" the aversive US in the sense of anticipating it. Rather the organism escapes an aversive internal state, caused by the CS. ==''Verbal Behavior''== {{Main|Verbal Behavior (book)}} In 1957, [[B. F. Skinner|Skinner]] published ''[[Verbal Behavior (book)|Verbal Behavior]]'', a theoretical extension of the work he had pioneered since 1938. This work extended the theory of operant conditioning to human behavior previously assigned to the areas of language, linguistics and other areas. ''Verbal Behavior'' is the logical extension of Skinner's ideas, in which he introduced new functional relationship categories such as intraverbals, [[Autoclitics (psychology)|autoclitics]], mands, tacts and the controlling relationship of the audience. All of these relationships were based on operant conditioning and relied on no new mechanisms despite the introduction of new functional categories. ==Four term contingency== Applied behavior analysis, which is the name of the discipline directly descended from Skinner's work, holds that behavior is explained in four terms: conditional stimulus (S<sup>C</sup>), a discriminative stimulus (S<sup>d</sup>), a response (R), and a reinforcing stimulus (S<sup>rein</sup> or S<sup>r</sup> for reinforcers, sometimes S<sup>ave</sup> for aversive stimuli).<ref>Pierce & Cheney (2004) Behavior Analysis and Learning</ref> ==Operant hoarding== '''Operant hoarding''' is a referring to the choice made by a rat, on a [[compound schedule]] called a [[multiple schedule]], that maximizes its rate of [[reinforcement]] in an operant conditioning context. More specifically, rats were shown to have allowed food pellets to accumulate in a food tray by continuing to press a lever on a [[continuous reinforcement]] schedule instead of retrieving those pellets. Retrieval of the pellets always instituted a one-minute period of [[extinction]] during which no additional food pellets were available but those that had been accumulated earlier could be consumed. This finding appears to contradict the usual finding that rats behave impulsively in situations in which there is a choice between a smaller food object right away and a larger food object after some delay. See [[schedules of reinforcement]].<ref>Cole, M.R. (1990). Operant hoarding: A new paradigm for the study of self-control. ''Journal of the Experimental Analysis of Behavior, 53'', 247–262.</ref> ==An alternative to the law of effect== However, an alternative perspective has been proposed by R. Allen and Beatrix Gardner.<ref>Gardner, R.A., & Gardner, B.T. (1988). Feedforward vs feedbackward: An ethological alternative to the law of effect. Behavioral and Brain Sciences. 11:429–447.</ref><ref>Gardner, R.A. & Gardner, B.T. (1998). The structure of learning from sign stimuli to sign language. Mahwah NJ: Lawrence Erlbaum Associates.</ref> Under this idea, which they called "feedforward," animals learn during operant conditioning by simple pairing of stimuli, rather than by the consequences of their actions. Skinner asserted that a rat or pigeon would only manipulate a lever if rewarded for the action, a process he called "shaping" (reward for approaching then manipulating a lever).<ref>Skinner, B.F. (1953). Science and human behavior. Oxford, England: Macmillan.</ref> However, in order to prove the necessity of reward (reinforcement) in lever pressing, a control condition where food is delivered without regard to behavior must also be conducted. Skinner never published this control group. Only much later was it found that rats and pigeons do indeed learn to manipulate a lever when food comes irrespective of behavior. This phenomenon is known as autoshaping.<ref> Brown, P., & Jenkins, H.M. (1968). Autoshaping of the pigeon's key-peck. J. Exp. Anal. Behav. 11:1–8.</ref> Autoshaping demonstrates that consequence of action is not necessary in an operant conditioning chamber, and it contradicts the law of effect. Further experimentation has shown that rats naturally handle small objects, such as a lever, when food is present.<ref>Timberlake, W. (1983). Rats' responses to a moving object related to food or water: A behavior-systems analysis. Animal Learning & Behavior. 11(3):309–320.</ref> Rats seem to insist on handling the lever when free food is available (contra-freeloading)<ref>Jensen, G.D. (1963). Preference for bar pressing over 'freeloading' as a function of number of rewarded presses. Journal of Experimental Psychology. 65:451–454.</ref><ref>Neuringer, A.J. (1969). Animals respond for food in the presence of free food. Science. 