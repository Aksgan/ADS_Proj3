and communication topology. '''Eden''' is not a skeleton language in the sense that skeletons are not provided as language constructs. Instead, skeletons are defined on top of Eden’s lower-level process abstraction, supporting both task and data parallelism. So, contrary to most other approaches, Eden lets the skeletons be defined in the same language and at the same level, the skeleton instantiation is written: Eden itself. Because Eden is an extension of a functional language, Eden skeletons are [[higher order function]]s. Eden introduces the concept of implementation skeleton, which is an architecture independent scheme that describes a parallel implementation of an algorithmic skeleton. ===eSkel=== The '''Edinburgh Skeleton Library''' ('''eSkel''') is provided in C and runs on top of MPI. The first version of eSkel was described in <ref>''Murray Cole.'' "Bringing skeletons out of the closet: a pragmatic manifesto for skeletal parallel programming." Parallel Computing, 30(3):389–406, 2004.</ref>, while a later version is presented in <ref>''A. Benoit, M. Cole, S. Gilmore, and J. Hillston.'' "Flexible skeletal programming with eskel." In J. C. Cunha and P. D. Medeiros, editors, Euro-Par, volume 3648 of Lecture Notes in Computer Science, pages 761–770. Springer, 2005.</ref>. In <ref>''A. Benoit and M. Cole.'' "Two fundamental concepts in skeletal parallel programming." In V. Sunderam, D. van Albada, P. Sloot, and J. Dongarra, editors, The International Confer-ence on Computational Science (ICCS 2005), Part II, LNCS 3515, pages 764–771. Springer Verlag, 2005.</ref>, nesting-mode and interaction-mode for skeletons are defined. The nesting-mode can be either transient or persistent, while the interaction-mode can be either implicit or explicit. Transient nesting means that the nested skeleton is instantiated for each invocation and destroyed Afterwards, while persistent means that the skeleton is instantiated once and the same skeleton instance will be invoked throughout the application. Implicit interaction means that the flow of data between skeletons is completely defined by the skeleton composition, while explicit means that data can be generated or removed from the flow in a way not specified by the skeleton composition. For example, a skeleton that produces an output without ever receiving an input has explicit interaction. Performance prediction for scheduling and resource mapping, mainly for pipe-lines, has been explored by Benoit et al.<ref>''A. Benoit, M. Cole, S. Gilmore, and J. Hillston.'' Evaluating the performance of skeleton-based high level parallel programs. In M. Bubak, D. van Albada, P. Sloot, and J. Dongarra, editors, The International Conference on Computational Science (ICCS 2004), Part III, LNCS 3038, pages 289–296. Springer Verlag, 2004.</ref><ref>''A. Benoit, M. Cole, S. Gilmore, and J. Hillston.'' "Evaluating the performance of pipeline structured parallel programs with skeletons and process algebra." Scalable Computing: Practice and Experience, 6(4):1–16, December 2005.</ref><ref>''A. Benoit, M. Cole, S. Gilmore, and J. Hillston.'' "Scheduling skeleton-based grid applications using pepa and nws." The Computer Journal, Special issue on Grid Performability Modelling and Measurement, 48(3):369–378, 2005.</ref><ref>''A. Benoit and Y. Robert.'' "Mapping pipeline skeletons onto heterogeneous platforms." In ICCS’2007, the 7th International Conference on Computational Science, LNCS 4487, pages 591–598. Springer Verlag, 2007.</ref>. They provided a performance model for each mapping, based on process algebra, and determine the best scheduling strategy based on the results of the model. More recent works have addressed the problem of adaptation on structured parallel programming <ref>''G. Yaikhom, M. Cole, S. Gilmore, and J. Hillston.'' "A structural approach for modelling performance of systems using skeletons." Electr. Notes Theor. Comput. Sci., 190(3):167–183,2007.</ref>, in particular for the pipe skeleton<ref>''H. Gonzalez-Velez and M. Cole''. "Towards fully adaptive pipeline parallelism for heterogeneous distributed environments." In Parallel and Distributed Processing and Applications, 4th International Symposium (ISPA), Lecture Notes in Computer Science, pages 916–926. Springer-Verlag, 2006.</ref><ref>''H. Gonzalez-Velez and M. Cole.'' "Adaptive structured parallelism for computational grids." In PPoPP ’07: Proceedings of the 12th ACM SIGPLAN symposium on Principles and practice of parallel programming, pages 140–141, New York, NY, USA, 2007. ACM.</ref>. ===HDC=== '''Higher-order Divide and Conquer''' ('''HDC''') <ref>''C. A. Herrmann and C. Lengauer.'' "HDC: A higher-order language for divide-and-conquer." Parallel Processing Letters, 10(2–3):239–250, 2000.</ref> is a subset of the functional language Haskell <ref>''P. Hudak, S. P. Jones, P. Wadler, B. Boutel, J. Fairbairn, J. Fasel, M. M. Guzm ́n, K. Hammond, J. Hughes, T. Johnsson, D. Kieburtz, R. Nikhil, W. Partain, and J. Peterson.'' "Report on the programming language haskell: a non-strict, purely functional language version 1.2." SIGPLAN Not., 27(5):1–164, 1992.</ref>. Functional programs are presented as polymorphic higher-order functions, which can be compiled into C/MPI, and linked with skeleton implementations. The language focus on divide and conquer paradigm, and starting from a general kind of divide and conquer skeleton, more specific cases with efficient implementations are derived. The specific cases correspond to: fixed recursion depth, constant recursion degree, multiple block recursion, elementwise operations, and correspondent communications <ref>''C. A. Herrmann.'' The Skeleton-Based Parallelization of Divide-and-Conquer Recursions. PhD thesis, 2000. ISBN 3-89722-556-5.".</ref> '''HDC''' pays special attention to the subproblem’s granularity and its relation with the number of Available processors. The total number of processors is a key parameter for the performance of the skeleton program as HDC strives to estimate an adequate assignment of processors for each part of the program. Thus, the performance of the application is strongly related with the estimated number of processors leading to either exceeding number of subproblems, or not enough parallelism to exploit available processors. ===HOC-SA=== HOC-SA is an [http://dev.globus.org/wiki/Guidelines#The_Globus_Incubator Globus Incubator project].<br/> HOC-SA stands for Higher-Order Components-Service Architecture. Higher-Order Components ([http://pvs.uni-muenster.de/pvs/forschung/hoc HOCs]) have the aim of simplifying Grid application development. <br/> The objective of HOC-SA is to provide Globus users, who do not want to know about all the details of the Globus middleware (GRAM RSL documents, Web services and resource configuration etc.), with HOCs that provide a higher-level interface to the Grid than the core Globus Toolkit.<br/> HOCs are Grid-enabled skeletons, implemented as components on top of the Globus Toolkit, remotely accessibly via Web Services<ref>''J. D&uuml;nnweber, S. Gorlatch.'' "Higher-Order Components for Grid Programming. Making Grids More Usable. ". Springer-Verlag, 2009. ISBN 978-3-642-00840-5</ref>. ===JaSkel=== '''JaSkel''' <ref>''J. F. Ferreira, J. L. Sobral, and A. J. Proenca.'' "Jaskel: A java skeleton-based framework for structured cluster and grid computing". In CCGRID 