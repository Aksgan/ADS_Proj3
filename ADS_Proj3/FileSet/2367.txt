one big tree was dispensed with in favor of an ensemble of interfacing representations which employed as many data-specific descriptions as necessary to capture the functionality of the diverse neurobiological manifestations of linguistic behavior being dealt with.'' Because target structuring was generable directly by the powerful J-rule base component and its array of linguistic operators, structure-oriented transformations required to combine kernel sentences and/or otherwise manipulate constituent structure were no longer required. Transformations formulated to generate correct word order and otherwise massage surface strings were supplanted by coding algorithms/grammars in the JG model. It may be said by way of general comparison that, whereas Chomsky's model of syntax was by design ''derivative'' (speaking of its roots in existing forms of notation), ''derivational,'' and ''manipulative,'' the JG model was ''seminal'' (speaking of its formal novelty), ''modular,'' and ''transpositional.'' Despite polar differences, however, ''Chomsky's objective of generating an infinite number of sentences with finite means, remained firmly intact in JG, as did the presumption of the fundamental innateness of natural language in the normal speaker/hearer.'' ===J-rules=== The base/junction rules (J-rules) of junction grammars are a set of algebraic formulas which generate for natural language what is akin to the [[Periodic Table]] of elements in chemistry, namely, an enumeration of well-formed linguistic structures<ref>Melby, Alan K. 1985. “Generalization and prediction of syntactic patterns in junction grammar”. In ''Linguistics and Philosophy.'' Festschrift for Rulon S. Wells, Makkai, Adam and Alan K. Melby (eds.).</ref> sometimes referred to as the ''Periodic Chart of Constituent structures'' (PCCS).<ref>See Lytle,Eldon G.(2009) ''LANGUAGE in Capital Letters'' (eBook edition), Chapters 4, 8. Rose Valley, NV: Linguistic Technologies, Inc. [http://www.language-icl.com]</ref> J-rules generate composite structures consisting of the labeled operands entering into them plus the relations established by operators, and assign a category to the composite produced, to wit: X ∘ Y ≐ Z. Composites thus generated become potential operands for subsequent operations. The resulting algebra may be represented in string form (e.g., infix, postfix, reverse polish) or graphed as a branching diagram (J-tree). ===Operators=== The universal operators utilized by these rules are ''subjunction'' (*), ''conjunction'' (&), and ''adjunction'' (+), plus subtypes required under particular circumstances, e.g., restrictive (.*) versus non-restrictive (=*=) under subjunction. Expressed in more familiar terms, subjunction joins modifiers and complements to their heads, conjunction bonds constituents of homogeneous category which are in some respect similar, and adjunction<ref>Not to be confused with ‘Chomskyan adjunction.’</ref> attaches relations and processes to their operands to form predicates, statements, and relational phrases. Supplemental operators effect the requirements of data management in [[mental model]]ing and conversational settings, corresponding in large part to the conventional classification of [[deixis]].<ref>Lytle, Eldon G. (1979) “Doing More with Structure.” ''JUNCTION THEORY AND APPLICATION'', V. 2, no. 2, Spring 1979. Provo, Utah : BYU Translation Sciences Institute. [http://www.junction-grammar.com/html/doing_more_with_structure.htm]</ref> ===Operands=== The operands of the base are drawn from a dictionary of [[sememe]]s (meaningful concepts) which are by definition non-lexical in JG and may be plausibly viewed as electromagnetic signatures in their neurobiological setting<ref>See Presman, A.S. (1970) ''Electromagnetic Fields and Life.'' New York:Plenum Press, 1 edition. Translation of “Elektromagnitnye polia i zhivaia priroda” by F.L. Sinclair; edited by Frank A. Brown, Jr.</ref> arising in connection with the formation of the mental models which provide the content and sensory linkages for their meanings. ===Coding Grammars=== While the link between ''signified'' and ''signifier'' (as per Saussure) may be separately represented in a junction grammar, the interfacing between J-rule structuring and the coding extant in other components of the model is provided by context-sensitive coding grammars formulated as [[algorithm]]s in an appropriate [[pattern matching]] language. For example, JG incorporates a lexical coding grammar consisting of ''lexical rules'' (L-rules) which encodes unordered sememic structuring as ordered lexical strings in a separate coding space.<ref>See, for example, Billings, Floyd and Thompson, Tracy (1972). “Proposals for Ordering Well-formed Syntactic  Statements.” ''LINGUISTICS SYMPOSIUM: AUTOMATIC LANGUAGE PROCESSING'', 30–31 March 1972. Provo, Utah: BYU Language Research Center.[http://www.junction-grammar.com/html/ordering_well-formed_syntactic.htm]</ref> A subsequent coding provides either the distinct patterning of the voice contour, or the formatting and punctuation of printed material. ===Nature of JG Analysis=== With the foregoing as a frame of reference, we draw renewed attention to significant differences between JG sentence analysis and conventional syntactic analysis. The more familiar syntax approach analyzes phrases and sentences in terms of outward ('surface') appearance, i.e. in terms of the words which they contain and how intuition groups them. Structural diagrams reflecting this method strive to depict constituent clusters in the word stream supplemented by labels, perhaps, or other information of focal interest to the analyst - some of it perhaps semantic. A change in word order requires that the diagram be changed. In contrast, the JG approach, while taking note of the words, looks beyond them to the base constructions from which they have presumably been encoded, concentrating all the while on the semantic effects associated with the constituents and their structural nuances. JG diagrams (J-trees), therefore, are not directly representative of the word stream but, rather, of rational constructs in the neural mass having linkage with the words which we read or write. This means that a variety of structuring detail made explicit in J-trees is only implicit in the word stream. Conversely, it means that certain lexical detail made explicit in the word stream is only implicit in J-trees. For example, depending upon the ordering rules of the lexical coding grammar in play ''and'' the discourse context of the sentence - the same J-tree may yield alternative word orders in the lexical coding space. The overall effect - as previously noted - is that, inasmuch as JG uses ''coding'' rather than ''derivation'' as a bridge between levels of representation, much that models of syntax have been preoccupied with in deriving ''surface structure'' from ''deep structure'' (movement, deletion, insertion, etc.) is taken over in JG by coding operations. ==Early Application== The first junction grammar was worked out by Eldon Lytle in connection with his Ph.D. dissertation during the late ‘60s,<ref>Lytle, Eldon G. (1972) ''Structural Derivation in Russian.'' Ph.D. Dissertation. University of Illinois, Champaign/Urbana</ref> in which he constructed such a 