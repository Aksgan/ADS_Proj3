</math> </div> If the truth of a proposition can be established in more than one way, the corresponding connective has multiple introduction rules. <div style="margin-left: 2em"> <math> \frac{A\hbox{ true}}{A \vee B\hbox{ true}}\ \vee_{I1} \qquad \frac{B\hbox{ true}}{A \vee B\hbox{ true}}\ \vee_{I2} </math> </div> Note that in the nullary case, ''i.e.'', for falsehood, there are ''no'' introduction rules. Thus one can never infer falsehood from simpler judgments. Dual to introduction rules are ''elimination rules'' to describe how to de-construct information about a compound proposition into information about its constituents. Thus, from "''A ∧ B'' true", we can conclude "''A'' true" and "''B'' true": <div style="margin-left: 2em"> <math> \frac{A \wedge B\hbox{ true}}{A\hbox{ true}}\ \wedge_{E1} \qquad \frac{A \wedge B\hbox{ true}}{B\hbox{ true}}\ \wedge_{E2} </math> </div> As an example of the use of inference rules, consider commutativity of conjunction. If ''A ∧ B'' is true, then ''B ∧ A'' is true; This derivation can be drawn by composing inference rules in such a fashion that premises of a lower inference match the conclusion of the next higher inference. <div style="margin-left: 2em"> <!-- there are serious vertical spacing issues here, but since Wikipedia's texvc parser doesn't support \displaystyle, our hands are tied somewhat --> <math> \cfrac{\cfrac{A \wedge B\hbox{ true}}{B\hbox{ true}}\ \wedge_{E2} \qquad \cfrac{A \wedge B\hbox{ true}}{A\hbox{ true}}\ \wedge_{E1}} {B \wedge A\hbox{ true}}\ \wedge_I </math> </div> The inference figures we have seen so far are not sufficient to state the rules of implication introduction or disjunction elimination; for these, we need a more general notion of ''hypothetical derivation''. ==Hypothetical derivations== A pervasive operation in mathematical logic is ''reasoning from assumptions''. For example, consider the following derivation: <div style="margin-left: 2em"> <math> \cfrac{A \wedge \left ( B \wedge C \right ) \ true}{\cfrac{B \wedge C \ true}{B \ true} \wedge_{ E_1}} \wedge_{ E_2} </math> </div> This derivation does not establish the truth of ''B'' as such; rather, it establishes the following fact: :If ''A ∧ (B ∧ C) is true'' then ''B is true''. In logic, one says "''assuming A ∧ (B ∧ C) is true, we show that B is true''"; in other words, the judgement "''B true''" depends on the assumed judgement "''A ∧ (B ∧ C) true''". This is a ''hypothetical derivation'', which we write as follows: <div style="margin-left: 2em"> <math> \begin{matrix} A \wedge \left ( B \wedge C \right ) \ true \\ \vdots \\ B \ true \end{matrix} </math> </div> The interpretation is: "''B true'' is derivable from ''A ∧ (B ∧ C) true''". Of course, in this specific example we actually know the derivation of "''B true''" from "''A ∧ (B ∧ C) true''", but in general we may not ''a-priori'' know the derivation. The general form of a hypothetical derivation is: <div style="margin-left: 2em"> <math> \begin{matrix} D_1 \quad D_2 \cdots D_n \\ \vdots \\ J \end{matrix} </math> </div> Each hypothetical derivation has a collection of ''antecedent'' derivations (the ''D<sub>i</sub>'') written on the top line, and a ''succedent'' judgement (''J'') written on the bottom line. Each of the premises may itself be a hypothetical derivation. (For simplicity, we treat a judgement as a premise-less derivation.) The notion of hypothetical judgement is ''internalised'' as the connective of implication. The introduction and elimination rules are as follows. <div style="margin-left: 2em"> <math> \cfrac{ \begin{matrix} \cfrac{}{A \ true} u \\ \vdots \\ B \ true \end{matrix} }{A \supset B \ true} \supset_{I^u} \qquad \cfrac{A \supset B \ true \quad A \ true}{B \ true} \supset_E </math> </div> In the introduction rule, the antecedent named ''u'' is ''discharged'' in the conclusion. This is a mechanism for delimiting the ''scope'' of the hypothesis: its sole reason for existence is to establish "''B true''"; it cannot be used for any other purpose, and in particular, it cannot be used below the introduction. As an example, consider the derivation of "''A ⊃ (B ⊃ (A ∧ B)) true''": <div style="margin-left: 2em"> <math> \cfrac{\cfrac{\cfrac{{}}{A \ true} u \quad \cfrac{{}}{B \ true} w}{A \wedge B \ true}\wedge_I}{ \cfrac{B \supset \left ( A \wedge B \right ) \ true}{ A \supset \left ( B \supset \left ( A \wedge B \right ) \right ) \ true } \supset_{I^u} } \supset_{I^w} </math> </div> This full derivation has no unsatisfied premises; however, sub-derivations ''are'' hypothetical. For instance, the derivation of "''B ⊃ (A ∧ B) true''" is hypothetical with antecedent "''A true''" (named ''u''). With hypothetical derivations, we can now write the elimination rule for disjunction: <div style="margin-left: 2em"> <math> \cfrac{ A \vee B \hbox{ true} \quad \begin{matrix} \cfrac{}{A \ true} u \\ \vdots \\ C \ true \end{matrix} \quad \begin{matrix} \cfrac{}{B \ true} w \\ \vdots \\ C \ true \end{matrix} }{C \ true} \vee_{E^{u,w}} </math> </div> In words, if ''A ∨ B'' is true, and we can derive ''C true'' both from ''A true'' and from ''B true'', then ''C'' is indeed true. Note that this rule does not commit to either ''A true'' or ''B true''. In the zero-ary case, ''i.e.'' for falsehood, we obtain the following elimination rule: <div style="margin-left: 2em"> <math> \frac{\perp true}{C \ true} \perp_E </math> </div> This is read as: if falsehood is true, then any proposition ''C'' is true. Negation is similar to implication. <div style="margin-left: 2em"> <math> \cfrac{ \begin{matrix} \cfrac{}{A \ true} u \\ \vdots \\ p \ true \end{matrix} }{\lnot A \ true} \lnot_{I^{u,p}} \qquad \cfrac{\lnot A \ true \quad A \ true}{C \ true} \lnot _E </math> </div> The introduction rule discharges both the name of the hypothesis ''u'', and the succedent ''p'', ''i.e.'', the proposition ''p'' must not occur in the conclusion '' A''. Since these rules are schematic, the interpretation of the introduction rule is: if from "''A true''" we can derive for every proposition ''p'' that "''p true''", then ''A'' must be false, ''i.e.'', "''not A true''". For the elimination, if both ''A'' and ''not A'' are shown to be true, then there is a contradiction, in which case every proposition ''C'' is true. Because the rules for implication and negation are so similar, it should be fairly easy to see that ''not 