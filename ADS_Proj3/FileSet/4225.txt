several others), plus a [[random error]]. Models often involve making a structural assumption about the form of the functional relationship here: for example, as in [[linear regression]]. This can be generalised to models involving relationships between underlying unobserved [[latent variable]]s. **Cross-variation assumptions. These assumptions involve the [[joint probability distribution]]s of either the observations themselves or the random errors in a model. Simple models may include the assumption that observations or errors are [[statistically independent]]. ==Checking assumptions== Given that the validity of conclusions drawn from a statistical analysis depend on the validity of any assumptions made, it is clearly important that these assumptions should be reviewed at some stage. In some instances, for example where data are lacking, this may have to be restricted to just making a judgement about whether an assumption is reasonable. This can be expended slightly to trying to judge what effect a departure from the assumptions might have. Where more extensive data are available, various types of procedure for statistical model validation are available, in particular for [[regression model validation]]. ==See also== * [[Misuse of statistics]] ==Notes== <references/> {{More footnotes|date=February 2010}} ==Bibliography== * {{cite journal|title=Miracles and Statistics: The Casual Assumption of Independence (ASA Presidential address) |authorlink=William Kruskal |first=William |last=Kruskal |journal=Journal of the American Statistical Association |volume=83 |issue=404 |month=December |year=1988 |pages=929–940 |url=http://www.jstor.org/stable/2290117 }} {{jstor|2290117}} ==References== *McPherson, G. (1990) ''Statistics in Scientific Investigation: Its Basis, Application and Interpretation'', Springer-Verlag. ISBN 0-387-97137-8 {{DEFAULTSORT:Statistical Assumption}} [[Category:Statistical theory]] [[Category:Data analysis]] [[ar:فرضية إحصائية]]</text> </page> <page> <id>35661</id> <title>Statistical semantics</title> <text>{{linguistics}} '''Statistical semantics''' is the study of "how the statistical patterns of human word usage can be used to figure out what people mean, at least to a level sufficient for information access" ([[George Furnas|Furnas]], 2006). How can we figure out what words mean, simply by looking at patterns of words in huge collections of text? What are the limits to this approach to understanding words? ==History== The term ''Statistical Semantics'' was first used by [[Warren Weaver|Weaver]] (1955) in his well-known paper on [[machine translation]]. He argued that [[word sense disambiguation]] for machine translation should be based on the [[co-occurrence]] frequency of the context words near a given target word. The underlying assumption that "a word is characterized by the company it keeps" was advocated by [[J. R. Firth|J.R. Firth]] (1957). This assumption is known in [[Linguistics]] as the [[Distributional hypothesis|Distributional Hypothesis]]. Delavenay (1960) defined ''Statistical Semantics'' as "Statistical study of meanings of words and their frequency and order of recurrence." [[George Furnas|Furnas]] et al. (1983) is frequently cited as a foundational contribution to Statistical Semantics. An early success in the field was [[Latent semantic analysis|Latent Semantic Analysis]]. ==Applications of statistical semantics== Research in Statistical Semantics has resulted in a wide variety of algorithms that use the Distributional Hypothesis to discover many aspects of [[semantics]], by applying statistical techniques to [[Text corpus|large corpora]]: * Measuring the [[Semantic similarity|similarity in word meanings]] (Lund et al., 1995; Landauer and Dumais, 1997; McDonald and Ramscar, 2001, Terra and Clarke, 2003) * Measuring the similarity in word relations (Turney, 2006) * Modeling [[similarity-based generalization]] (Yarlett, 2008) * Discovering words with a given relation (Hearst, 1992) * Classifying relations between words (Turney and Littman, 2005) * Extracting keywords from documents (Frank et al., 1999; Turney, 2000) * Measuring the cohesiveness of text (Turney, 2003) * Discovering the different senses of words (Pantel and Lin, 2002) * Distinguishing the different senses of words (Turney, 2004) * Subcognitive aspects of words (Turney, 2001) * Distinguishing praise from criticism (Turney and Littman, 2003) ==Related fields== Statistical Semantics focuses on the meanings of common words and the relations between common words, unlike [[text mining]], which tends to focus on whole documents, document collections, or named entities (names of people, places, and organizations). Statistical Semantics is a subfield of [[computational semantics]], which is in turn a subfield of [[computational linguistics]] and [[natural language processing]]. Many of the applications of Statistical Semantics (listed above) can also be addressed by [[lexicon]]-based algorithms, instead of the [[text corpus|corpus]]-based algorithms of Statistical Semantics. One advantage of corpus-based algorithms is that they are typically not as labour-intensive as lexicon-based algorithms. Another advantage is that they are usually easier to adapt to new languages than lexicon-based algorithms. However, the best performance on an application is often achieved by combining the two approaches (Turney et al., 2003). ==See also== {{Portal|Linguistics}} *[[Latent semantic analysis]] *[[Latent semantic indexing]] *[[Text mining]] *[[Information retrieval]] *[[Natural language processing]] *[[Computational linguistics]] *[[Web mining]] *[[Semantic similarity]] *[[Co-occurrence]] *[[Text corpus]] *[[Semantic Analytics]] ==External links== *[http://www.si.umich.edu/people/faculty-detail.htm?sid=41 George Furnas] *[http://research.microsoft.com/%7Esdumais/ Susan Dumais] *[http://www.pearsonkt.com/bioLandauer.shtml Thomas Landauer] *[http://www.apperceptual.com/ Peter Turney] *[http://waldron.stanford.edu/~michael/papers/ Michael Ramscar] *[http://www.cs.ualberta.ca/~lindek/demos.htm Dekang Lin's Demos] *[http://www.isi.edu/~pantel/Content/demos.htm Patrick Pantel's Demos] *[http://www.nzdl.org/Kea/ Kea keyphrase extraction] *[http://seokeywordanalysis.com/seotools/ Online keyphrase extractor] ==References== * Delavenay, E. (1960). ''An Introduction to Machine Translation'', New York, NY: Thames and Hudson. * Firth, J.R. (1957). A synopsis of linguistic theory 1930-1955. In ''Studies in Linguistic Analysis'', pp. 1–32. Oxford: Philological Society. Reprinted in F.R. Palmer (ed.), ''Selected Papers of J.R. Firth 1952-1959'', London: Longman (1968). * Frank, E., Paynter, G.W., Witten, I.H., Gutwin, C., and Nevill-Manning, C.G. (1999). Domain-specific keyphrase extraction. In ''Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence (IJCAI-99)'', pp. 668–673. California: Morgan Kaufmann. * Furnas, G.W., Landauer, T.K., Gomez, L.M., and Dumais, S.T. (1983). Statistical semantics: Analysis of the potential performance of keyword information systems. ''Bell System Technical Journal'', 62(6):1753-1806. * Furnas, G.W. (2006). [http://www.si.umich.edu/people/faculty-detail.htm?sid=41 Faculty Profile: George Furnas], University of Michigan, School of Information, URL verified on October 2, 2006. * Hearst, M.A. (1992). Automatic acquisition of hyponyms from large text corpora. In ''Proceedings of the Fourteenth International Conference on Computational Linguistics'', pages 539–545, Nantes, France. * Landauer, T.K., and Dumais, S.T. (1997). A solution to Plato's problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge. ''Psychological Review'', 104(2):211–240. * Lund, K., Burgess, C., and Atchley, R.A. (1995). Semantic and associative priming in high-dimensional semantic space. In ''Proceedings of the 17th Annual Conference of the Cognitive Science Society'', pages 660-665. * McDonald, S., and Ramscar, M. (2001). [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.104.7535&rep=rep1&type=pdf 