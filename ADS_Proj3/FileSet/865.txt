external parties. Rigid authentication mechanisms, such as [[Public Key Infrastructure]]s (PKIs)<ref>{{Cite journal| author = Weise J. | title = Public Key Infrastructure Overview. | publisher = SunPs Global Security Practice, SunMicrosystems. | date = August 2001}}</ref> or [[Kerberos]]<ref>{{Cite journal| author = Kohl J. & B. C. Neuman | title = The Kerberos Network Authentication Service(Version 5). | publisher = Internet Request for Comments RFC-1510. | year = 1993}}</ref> have allowed this model to be extended to [[distributed systems]] within a few closely collaborating domains or within a single administrative domain. During the last years, Computer Science has moved from centralised computer systems to distributed computing. This evolution has several implications on the security models, the policies and the mechanisms needed to protect users’ information and resources in an increasingly interconnected computing infrastructure.<ref>{{Cite journal| author = Seigneur J.M | title = Trust, Security and Privacy in Global Computing. | publisher = PhD Thesis, University of Dublin, Trinity College | year = 2005}}</ref> Identity-based security mechanisms cannot [[authorization|authorise]] an operation without [[authenticating]] the claiming entity. This means that no interaction can occur unless both parties known their authentication frameworks. Spontaneous interactions would, therefore, require a single, or a few trusted [[certificate authorities]] (CAs). In the present context, PKI has not been considered since they have shown difficulties to emerge, thus it is not so probable that they will establish themselves as a reference standard in the near future. In the present, a user who wishes to join spontaneous collaboration with another party can choose between enabling security and thereby disabling spontaneous collaboration, or disabling security and enabling spontaneous collaboration. It is fundamental that mobile users and devices can authenticate in an autonomous way without relying on a common authentication infrastructure. In order to face this problem, we need to examine the challenges introduced by ”Global Computing“,<ref>{{Cite journal | title = IST, Global Computing, EU | publisher = http://www.cordis.lu/ist/fet/gc.htm. | year = 2004}}</ref> a term coined by the [[EU]] for the future of the global information society, and to identify their impact on security. ==History== Computational Trust applies the human notion of [[Trust (social sciences)|trust]] into the digital world, that is seen as malicious rather than cooperative. The expected benefits, according to Marsh et al., result in an exploitation of others' ability through delegation and in an achievement of more cooperation in an open and less protected environment. The scientiﬁc research in the area of computational mechanism for trust and reputation in [[virtual community|virtual societies]] is oriented to increase the reliability and performance of electronic communities.<ref>{{Cite journal| author = Longo L., Dondio P., Barrett S. | title = Temporal Factors to evaluate trustworthiness of virtual identities | publisher = Third International Workshop on the Value of Security through Collaboration, SECURECOMM | year = 2007}}</ref> A trust-based decision in a specific domain is a multi-stage process. The first step of this process consists in identifying and selecting the proper input data, that is, the trust evidences. In general, these are domain-specific and they result from an analysis conducted over the [[application software|application]] involved. In the next step, a trust computation is performed over evidences to produce Trust values, that means the estimation of the trustworthiness of entities in that particular domain. The selection of evidences and the subsequent trust computation are informed by a notion of Trust, defined in the Trust model. Finally, the trust decision is taken by considering the computed values and exogenous factors, like disposition or [[IT risk management#risk assessment|risk assessment]]s. ==Defining Trust== These concepts have been acquiring a great relevance in the last decade in the computer science field, mostly in the area of distributed [[artificial intelligence]]. The multi-agent system paradigm and the huge evolution of [[e-commerce]] are factors that contributed to the increase of interest on trust and reputation. In fact, Trust and [[reputation systems]] have been recognized as the key factors for a successful electronic commerce adoption. These systems are used by intelligent software agents as an incentive in decision-making, when deciding whether or not to honor contracts, and as a mechanism to search trustworthy exchange partners. In particular, reputation is used in electronic markets as a trust-enforcing mechanism or as a method to avoid cheaters and frauds.<ref>{{Cite journal| author = Dellarocas C. | title = The digitalization of Word-Of-Mouth: Promise and Challenges of Online Reputation Mechanism | publisher = Management Science, | year = 2003 }}</ref> Another area of application of these concepts, in agent technology, is teamwork and cooperation.<ref>{{Cite journal| author = Montaner M., Lopez B., De La Rosa J. | title = Developing Trust in Recommender Agents. | publisher = Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS-02) | year = 2002}}</ref> Several definitions of the human notion of trust have been proposed during the last years in different domains from [[sociology]], [[psychology]] to [[political science|political]] and [[business science]]. These definitions may even change in accordance with the application domain. For example, Romano’s recent definition<ref>{{Cite journal| author = Romano D.M. | title = The Nature of Trust: Conceptual and Operational Clarification | publisher = Louisiana State University, PhD Thesis | year = 2003}}</ref> tries to encompass the previous work in all these domains: {{quote|Trust is a subjective assessment of another’s influence in terms of the extent of one’s perception about the quality and significance of another’s impact over one’s outcomes in a given situation, such that one’s expectation of, openness to, and inclination toward such influence provide a sense of control over the potential outcomes of the situation.}} Trust and reputation both have a social value. When someone is trustworthy, that person may be expected to perform in a beneficial or at least not in a suspicious way that assure others, with high probability, good collaborations with him. On the contrary, when someone appears not to be trustworthy, others refrain from collaborating since there is a lower level of probability that these collaborations will be successful.<ref>{{Cite journal| author = Gambetta D. | title = Can We Trust Trust. | 