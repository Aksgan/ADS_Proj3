of the likelihood function, called the '''log-likelihood''', than in terms of the likelihood function itself. Because the logarithm is a [[monotonically increasing]] function, the logarithm of a function achieves its [[maximum]] value at the same points as the function itself, and hence the log-likelihood can be used in place of the likelihood in [[maximum likelihood]] estimation and related techniques. Finding the maximum of a function often involves taking the [[derivative]] of a function and solving for the parameter being maximized, and this is often easier when the function being maximized is a log-likelihood rather than the original likelihood function. For example, some likelihood functions are for the parameters that explain a collection of statistically independent observations. In such a situation, the likelihood function factors into a product of individual likelihood functions. The logarithm of this product is a sum of individual logarithms, and the [[derivative]] of a sum of terms is often easier to compute than the derivative of a product. In addition, several common distributions have likelihood functions that contain products of factors involving [[exponentiation]]. The logarithm of such a function is a sum of products, again easier to differentiate than the original function. As an example, consider the [[gamma distribution]], whose likelihood function is :<math>L (\alpha, \beta|x) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}</math> and suppose we wish to find the maximum likelihood estimate of β for a single observed value ''x''. This function looks rather daunting. Its logarithm, however, is much simpler to work with: :<math>\log L(\alpha,\beta|x) = \alpha \log \beta - \log \Gamma(\alpha) + (\alpha-1) \log x - \beta x\,.</math> The [[partial derivative]] with respect to β is simply :<math>\frac{\partial \log L(\alpha,\beta|x)}{\partial \beta} = \frac{\alpha}{\beta} - x</math> If there are a number of samples ''x''<sub>1</sub>,…,''x''<sub>''n''</sub>, then the joint log-likelihood will be the sum of individual log-likelihoods, and the derivative of this sum will be the sum of individual derivatives: :<math>\frac{n \alpha}{\beta} - \sum_{i=1}^n x_i</math> Setting this equal to zero and solving for <math>\beta</math> yields :<math>\beta^* = \frac{\alpha}{\bar{x}}</math> where <math>\beta^*\,</math> represents the maximum-likelihood estimate and <math>\bar{x} = \frac{1}{n} \sum_{i=1}^n x_i</math> is the [[sample mean]] of the observations. ==Likelihood function of a parameterized model== Among many applications, we consider here one of broad theoretical and practical importance. Given a [[parameterized family]] of [[probability density function]]s (or [[probability mass function]]s in the case of discrete distributions) :<math>x\mapsto f(x\mid\theta), \!</math> where ''θ'' is the parameter, the '''likelihood function''' is :<math>\theta\mapsto f(x\mid\theta), \!</math> written :<math>L(\theta \mid x)=f(x\mid\theta), \!</math> where ''x'' is the observed outcome of an experiment. In other words, when ''f''(''x'' | ''θ'') is viewed as a function of ''x'' with ''θ'' fixed, it is a probability density function, and when viewed as a function of ''θ'' with ''x'' fixed, it is a likelihood function. ''Note:'' This is ''not'' the same as the probability that those parameters are the right ones, given the observed sample. Attempting to interpret the likelihood of a hypothesis given observed evidence as the probability of the hypothesis is a common error, with potentially disastrous real-world consequences in medicine, engineering or jurisprudence. See [[prosecutor's fallacy]] for an example of this. From a geometric standpoint, if we consider ''f'' (''x'', ''θ'') as a function of two variables then the family of probability distributions can be viewed as level curves parallel to the ''x'' -axis, while the family of likelihood functions are the orthogonal level curves parallel to the θ-axis. ===Likelihoods for continuous distributions=== The use of the [[probability density]] instead of a probability in specifying the likelihood function above may be justified in a simple way. Suppose that, instead of an exact observation, ''x'', the observation is the value in a short interval (''x''<sub>''j''&minus;1</sub>, ''x''<sub>''j''</sub>), with length ''Δ''<sub>''j''</sub>, where the subscripts refer to a predefined set of intervals. Then the probability of getting this observation (of being in interval ''j'') is approximately :<math>L_\text{approx}(\theta \mid x \text{ in interval } j)=\Delta_j f(x_{*}\mid\theta), \!</math> where ''x''<sub>*</sub> can be any point in interval ''j''. Then, recalling that the likelihood function is defined up to a multiplicative constant, it is just as valid to say that the likelihood function is approximately :<math>L_\text{approx}(\theta \mid x \text{ in interval } j)= f(x_{*}\mid\theta), \!</math> and then, on considering the lengths of the intervals to decrease to zero, :<math>L(\theta \mid x )= f(x\mid\theta). \!</math> ===Likelihoods for mixed continuous &mdash; discrete distributions=== The above can be extended in a simple way to allow consideration of distributions which contain both discrete and continuous components. Suppose that the distribution consists of a number of discrete probability masses ''p<sub>k</sub>''(θ) and a density ''f''(''x'' | ''θ''), where the sum of all the ''p'''s added to the integral of ''f'' is always one. Assuming that it is possible to distinguish an observation corresponding to one of the discrete probability masses from one which corresponds to the density component, the likelihood function for an observation from the continuous component can be dealt with as above by setting the interval length short enough to exclude any of the discrete masses. For an observation from the discrete component, the probability can either be written down directly or treated within the above context by saying that the probability of getting an observation in an interval that does contain a discrete component (of being in interval ''j'' which contains discrete component ''k'') is approximately :<math>L_\text{approx}(\theta \mid x \text{ in interval } j \text{ containing discrete mass } k)=p_k(\theta)+\Delta_j f(x_{*}\mid\theta), \!</math> where x<sub>*</sub> can be any point in interval ''j''. Then, on considering the lengths of the intervals to decrease to zero, the likelihood function for a observation from the discrete component is :<math>L(\theta \mid x )= p_k(\theta), \!</math> where ''k'' is the index of the discrete probability mass corresponding to observation ''x''. The fact that the likelihood function can be defined in a way that includes contributions that are not commensurate (the density and the probability mass) arises from the way in which the likelihood function is defined up to a constant of proportionality, where this "constant" can change with the observation ''x'', but not with the parameter 