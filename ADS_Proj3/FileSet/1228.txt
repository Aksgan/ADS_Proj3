obtained locks on resources, it is possible to produce a situation where each is preventing another from obtaining a lock, and none of them can proceed. This is known as a ''deadly embrace'' or [[deadlock]]. A simple example is when Process 1 has obtained an exclusive lock on Resource A, and Process 2 has obtained an exclusive lock on Resource B. If Process 1 then tries to lock Resource B, it will have to wait for Process 2 to release it. But if Process 2 then tries to lock Resource A, both processes will wait forever for each other. The OpenVMS DLM periodically checks for deadlock situations. In the example above, the second lock enqueue request of one of the processes would return with a deadlock status. It would then be up to this process to take action to resolve the deadlock &mdash; in this case by releasing the first lock it obtained. ==Linux clustering== Both [[Red Hat]] and [[Oracle Corporation|Oracle]] have developed clustering software for [[Linux]]. [[OCFS|OCFS2]], the Oracle Cluster File System was added<ref>http://www.kernel.org/git/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=29552b1462799afbe02af035b243e97579d63350</ref> to the official [[Linux kernel]] with version 2.6.16, in January 2006. The alpha-quality code warning on OCFS2 was removed in 2.6.19. Red Hat's cluster software, including their DLM and [[Global File System]] was officially added to the Linux kernel <ref>http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=commit;h=1c1afa3c053d4ccdf44e5a4e159005cdfd48bfc6</ref> with version 2.6.19, in November 2006. Both systems use a DLM modeled on the venerable VMS DLM.<ref>http://lwn.net/Articles/137278/</ref> Oracle's DLM has a simpler API. (the core function, <code>dlmlock()</code>, has eight parameters, whereas the VMS <small><code>SYS$ENQ</code></small> service and Red Hat's <tt>dlm_lock</tt> both have 11.) ==Google's Chubby lock service== [[Google]] has developed ''Chubby'', a lock service for loosely-coupled distributed systems<ref name="chubby">http://labs.google.com/papers/chubby.html</ref>. It is designed for coarse-grained locking and also provides a limited but reliable distributed file system. Key parts of Google's infrastructure, including [[Google File System]], [[BigTable]], and [[MapReduce]], use Chubby to synchronize accesses to shared resources. Though Chubby was designed as a lock service, it is now heavily used inside Google as a [[name server]], supplanting [[Domain name system|DNS]]<ref name="chubby" />. ==SSI Systems== A DLM is also a key component of more ambitious [[Single-system image|single system image]] projects such as [[OpenSSI]]. ==References== {{Reflist}} {{Refbegin}} *[http://h71000.www7.hp.com/doc/82FINAL/4527/4527pro_044.html#jun_227 HP OpenVMS Systems Services Reference Manual &ndash; $ENQ] *[http://www.arcs.us ARCS - A Web Service used as a Distributed Lock Manager] {{Refend}} {{DEFAULTSORT:Distributed Lock Manager}} [[Category:Distributed computing architecture]] [[ja:分散ロックマネージャ]]</text> </page> <page> <id>10801</id> <title>Distributed network block device</title> <text>{{Orphan|date=November 2006}} {{primarysources|date=April 2007}} A '''Distributed Network Block Device (DNBD)''' is a read-only and caching [[network block device]] and supports following main features: * replication of [[server (computing)|server]]s for robustness * multicast communication and [[caching]] of network traffic for [[scalability]] These characteristics make it suitable especially for use in [[wireless networks]], e.g. for [[diskless client]]s or to share multimedia files in such an environment. The servers can export a file or block device equipped with an operating system, movies, music, etc. Several clients can import the block device and access it like a local [[hard disk]]. However, each block transfer over the network can be cached by all clients: If several users on each client start to watch a movie within a certain time interval, the movie data has to be transmitted only once (depending on the [[cache]] size). The network is not burdened with unnecessary traffic. DNBD can be used together with [[cowloop]] [1] or [[unionfs]] [2] in order to get local write [[semantics]], e.g. for diskless clients. Especially in wireless environments with limited [[Bandwidth (computing)|bandwidth]], caching can increase [[boot-up]] time enormously. ==External links== * [https://sourceforge.net/projects/dnbd/ Sourceforge.net] [[Category:Computer networking]]</text> </page> <page> <id>10812</id> <title>Distributed transaction</title> <text>A '''distributed transaction''' is an [[operations bundle]], in which two or more network hosts are involved. Usually, hosts provide '''transactional resources''', while the '''transaction manager''' is responsible for creating and managing a global transaction that encompasses all operations against such resources. Distributed transactions, as any other [[Database transaction|transactions]], must have all four [[ACID]] properties, where atomicity guarantees all-or-nothing outcomes for the unit of work (operations bundle). Open Group, a vendor consortium, proposed the [[X/Open XA|X/Open Distributed Transaction Processing (DTP) Model]] (X/Open XA), which became a de-facto standard for behavior of transaction model components. Databases are common transactional resources and, often, transactions span a couple of such databases. In this case, a distributed transaction can be seen as a [[database transaction]] that must be [[synchronized]] (or provide [[ACID]] properties) among multiple participating [[database]]s which are [[distributed computing|distributed]] among different physical locations. The [[isolation (computer science)|isolation]] property (the I of ACID) poses a special challenge for multi database transactions, since the (global) [[serializability]] property could be violated, even if each database provides it (see also [[global serializability]]). In practice most commercial database systems use [[Two phase locking|strong strict two phase locking (SS2PL)]] for [[concurrency control]], which ensures global serializability, if all the participating databases employ it. (see also [[commitment ordering]] for multidatabases.) A common [[algorithm]] for ensuring [[correctness|correct]] completion of a distributed transaction is the [[two-phase commit]] (2PC). This algorithm is usually applied for updates able to [[commit (data management)|commit]] in a short period of time, ranging from couple of milliseconds to couple of minutes. There are also long-lived distributed transactions, for example a transaction to book a trip, which consists of booking a flight, a rental car and a hotel. Since booking the flight might take up to a day to get a confirmation, two-phase commit is not applicable here, it will lock the resources for this long. In this case more sophisticated techniques that involve multiple undo levels are used. The way you can undo the hotel booking by calling a desk and cancelling the reservation, a system can be designed to undo certain operations (unless they are irreversibly finished). In practice, long-lived distributed transactions are implemented in systems based on [[Web Services]]. Usually these transactions utilize principles of [[Compensating transaction]]s, Optimism and Isolation Without Locking. X/Open standard does not cover long-lived DTP. Several modern technologies, including [[Enterprise Java Beans]] (EJBs) and [[Microsoft Transaction Server]] (MTS) fully support distributed transaction standards. ==References== * {{cite web | title=Web-Services Transactions | work=Web-Services Transactions | 