interchangeability guarantees a nearly unlimited quantity of data close at hand. [[Magnetic tape data storage|Magnetic tape]] provided archival capability for this data, at a lower cost than disk. Many second generation CPUs delegated peripheral device communications to a secondary processor. For example, while the communication processor controlled [[Unit record equipment|card reading and punching]], the main CPU executed calculations and binary [[branch (computer science)|branch instructions]]. One [[databus]] would bear data between the main CPU and core memory at the CPU's [[fetch-execute cycle]] rate, and other databusses would typically serve the peripheral devices. On the [[PDP-1]], the core memory's cycle time was 5 microseconds; consequently most arithmetic instructions took 10 microseconds (100,000 operations per second) because most operations took at least two memory cycles; one for the instruction, one for the [[operand]] data fetch. During the second generation [[Remote Digital Terminal|remote terminal]] units (often in the form of [[Teleprinter|teletype machines]] like a [[Friden Flexowriter]]) saw greatly increased use.<!--ref>[[Alan Newell]] used remote terminals to communicate cross-country with the [[RAND]] computers, as noted in {{harvnb|Simon|1991}}</ref--> Telephone connections provided sufficient speed for early remote terminals and allowed hundreds of kilometers separation between remote-terminals and the computing center. Eventually these stand-alone computer networks would be generalized into an interconnected ''[[history of the Internet|network of networks]]''—the Internet.<ref>{{harvnb|Mayo|Newcomb|2008|pp=96–117}}; Jimbo Wales is quoted on p. 115.</ref> ==Post-1960: third generation and beyond== {{Main|history of computing hardware (1960s–present)|history of general purpose CPUs}} [[File:153056995 5ef8b01016 o.jpg|right|thumb|Intel [[integrated circuit|8742 eight-bit microcontroller IC]]]] The explosion in the use of computers began with "third-generation" computers, making use of [[Jack Kilby|Jack St. Clair Kilby]]'s<ref>{{harvnb|Kilby|2000}}</ref> and [[Robert Noyce]]'s<ref>[[Robert Noyce]]'s Unitary circuit, {{Ref patent |country=US |number=2981877|status=patent|gdate=1961-04-25|title=Semiconductor device-and-lead structure |assign1 =[[Fairchild Semiconductor Corporation]]}}</ref> independent invention of the [[integrated circuit]] (or microchip), which later led to the invention of the microprocessor,<ref>{{harvnb|Intel_4004|1971}}</ref> by [[Marcian Hoff|Ted Hoff]], [[Federico Faggin]], and Stanley Mazor at [[Intel]].<ref>The Intel 4004 (1971) die was <math>12 mm^2</math>, composed of 2300 transistors; by comparison, the Pentium Pro was <math>306 mm^2</math>, composed of 5.5 million transistors, according to {{harvnb|Patterson|Hennessy|1998|pp=27–39}}</ref> The integrated circuit in the image on the right, for example, an [[Intel]] 8742, is an 8-bit [[microcontroller]] that includes a [[CPU]] running at 12 MHz, 128 bytes of [[RAM]], 2048 bytes of [[EPROM]], and [[Input/output|I/O]] in the same chip. During the 1960s there was considerable overlap between second and third generation technologies.<ref>In the defense field, considerable work was done in the computerized implementation of equations such as {{harvnb|Kalman|1960|pp= 35–45}}</ref> IBM implemented its [[IBM Solid Logic Technology]] modules in [[hybrid circuit]]s for the IBM System/360 in 1964. As late as 1975, Sperry Univac continued the manufacture of second-generation machines such as the UNIVAC 494. The [[Burroughs large systems]] such as the B5000 were [[stack machine]]s, which allowed for simpler programming. These [[pushdown automaton]]s were also implemented in minicomputers and microprocessors later, which influenced programming language design. Minicomputers served as low-cost computer centers for industry, business and universities.<ref>{{harvnb|Eckhouse|Morris|1979|pp= 1–2}}</ref> It became possible to simulate analog circuits with the ''simulation program with integrated circuit emphasis'', or [[SPICE]] (1971) on minicomputers, one of the programs for electronic design automation ([[:Category:Electronic design automation software|EDA]]). The microprocessor led to the development of the [[microcomputer]], small, low-cost computers that could be owned by individuals and small businesses. Microcomputers, the first of which appeared in the 1970s, became ubiquitous in the 1980s and beyond. In [[April]] [[1975]] at the Hannover Fair, was presented the [[P6060]] produced by [[Olivetti]], the world's first personal with built-in floppy disk: Central Unit on two plates, code names PUCE1/PUCE2, [[TTL]] components made, 8" single or double [[floppy disk]] driver, 32 alphanumeric characters [[plasma display]], 80 columns graphical [[thermal printer]], 48 Kbytes of [[RAM]], [[Basic]] language, 40 kilograms of weight. He was in competition with a similar product by IBM but with an external floppy disk. [[Steve Wozniak]], co-founder of [[Apple Computer]], is sometimes erroneously credited{{By whom|date=October 2010}} with developing the first mass-market [[home computer]]s. However, his first computer, the [[Apple I]], came out some time after the [[KIM-1|MOS Technology KIM-1]] and [[Altair 8800]], and the first Apple computer with graphic and sound capabilities came out well after the [[Commodore PET]]. Computing has evolved with microcomputer architectures, with features added from their larger brethren, now dominant in most market segments. Systems as complicated as computers require very high [[reliability engineering|reliability]]. ENIAC remained on, in continuous operation from 1947 to 1955, for eight years before being shut down. Although a vacuum tube might fail, it would be replaced without bringing down the system. By the simple strategy of never shutting down ENIAC, the failures were dramatically reduced. The vacuum-tube SAGE air-defense computers became remarkably reliable – installed in pairs, one off-line, tubes likely to fail did so when the computer was intentionally run at reduced power to find them. [[Hot plugging|Hot-pluggable]] hard disks, like the hot-pluggable vacuum tubes of yesteryear, continue the tradition of repair during continuous operation. Semiconductor memories routinely have no errors when they operate, although operating systems like Unix have employed memory tests on start-up to detect failing hardware. Today, the requirement of reliable performance is made even more stringent when [[server farm]]s are the delivery platform.<ref>"Since 2005, its [Google's] data centers have been composed of standard shipping containers—each with 1,160 servers and a power consumption that can reach 250 kilowatts." — Ben Jai of Google, as quoted in {{harvnb|Shankland|2009}}</ref> Google has managed this by using fault-tolerant software to recover from hardware failures, and is even working on the concept of replacing entire server farms on-the-fly, during a service event.<ref>"If you're running 10,000 machines, something is going to die every day." —Jeff Dean of Google, as quoted in {{harvnb|Shankland|2008}}.</ref><ref>[https://groups.google.com/group/google-appengine/browse_thread/thread/a7640a2743922dcf?pli=1 However, when an entire server farm fails today, the recovery procedures are currently still manual procedures, with the need for training the recovery team, even for the most advanced facilities. The initial failure was a power failure; the recovery procedure cited an inconsistent backup site, and the inconsistent backup site was outdated. Accessdate=2010-03-08]</ref> In the 21st century, [[multi-core]] CPUs became commercially available.<ref>Intel has unveiled a [http://www.pcper.com/article.php?aid=825 single-chip version of a 48-core CPU] for 