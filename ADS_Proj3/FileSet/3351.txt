boundary-value problem. It is, however, the fact that the NLP is easier to solve than the boundary-value problem. The reason for the relative ease of computation, particularly of a direct collocation method, is that the NLP is ''sparse'' and many well-known software programs exist (e.g., [[SNOPT]]<ref>Gill, P. E., Murray, W. M., and Saunders, M. A., ''User's Manual for SNOPT Version 7: Software for Large-Scale Nonlinear Programming'', University of California, San Diego Report, 24 April 2007</ref>) to solve large sparse NLPs. As a result, the range of problems that can be solved via direct methods (particularly direct ''collocation methods'' which are very popular these days) is significantly larger than the range of problems that can be solved via indirect methods. In fact, direct methods have become so popular these days that many people have written elaborate software programs that employ these methods. In particular, many such programs written in FORTRAN include ''DIRCOL'',<ref>von Stryk, O., ''User's Guide for DIRCOL (version 2.1): A Direct Collocation Method for the Numerical Solution of Optimal Control Problems'', Fachgebiet Simulation und Systemoptimierung (SIM), Technische Universität Darmstadt (2000, Version of November 1999).</ref> SOCS,<ref>Betts, J.T. and Huffman, W. P., ''Sparse Optimal Control Software, SOCS'', Boeing Information and Support Services, Seattle, Washington, July 1997</ref> OTIS,<ref>Hargraves, C. R. and Paris, S. W., "Direct Trajectory Optimization Using Nonlinear Programming and Collocation", ''Journal of Guidance, Control, and Dynamics'', Vol. 10, No. 4., 1987, pp. 338-342</ref>, GESOP.<ref>Gath, P.F., Well, K.H., "Trajectory Optimization Using a Combination of Direct Multiple Shooting and Collocation", AIAA 2001-4047, AIAA Guidance, Navigation, and Control Conference, Montréal, Québec, Canada, 6–9 August 2001</ref> and DITAN<ref>Vasile M., Bernelli-Zazzera F., Fornasari N., Masarati P., "Design of Interplanetary and Lunar Missions Combining Low-Thrust and Gravity Assists", Final Report of the ESA/ESOC Study Contract No. 14126/00/D/CS, September 2002</ref>. In recent years, due to the advent of the MATLAB programming language, optimal control software in MATLAB has become more common. Examples of academically developed MATLAB software tools implementing direct methods include ''[http://www.schwartz-home.com/RIOTS/ RIOTS]''<ref>Schwartz, Adam, ''Theory and Implementation of Methods based on Runge-Kutta Integration for Solving Optimal Control Problems'', University of California at Berkeley, PhD Dissertation, 1996.</ref>,''[[DIDO (optimal control)|DIDO]]'',<ref>Ross, I. M. and Fahroo, F., ''User's Manual for DIDO: A MATLAB Package for Dynamic Optimization'', Dept. of Aeronautics and Astronautics, Naval Postgraduate School Technical Report, 2002</ref> ''DIRECT'',<ref>Williams, P., ''User's Guide to DIRECT, Version 2.00,'' Melbourne, Australia, 2008</ref> and ''[http://gpops.sourceforge.net GPOPS],''<ref>Rao, A. V., Benson, D. A., Huntington, G. T., Francolin, C., Darby, C. L., and Patterson, M. A., ''User's Manual for GPOPS: A MATLAB Package for Dynamic Optimization Using the [[Gauss pseudospectral method|Gauss Pseudospectral Method]]'', University of Florida Report, August 2008.</ref> while an example of an industry developed MATLAB tool is ''[[PROPT]]''.<ref>Rutquist, P. and Edvall, M. M, ''PROPT - MATLAB Optimal Control Software," 1260 S.E. Bishop Blvd Ste E, Pullman, WA 99163, USA: Tomlab Optimization, Inc.</ref> These software tools have increased significantly the opportunity for people to explore complex optimal control problems both for academic research and industrial-strength problems. Finally, it is noted that general-purpose [[MATLAB]] optimization environments such as [[TOMLAB]] have made coding complex optimal control problems significantly easier than was previously possible in languages such as C and [[FORTRAN]]. ==Discrete-time optimal control== The examples thus far have shown [[continuous time]] systems and control solutions. In fact, as optimal control solutions are now often implemented [[digital]]ly, contemporary control theory is now primarily concerned with [[discrete time]] systems and solutions. The Theory of [[Consistent Approximations]]<ref>E. Polak, ''On the use of consistent approximations in the solution of semi-infinite optimization and optimal control problems'' Math. Prog. 62 pp. 385-415 (1993).</ref> provides conditions under which solutions to a series of increasingly accurate discretized optimal control problem converge to the solution of the original, continuous-time problem. Not all discretization methods have this property, even seemingly obvious ones. For instance, using a variable step-size routine to integrate the problem's dynamic equations may generate a gradient which does not converge to zero (or point in the right direction) as the solution is approached. The direct method ''[http://www.schwartz-home.com/RIOTS RIOTS]'' is based on the Theory of Consistent Approximation. ==Examples== A common solution strategy in many optimal control problems is to solve for the costate (sometimes called the [[shadow price]]) <math>\lambda(t)</math>. The costate summarizes in one number the marginal value of expanding or contracting the state variable next turn. The marginal value is not only the gains accruing to it next turn but associated with the duration of the program. It is nice when <math>\lambda(t)</math> can be solved analytically, but usually the most one can do is describe it sufficiently well that the intuition can grasp the character of the solution and an equation solver can solve numerically for the values. Having obtained <math>\lambda(t)</math>, the turn-t optimal value for the control can usually be solved as a differential equation conditional on knowledge of <math>\lambda(t)</math>. Again it is infrequent, especially in continuous-time problems, that one obtains the value of the control or the state explicitly. Usually the strategy is to solve for thresholds and regions that characterize the optimal control and use a numerical solver to isolate the actual choice values in time. ===Finite time=== Consider the problem of a mine owner who must decide at what rate to extract ore from his mine. He owns rights to the ore from date <math>0</math> to date <math>T</math>. At date <math>0</math> there is <math>x_0</math> ore in the ground, and the instantaneous stock of ore <math>x(t)</math> declines at the rate the mine owner extracts it u(t). The mine owner extracts ore at cost <math>u(t)^2/x(t)</math> and sells ore at a constant price <math>p</math>. He does not value the ore remaining in the ground at time <math>T</math> (there is no "scrap value"). He chooses the rate of extraction in time u(t) to maximize profits over the period of ownership with no time discounting. {| cellpadding="2" style="border:1px solid darkgray;" |- border=0; | 1. Discrete-time version The manager maximizes profit <math>\Pi</math>: :<math>\Pi = \sum_{t=0}^{T-1} \left[ pu_t - \frac{u_t^2}{x_t} \right] </math> subject to the law of evolution for the state variable <math>x_t</math> :<math>x_{t+1} - x_t = - u_t\!</math> 