''y'' to maximize <math>f(x,y)</math> subject to a constraint (shown in red) <math>g(x,y)=c</math>.]] [[Image:LagrangeMultipliers2D.svg|thumb|right|300px|Figure 2: Contour map of Figure 1. The red line shows the constraint <math>g(x,y)=c</math>. The blue lines are contours of <math>f(x,y)</math>. The point where the red line tangentially touches a blue contour is our solution.]] In mathematical [[optimization (mathematics)|optimization]], the method of '''Lagrange multipliers''' (named after [[Joseph Louis Lagrange]]) provides a strategy for finding the maxima and minima of a [[function (mathematics)|function]] subject to [[constraint (mathematics)|constraints]]. For instance (see Figure 1 on the right), consider the optimization problem :maximize <math>f(x, y) \,</math> :subject to <math>g(x, y) = c.\, </math> We introduce a new variable (<math>\lambda</math>) called a Lagrange multiplier, and study the Lagrange function defined by :<math> \Lambda(x,y,\lambda) = f(x,y) + \lambda \cdot \Big(g(x,y)-c\Big).</math> (the <math>\lambda</math> term may be either added or subtracted.) If <math>(x, y)</math> is a maximum for the original constrained problem, then there exists a ''λ'' such that <math>(x,y,\lambda)</math> is a [[stationary point]] for the Lagrange function (stationary points are those points where the partial derivatives of Λ are zero). However, not all stationary points yield a solution of the original problem. Thus, the method of Lagrange multipliers yields a [[necessary condition]] for optimality in constrained problems.<ref> {{cite book | last = Bertsekas | first = Dimitri P. | authorlink = Dimitri P. Bertsekas | title = Nonlinear Programming | edition = Second | publisher = Athena Scientific | date = 1999 | location = Cambridge, MA. | isbn = 1-886529-00-0 }}</ref><ref>{{springer | id=L/l057190 | title=Lagrange multipliers| first=I.B. | last=Vapnyarskii }}.</ref><ref> * {{cite book|last=Lasdon|first=Leon S.|title=Optimization theory for large systems|publisher=The Macmillan Company|series=Macmillan series in operations research|location=New York|year=1970|pages=xi+523|id={{MR|337317}}|}} * {{cite book|last=Lasdon|first=Leon S.|title=Optimization theory for large systems|publisher=Dover Publications, Inc.|location=Mineola, New York|year=2002|edition=reprint of the 1970 Macmillan|pages=xiii+523|id={{MR|1888251}}|}}</ref><ref> {{cite book|last1=Hiriart-Urruty|first1=Jean-Baptiste|last2=Lemaréchal|first2=Claude|chapter=XII Abstract duality for practitioners|title=Convex analysis and minimization algorithms, Volume II: Advanced theory and bundle methods|series=Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences]|volume=306|publisher=Springer-Verlag|location=Berlin|year=1993|pages=136–193 (and Bibliographical comments on pp. 334–335)|isbn=3-540-56852-2|{{MR|1295240}}|authorlink2=Claude Lemaréchal|}}</ref><ref>{{cite book|last=Lemaréchal|first=Claude |chapter=Lagrangian relaxation|pages=112–156|doi=10.1007/3-540-45586-8_4|title=Computational combinatorial optimization: Papers from the Spring School held in Schloß Dagstuhl, May 15–19, 2000|editor=Michael Jünger and Denis Naddef|series=Lecture Notes in Computer Science|volume=2241|publisher=Springer-Verlag|location=Berlin|year=2001|isbn=3-540-42877-1|id={{MR|1900016}}.{{doi|10.1007/3-540-45586-8_4}}|authorlink=Claude Lemaréchal|}}</ref> ==Introduction== Consider the two-dimensional problem introduced above: :maximize <math>f(x, y) \,</math> :subject to <math>g(x, y) = c. \,</math> We can visualize [[Contour line|contour]]s of ''f'' given by :<math>f(x, y)=d \,</math> for various values of <math> d </math>, and the contour of <math> g </math> given by <math> g ( x, y ) = c </math>. Suppose we walk along the contour line with <math> g = c </math>. In general the contour lines of <math> f </math> and <math> g </math> may be distinct, so following the contour line for <math> g = c </math> one could intersect with or cross the contour lines of <math> f </math>. This is equivalent to saying that while moving along the contour line for <math> g = c </math> the value of <math>f </math> can vary. Only when the contour line for <math> g = c </math> meets contour lines of <math> f </math> [[contact (mathematics)| tangentially]], we do not increase or decrease the value of <math> f </math> — that is, when the contour lines touch but do not cross. The contour lines of ''f'' and ''g'' touch when the [[tangent vector]]s of the contour lines are parallel. Since the [[gradient]] of a function is perpendicular to the contour lines, this is the same as saying that the gradients of ''f'' and ''g'' are parallel. Thus we want points <math>(x,y)</math> where <math>g(x,y) = c</math> and :<math>\nabla_{x,y} f = - \lambda \nabla_{x,y} g</math>, where :<math> \nabla_{x,y} f= \left( \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y} \right) </math> and :<math> \nabla_{x,y} g= \left( \frac{\partial g}{\partial x}, \frac{\partial g}{\partial y} \right) </math> are the respective gradients. The constant <math>\lambda</math> is required because although the two gradient vectors are parallel, the magnitudes of the gradient vectors are generally not equal. To incorporate these conditions into one equation, we introduce an auxiliary function :<math> \Lambda(x,y,\lambda) = f(x,y) + \lambda \cdot \Big(g(x,y)-c\Big), </math> and solve :<math> \nabla_{x,y,\lambda} \Lambda(x , y, \lambda)=0. </math> This is the method of Lagrange multipliers. Note that <math>\nabla_{\lambda} \Lambda(x , y, \lambda)=0</math> implies <math> g(x,y)=c</math>. === Not extrema === The solutions are the ''[[Critical point (mathematics)|critical points]]'' of the Lagrangian <math>\Lambda</math>; they are not necessarily ''extrema'' of <math>\Lambda</math>. In fact, the function <math>\Lambda</math> is unbounded: given a point <math>(x,y)</math> that does not lie on the constraint, letting <math>\lambda \to \pm \infty</math> makes <math>\Lambda</math> arbitrarily large or small. One may [[Hamiltonian mechanics#As a reformulation of Lagrangian mechanics|reformulate the Lagrangian]] as a [[Hamiltonian mechanics|Hamiltonian]], in which case the solutions are local minima for the Hamiltonian. This is done in [[optimal control]] theory, in the form of [[Pontryagin's minimum principle]]. The fact that solutions of the Lagrangian are not extrema also poses difficulties for numerical optimization. This can be addressed by computing the ''magnitude'' of the gradient, as the zeros of the magnitude are necessarily local minima, and is illustrated in [[#Example: numerical optimization|the numerical optimization example]]. == Handling multiple constraints == [[Image:As_wiki_lgm_parab.png|thumb|right|300px|A paraboloid, some of its level sets (aka contour lines) and 2 line constraints.]] [[Image:As_wiki_lgm_levelsets.png|thumb|right|300px|Zooming in on the levels sets and constraints, we see that the two constraint lines intersect to form a "joint" constraint that is a point. Since there is only one point to analyze, the corresponding point on the paraboloid is automatically a minimum and maximum. Yet the simplified reasoning presented in sections above seems to fail because the level set definitely appears to "cross" the point and at the same time its gradient is not parallel to the gradients of either constraint. This shows we must refine our explanation of the method to handle the kinds of constraints that are formed when we have more than one constraint acting at once.]] The method of ''Lagrange multipliers'' can also accommodate multiple constraints. To see how this is done, we need to reexamine the problem in a slightly different manner because the concept of “crossing” discussed above becomes rapidly unclear when we consider the types of constraints that are 