mind</title> <text>{{Citations missing|date=July 2008}} {{No footnotes|date=April 2009}} In [[philosophy of mind|philosophy]], the '''computational theory of mind''' is the view that the human [[mind]] ought to be conceived as an [[information processing system]] and that [[thought]] is a form of [[computation]]. The theory was proposed in its modern form by [[Hilary Putnam]] in 1961{{Citation needed|date=June 2010}} and developed by [[Jerry Fodor]] in the 60s and 70s.<ref>[[Steven Horst|Horst, Steven]], (2005) [http://plato.stanford.edu/entries/computational-mind/ "The Computational Theory of Mind"] in ''The Stanford Encyclopedia of Philosophy''</ref> This view is common in modern [[cognitive psychology]] and is presumed by theorists of [[evolutionary psychology]]. The computational theory of mind is a philosophical concept that the mind functions as a computer or symbol manipulator. The theory is that the mind computes input from the natural world to create outputs in the form of further mental or physical states. A [[computation]] is the process of taking input and following a step by step [[algorithm]] to get a specific output. The computational theory of mind claims that there are certain aspects of the mind that follow step by step processes to compute representations of the world. The computational theory of mind requires [[Representation (psychology)|representation]] because 'input' into a computation comes in the form of symbols or representations of other objects. A computer cannot compute an actual object, it must interpret and represent the object in some form and then compute the representation. The computational theory of mind is related to the [[representational theory of mind]] in that they both require that mental states are representations. However the two theories differ in that the representational theory claims that all mental states are representations while the computational theory leaves open that certain mental states, such as pain or depression, may not be representational and therefore may not be suitable for a computational treatment. These non-representational mental states are known as [[qualia]]. The computational theory of mind is also related to the [[language of thought]]. The language of thought theory allows the mind to process more complex representations with the help of semantics. (See below in semantics of mental states). =="Computer metaphor"== Computational theory of mind is not the same as the computer metaphor, according to which the mind literally works like a computer.<ref name="BS">[[Steven Pinker|Pinker, Steven]]. [[The Blank Slate]]. New York: Penguin. 2002</ref> Computational theory just uses some of the same principles as those found in digital computing.<ref name="BS">[[Steven Pinker|Pinker, Steven]]. [[The Blank Slate]]. New York: Penguin. 2002</ref> 'Computer' is not meant to mean a modern day electronic computer. Rather a computer is a symbol manipulator that follows step by step functions to compute input and form output. [[Alan Turing]] describes this type of computer in his concept of a [[Turing Machine]]. == Causal picture of thoughts == At the heart of the Computational Theory of Mind is the idea that thoughts are a form of computation, and a computation is by definition a systematic set of laws for the relations among representations. Meaning that a mental state represents something if and only if there is some causal correlation between the mental state and that particular thing. An example would be seeing dark clouds and thinking “clouds mean rain”, there is a correlation between the thought of the clouds and rain, as the clouds causing rain. This is known as Natural Meaning. Conversely, there is another side to the causality of thoughts and that is the non-natural representation of thoughts. An example would be seeing a red traffic light and thinking “red means stop”, there is nothing about the color red that indicates it represents stopping, and thus is just a convention that has been invented, similar to languages and their abilities to form representations. == Semantics of mental states == The computational theory of mind states that the mind functions as a symbolic operator, and that mental representations are symbolic representations; just as the [[semantics]] of language are the features of words and sentences that relate to their meaning, the semantics of mental states are those meanings of representations, the definitions of the ‘words’ of the [[language of thought]]. If these basic mental states can have a particular meaning just as words in a language do, then this means that more complex mental states (thoughts) can be created, even if they have never been encountered before. Just as new sentences that are read can be understood even if they have never been encountered before, as long as the basic components are understood, and it is syntactically correct. For example: “I have eaten plum pudding every day of this fortnight.” While it's doubtful many have seen this particular configuration of words, nonetheless most readers should be able to glean an understanding of this sentence because it is syntactically correct and the constituent parts are understood. == Criticism == There are arguments against the Computational Theory of Mind. Some of the most compelling encompass the physical realm of a computational process. [[Gallistel]] writes in Learning and Representation about some of the implications of a truly computational system of the mind. Essentially Gallistel is concerned with the limits of thermodynamics within the circuits of the brain. With the high volume of information, and the low level of lost material necessary, we have to ask where the energy comes from and how the heat would be dissipated.{{Citation needed|date=December 2010}} [[John Searle]] has offered a thought experiment known as the [[Chinese Room]] that demonstrates this problem. Imagine that there is a man in a room with no way of communicating to anyone or anything outside of the room except for a piece of paper that is passed under the door. With the paper, he is to use a series of books provided to decode and “answer” what is on the paper. The symbols are all in Chinese, and all the man knows is where to look in the books, which then tell him what to write in response. It just so happens that this generates a conversation that the Chinese man outside of the room can actually 