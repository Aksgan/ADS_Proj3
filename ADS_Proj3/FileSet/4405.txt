altruistic behavior."</ref> Trivers' theory is very powerful. Not only can it replace group selection, it also predicts various observed behavior, including moralistic aggression,<ref> To deter cheaters from exploiting altruists. And "in extreme cases, perhaps, to select directly against the unreciprocating individual by injuring, killing, or exiling him."(Trivers)</ref> gratitude and sympathy, guilt and reparative altruism,<ref> Analogous to the situation in the IPD where, having once defected, a player voluntarily elects to cooperate, even in anticipation of being suckered, in order to return to a state of mutual cooperation. As Trivers says (p. 50): "It seems plausible ... that the emotion of guilt has been selected for in humans partly in order to motivate the cheater to compensate his misdeed and to behave reciprocally in the future...."</ref> and development of abilities to detect and discriminate against subtle cheaters. The benefits of such reciprocal altruism was dramatically demonstrated by a pair of tournaments held by Robert Axelrod around 1980. == Axelrod's Tournaments == Axelrod initially solicited strategies from other game theorists to compete in the first tournament. Each strategy was paired with each other strategy for 200 iterations of a [[Prisoner's Dilemma]] game, and scored on the total points accumulated through the tournament. The winner was a very simple strategy submitted by [[Anatol Rapoport]] called "[[Tit for tat|TIT FOR TAT]]" (TFT) that cooperates on the first move, and subsequently echoes (reciprocates) what the other player did on the previous move. The results of the first tournament were analyzed and published, and a second tournament held to see if anyone could find a better strategy. TIT FOR TAT won again. Axelrod analyzed the results, and made some interesting discoveries about the nature of cooperation, which he describes in his book<ref>{{Harvnb|Axelrod|1984}}.</ref> In both actual tournaments and various replays the best performing strategies were '''nice'''<ref>{{Harvnb|Axelrod|1984|p=113}}.</ref>: that is, they were never the first to defect. Many of the competitors went to great lengths to gain an advantage over the "nice" (and usually simpler) strategies, but to no avail: tricky strategies fighting for a few points generally could not do as well as nice strategies working together. TFT (and other "nice" strategies generally) "won, not by doing better than the other player, but by eliciting cooperation [and] by promoting the mutual interest rather than by exploiting the other's weakness."<ref>{{Harvnb|Axelrod|1984|p=130}}.</ref> Being "nice" can be beneficial, but it can also lead to being suckered. To obtain the benefit &ndash; or avoid exploitation &ndash; it is necessary to be '''provocable''' to both retaliation and forgiveness. When the other player defects, a nice strategy must immediately be provoked into retaliatory defection.<ref>{{Harvnb|Axelrod|1984|pp=62, 211}}.</ref> The same goes for forgiveness: return to cooperation as soon as the other player does. Overdoing the punishment risks escalation, and can lead to an "unending echo of alternating defections" that depresses the scores of both players.<ref>{{Harvnb|Axelrod|1984|p=186}}.</ref> Most of the games that game theory had heretofore investigated are "[[zero-sum]]" &ndash; that is, the total rewards are fixed, and a player does well only at the expense of other players. But real life is not zero-sum. Our best prospects are usually in cooperative efforts. In fact, TFT ''cannot'' score higher than its partner; at best it can only do "as good as". Yet it won the tournaments by consistently scoring a strong second-place with a variety of partners.<ref>{{Harvnb|Axelrod|1984|p=112}}.</ref> Axelrod summarizes this as '''don't be envious''';<ref>{{Harvnb|Axelrod|1984|pp=110–113}}.</ref> in other words, don't strive for a payoff ''greater'' than the other player's.<ref>{{Harvnb|Axelrod|1984|p=25}}.</ref> In any IPD game there is a certain maximum score each player can get by always cooperating. But some strategies try to find ways of getting a little more with an occasional defection (exploitation). This can work against some strategies that are less provocable or more forgiving than TIT FOR TAT, but generally they do poorly. "A common problem with these rules is that they used complex methods of making inferences about the other player [strategy] &ndash; and these inferences were wrong."<ref>{{Harvnb|Axelrod|1984|p=120}}.</ref> Against TFT (and "nice" strategies generally) one can do no better than to simply cooperate.<ref>{{Harvnb|Axelrod|1984|pp=47,118}}.</ref> Axelrod calls this '''clarity'''. Or: '''don't be too clever'''.<ref>{{Harvnb|Axelrod|1984|pp=120+}}.</ref> The success of any strategy depends on the nature of the particular strategies it encounters, which depends on the composition of the overall population. To better model the effects of reproductive success Axelrod also did an "ecological" tournament, where the prevalence of each type of strategy in each round was determined by that strategy's success in the previous round. The competition in each round becomes stronger as weaker performers are reduced and eliminated. The results were amazing: a handful of strategies &ndash; all "nice" &ndash; came to dominate the field.<ref>{{Harvnb|Axelrod|1984|pp=48–53}}.</ref> In a sea of non-nice strategies the "nice" strategies &ndash; provided they were also provokable! &ndash; did well enough with each other to offset the occasional exploitation. As cooperation became general the non-provocable strategies were exploited and eventually eliminated, whereupon the exploitive (non-cooperating) strategies were out-performed by the cooperative strategies. In summary, success in an evolutionary "game" correlated with the following characteristics: * '''Be nice:''' cooperate, never be the first to defect. * '''Be provocable:''' return defection for defection, cooperation for cooperation. * '''Don't be envious:''': be fair with your ''partner''. * '''Don't be too clever:''' or, don't try to be tricky. == Foundation of reciprocal cooperation == The lessons described above apply in environments that support cooperation, but whether cooperation is supported at all depends crucially on the probability (called ω [omega]) that the players will meet again,<ref>{{Harvnb|Axelrod|1984|p=13}}.</ref> also called the discount parameter or, poetically, the shadow of the future. When ω is low &ndash; that is, the players have a negligible chance of meeting again &ndash; each interaction is effectively a single-shot Prisoner's Dilemma game, and one might as well defect in all cases (a strategy called "ALL D"), because even if one cooperates there is no way to keep the other player from exploiting that. But in the iterated PD the value of repeated cooperative interactions can become greater than the benefit/risk of a single exploitation (which is all that a strategy like TFT 