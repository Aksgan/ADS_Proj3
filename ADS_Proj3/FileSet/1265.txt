using the solution to its subproblems, and if its subproblems are overlapping, then one can easily [[memoization|memoize]] or store the solutions to the subproblems in a table. Whenever we attempt to solve a new subproblem, we first check the table to see if it is already solved. If a solution has been recorded, we can use it directly, otherwise we solve the subproblem and add its solution to the table. * ''[[Top-down and bottom-up design|Bottom-up approach]]'': This is the more interesting case. Once we formulate the solution to a problem recursively as in terms of its subproblems, we can try reformulating the problem in a bottom-up fashion: try solving the subproblems first and use their solutions to build-on and arrive at solutions to bigger subproblems. This is also usually done in a tabular form by iteratively generating solutions to bigger and bigger subproblems by using the solutions to small subproblems. For example, if we already know the values of F<sub>41</sub> and F<sub>40</sub>, we can directly calculate the value of F<sub>42</sub>. Some [[programming language]]s can automatically [[memoization|memoize]] the result of a function call with a particular set of arguments, in order to speed up [[call-by-name]] evaluation (this mechanism is referred to as ''[[evaluation strategy#Call by need|call-by-need]]''). Some languages make it possible portably (e.g. [[Scheme (programming language)|Scheme]], [[Common Lisp]] or [[Perl]]), some need special extensions (e.g. [[C++]], see <ref>http://www.apl.jhu.edu/~paulmac/c++-memoization.html</ref>). Some languages have automatic [[memoization]] <!-- still not a typo for "memor-" --> built in, such as tabled [[Prolog]]. In any case, this is only possible for a [[referential transparency (computer science)|referentially transparent]] function. == Example: mathematical optimization == ===Optimal consumption and saving=== A mathematical optimization problem that is often used in teaching dynamic programming to economists (because it can be solved by hand<ref>Stokey et al., 1989, Chap. 1</ref>) concerns a consumer who lives over the periods <math>t=0,1,2,...,T</math> and must decide how much to consume and how much to save in each period. Let <math>c_t</math> be consumption in period <math>t</math>, and assume consumption yields [[utility]] <math>u(c_t)=\ln(c_t)</math> as long as the consumer lives. Assume the consumer is impatient, so that he [[discounting|discounts]] future utility by a factor <math>b</math> each period, where <math>0<b<1</math>. Let <math>k_t</math> be [[capital (economics)|capital]] in period <math>t</math>. Assume initial capital is a given amount <math>k_0>0</math>, and suppose that this period's capital and consumption determine next period's capital as <math>k_{t+1}=Ak^a_t - c_t</math>, where <math>A</math> is a positive constant and <math>0<a<1</math>. Assume capital cannot be negative. Then the consumer's decision problem can be written as follows: : <math>\max \sum_{t=0}^T b^t \ln(c_t)</math> subject to <math>k_{t+1}=Ak^a_t - c_t \geq 0</math> for all <math>t=0,1,2,...,T</math> Written this way, the problem looks complicated, because it involves solving for all the choice variables <math>c_0, c_1, c_2, ... , c_T</math> and <math>k_1, k_2, k_3, ... , k_{T+1}</math> simultaneously. (Note that <math>k_0</math> is not a choice variable—the consumer's initial capital is taken as given.) The dynamic programming approach to solving this problem involves breaking it apart into a sequence of smaller decisions. To do so, we define a sequence of ''value functions'' <math>V_t(k)</math>, for <math>t=0,1,2,...,T,T+1</math> which represent the value of having any amount of capital <math>k</math> at each time <math>t</math>. Note that <math>V_{T+1}(k)=0</math>, that is, there is (by assumption) no utility from having capital after death. The value of any quantity of capital at any previous time can be calculated by [[backward induction]] using the [[Bellman equation]]. In this problem, for each <math>t=0,1,2,...,T</math>, the Bellman equation is : <math>V_t(k_t) \, = \, \max \left( \ln(c_t) + b V_{t+1}(k_{t+1}) \right)</math> subject to <math>k_{t+1}=Ak^a_t - c_t \geq 0</math> This problem is much simpler than the one we wrote down before, because it involves only two decision variables, <math>c_t</math> and <math>k_{t+1}</math>. Intuitively, instead of choosing his whole lifetime plan at birth, the consumer can take things one step at a time. At time <math>t</math>, his current capital <math>k_t</math> is given, and he only needs to choose current consumption <math>c_t</math> and saving <math>k_{t+1}</math>. To actually solve this problem, we work backwards. For simplicity, the current level of capital is denoted as <math>k</math>. <math>V_{T+1}(k)</math> is already known, so using the Bellman equation once we can calculate <math>V_T(k)</math>, and so on until we get to <math>V_0(k)</math>, which is the ''value'' of the initial decision problem for the whole lifetime. In other words, once we know <math>V_{T-j+1}(k)</math>, we can calculate <math>V_{T-j}(k)</math>, which is the maximum of <math>\ln(c_{T-j}) + b V_{T-j+1}(Ak^a-c_{T-j})</math>, where <math>c_{T-j}</math> is the choice variable and <math>Ak^a-c_{T-j} \ge 0</math>. Working backwards, it can be shown that the value function at time <math>t=T-j</math> is : <math>V_{T-j}(k) \, = \, a \sum_{i=0}^j a^ib^i \ln k + v_{T-j}</math> where each <math>v_{T-j}</math> is a constant, and the optimal amount to consume at time <math>t=T-j</math> is : <math>c_{T-j}(k) \, = \, \frac{1}{\sum_{i=0}^j a^ib^i} Ak^a</math> which can be simplified to : <math>c_{T}(k) \, = \, Ak^a</math>, and <math>c_{T-1}(k) \, = \, \frac{Ak^a}{1+ab}</math>, and <math>c_{T-2}(k) \, = \, \frac{Ak^a}{1+ab+a^2b^2}</math>, etc. We see that it is optimal to consume a larger fraction of current wealth as one gets older, finally consuming all remaining wealth in period <math>T</math>, the last period of life. ==Examples: Computer algorithms== === Dijkstra's algorithm for the shortest path problem === From a dynamic programming point of view, [[Dijkstra's algorithm]] for the [[shortest path problem]] is a successive approximation scheme that solves the dynamic programming functional equation for the shortest path problem by the '''Reaching''' method.<ref name=sniedovich_06>{{cite journal | last = Sniedovich | first = M. | title = Dijkstra’s algorithm revisited: the dynamic programming connexion | journal = Journal of Control and Cybernetics | volume = 35 | issue = 3 | pages = 599–620 | year = 2006 | url = http://matwbn.icm.edu.pl/ksiazki/cc/cc35/cc3536.pdf | format = [[PDF]]}} [http://www.ifors.ms.unimelb.edu.au/tutorial/dijkstra_new/index.html Online version of the paper with interactive computational modules.]</ref><ref name=denardo_03>{{cite book | last = Denardo | first = E.V. | title = Dynamic Programming: Models and Applications | publisher = [[Dover Publications]] | location = Mineola, NY | year = 2003 | isbn = 978-0486428109}}</ref> <ref name=sniedovich_10>{{cite book | last = Sniedovich | first = M. | title = Dynamic Programming: Foundations and 