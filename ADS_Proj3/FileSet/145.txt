from evolutionary algorithms such as genetic algorithms, evolution strategy, and others (CHC). The hybrid skeletons combine strategies, such as: GASA, a mixture of genetic algorithm and simulated annealing, and CHCCES which combines CHC and ES. The skeletons are provided as a C++ library and are not nestable but type safe. A custom MPI abstraction layer is used, NetStream, which takes care of primitive data type marshalling, synchronization, etc. A skeleton may have multiple lower-level parallel implementations depending on the target architectures: sequential, LAN, and WAN. For example: centralized master-slave, distributed master-slave, etc. '''Mallba''' also provides state variables which hold the state of the search skeleton. The state links the search with the environment, and can be accessed to inspect the evolution of the search and decide on future actions. For example, the state can be used to store the best solution found so far, or α, β values for branch and bound pruning <ref>''E. Alba, G. Luque, J. Garcia-Nieto, G. Ordonez, and G. Leguizamon.'' "Mallba a software library to design efficient optimisation algorithms." International Journal of Innovative Computing and Applications, 1(1):74–85, 2007.</ref>. Compared with other frameworks, Mallba’s usage of skeletons concepts is unique. Skeletons are provided as parametric search strategies rather than parametric parallelization patterns. ===Muesli=== The Muenster Skeleton Library '''Muesli''' <ref>''H. Kuchen and J. Striegnitz.'' "Features from functional programming for a C++ skeleton library". Concurrency - Practice and Experience, 17(7-8):739-756, 2005.</ref><ref>''Philipp Ciechanowicz, Michael Poldner, and Herbert Kuchen.'' "The Muenster Skeleton Library Muesli - A Comprehensive Overview." ERCIS Working Paper No. 7, 2009.</ref> is a C++ template library which re-implements many of the ideas and concepts introduced in [[Algorithmic skeleton#Skil|Skil]], e.g. higher order functions, currying, and polymorphic types [http://www.wi.uni-muenster.de/pi/forschung/Skeletons/index.html]. It is build on top of [[Message Passing Interface|MPI]] 1.2 and [[OpenMP]] 2.5 and supports, unlike many other skeleton libraries, both task and data parallel skeletons. Skeleton nesting (composition) is similar to the two tier approach of [[Algorithmic skeleton#P3L, SkIE, SKElib|P3L]], i.e. task parallel skeletons can be nested arbitrarily while data parallel skeletons cannot, but may be used at the leaves of a task parallel nesting tree <ref>''H. Kuchen and M. Cole''. "The integration of task and data parallel skeletons." Parallel Processing Letters, 12(2):141-155, 2002.</ref>. C++ templates are used to render skeletons polymorphic, but no type system is enforced. However, the library implements an automated serialization mechanism inspired by <ref>''A. Alexandrescu.'' "Modern C++ Design: Generic Programming and Design Patterns Applied". Addison-Wesley, 2001.</ref> such that, in addition to the standard MPI data types, arbitrary user-defined data types can be used within the skeletons. The supported task parallel skeletons <ref>''Michael Poldner.'' "Task Parallel Algorithmic Skeletons." PhD Thesis, University of Münster, 2008.</ref> are Branch & Bound <ref>''Michael Poldner and Herbert Kuchen.'' "Algorithmic Skeletons for Branch and Bound." Proceedings of the 1st International Conference on Software and Data Technology (ICSOFT), 1:291-300, 2006.</ref>, Divide & Conquer <ref>''Michael Poldner and Herbert Kuchen.'' "Optimizing Skeletal Stream Processing for Divide and Conquer." Proceedings of the 3rd International Conference on Software and Data Technologies (ICSOFT), 181-189, 2008.</ref><ref>''Michael Poldner and Herbert Kuchen.'' "Skeletons for Divide and Conquer." Proceedings of the IASTED International Conference on Parallel and Distributed Computing and Networks (PDCN), 181-188, 2008.</ref>, Farm <ref>''Michael Poldner and Herbert Kuchen.'' "Scalable Farms." Proceedings of the International Conference on Parallel Processing (ParCo) 33:795-802, 2006.</ref><ref>''Michael Poldner and Herbert Kuchen.'' "On Implementing the Farm Skeleton." Parallel Processing Letters, 18(1):117-131, 2008.</ref>, and Pipe, auxiliary skeletons are Filter, Final, and Initial. Data parallel skeletons, such as fold (reduce), map, permute, zip, and their variants are implemented as higher order member functions of a distributed data structure. Currently, Muesli supports distributed data structures for arrays, matrices, and sparse matrices <ref>''Philipp Ciechanowicz.'' "Algorithmic Skeletons for General Sparse Matrices." Proceedings of The 20th IASTED International Conference on Parallel and Distributed Computing and Systems (PDCS), 188-197, 2008.</ref>. As a unique feature, Muesli’s data parallel skeletons automatically scale both on single- as well as on multi-core, multi-node cluster architectures <ref>''Philipp Ciechanowicz, Philipp Kegel, Maraike Schellmann, Sergei Gorlatch, and Herbert Kuchen.'' "Parallelizing the LM OSEM Image Reconstruction on Multi-Core Clusters." Parallel Computing: From Multicores and GPU's to Petascale, 19: 169-176, 2010.</ref><ref>''Philipp Ciechanowicz and Herbert Kuchen.'' "Enhancing Muesli's Data Parallel Skeletons for Multi-Core Computer Architectures". International Conference on High Performance Computing and Communications (HPCC), 108-113, 2010.</ref>. Here, scalability across nodes and cores is ensured by simultaneously using MPI and OpenMP, respectively. However, this feature is optional in the sense that a program written with Muesli still compiles and runs on a single-core, multi-node cluster computer without changes to the source code, i.e. backward compatibility is guaranteed. This is ensured by providing a very thin OpenMP abstraction layer such that the support of multi-core architectures can be switched on/off by simply providing/omitting the OpenMP compiler flag when compiling the program. By doing so, virtually no overhead is introduced at runtime. ===P3L, SkIE, SKElib=== '''P3L''' <ref>{{cite doi|10.1002/cpe.4330070305}}</ref> (Pisa Parallel Programming Language) is a skeleton based coordination language. '''P3L''' provides skeleton constructs which are used to coordinate the parallel or sequential execution of C code. A compiler named Anacleto <ref>''S. Ciarpaglini, M. Danelutto, L. Folchi, C. Manconi, and S. Pelagatti.'' "ANACLETO: a template-based p3l compiler." In Proceedings of the Seventh Parallel Computing Workshop (PCW ’97), Australian National University, Canberra, August 1997.</ref> is provided for the language. Anacleto uses implementation templates to compile P3 L code into a target architecture. Thus, a skeleton can have several templates each optimized for a different architecture. A template implements a skeleton on a specific architecture and provides a parametric process graph with a performance model. The performance model can then be used to decide program transformations which can lead to performance optimizations <ref>M. Aldinucci, M. Coppola, and M. Danelutto. Rewriting skeleton programs: How to evaluate the data-parallel stream-parallel tradeoff. In S. Gorlatch, editor, Proc of CMPP: Intl. Workshop on Constructive Methods for Parallel Programming, pages 44–58. Uni. Passau, Germany, May 1998.</ref>. A '''P3L''' module corresponds to a properly defined skeleton construct with input and output streams, and other sub-modules or sequential C code. Modules can be nested using the two tier 