''E'' is visited 4 times in the query of ''Q'' and so has to be skipped 3 times. To further speed up the query, divisions can be replaced by [[right shift]]s. This requires the number of bins along an axis direction to be an exponent of 2. == Compared to other range query data structures == Against [[kd-tree]], the bin structure allows efficient insertion and deletion without the complexity of rebalancing. This can be very useful in algorithms that need to incrementally add shapes to the search data structure. == See also == * [[kd-tree]] is another efficient range query data structure. * [[Space partitioning]] [[Category:Geometric algorithms]]</text> </page> <page> <id>3803</id> <title>BinaryObject (metadata)</title> <text>{{Unreferenced stub|auto=yes|date=February 2009}} In [[metadata]] a '''Binary Object''' is a [[representation term]] used to describe a set of finite-length sequences of binary octets used to represent sound, images and other structures. {{Comp-sci-stub}} [[Category:Metadata]]</text> </page> <page> <id>3827</id> <title>Binary multiplier</title> <text>A '''binary multiplier''' is an [[electronic circuit]] used in [[digital electronics]], such as a [[computer]], to [[Multiplication|multiply]] two [[binary number]]s. It is built using [[binary adder]]s. A variety of [[:Category:computer arithmetic|computer arithmetic]] techniques can be used to implement a digital multiplier. Most techniques involve computing a set of ''partial products'', and then summing the partial products together. This process is similar to the method taught to primary schoolchildren for conducting long multiplication on base-10 integers, but has been modified here for application to a base-2 ([[binary numeral system|binary]]) [[numeral system]]. ===History=== Until the late 1970s, most [[minicomputers]] did not have a multiply instruction, and so programmers used a "multiply routine"<ref> "The Evolution of Forth" by Elizabeth D. Rather et. al. [http://www.forth.com/resources/evolution/evolve_2.html] [http://www.forth.com/resources/evolution/evolve_1.html] </ref><ref> [http://dx.doi.org/10.1016/0308-5953(77)90004-6 "Interfacing a hardware multiplier to a general-purpose microprocessor"] </ref> which repeatedly shifts and accumulates partial results, often written using [[loop unwinding]]. [[Mainframe computer]]s had multiply instructions, but they did the same sorts of shifts and adds as a "multiply routine". Early [[microprocessor]]s also had no multiply instruction. The [[Motorola 6809]], introduced circa 1977-78, was one of the earliest microprocessors with a dedicated hardware multiply instruction. It apparently{{Citation needed|date=March 2010}} did the same sorts of shifts and adds as a "multiply routine", but implemented in the [[microcode]] of the MUL instruction. As more [[transistor count|transistors per chip]] became available (Moore's law), it became possible to put enough adders on a single chip to sum all the partial products at once, rather than re-use a single adder to handle each partial product one at a time. Because some common [[digital signal processing]] algorithms spend most of their time multiplying, people who design [[digital signal processor]]s sacrifice a lot of chip area in order to make the "multiply" as fast as possible—a single-cycle [[multiply-accumulate]] unit often used up most of the chip area of early DSPs. ==Multiplication basics== The method taught in school for multiplying decimal numbers, is based on calculating partial products, shifting them to the left and then adding them together. The most difficult part is to obtain the partial products, as that involves multiplying a long number by one digit (from 0 to 9): <nowiki> 123 x 456 ===== 738 (this is 123 x 6) 615 (this is 123 x 5, shifted one position to the left) + 492 (this is 123 x 4, shifted two positions to the left) ===== 56088</nowiki> A binary computer does exactly the same, but with binary numbers. In binary encoding each long number is multiplied by one digit (either 0 or 1), and that is much easier than in decimal, as the product by 0 or 1 is just 0 or the same number. Therefore, the multiplication of two binary numbers comes down to calculating partial products (which are 0 or the first number), shifting them left, and then adding them together (a binary addition, of course): <nowiki> 1011 (this is 11 in binary) x 1110 (this is 14 in binary) ====== 0000 (this is 1011 x 0) 1011 (this is 1011 x 1, shifted one position to the left) 1011 (this is 1011 x 1, shifted two positions to the left) + 1011 (this is 1011 x 1, shifted three positions to the left) ========= 10011010 (this is 154 in binary)</nowiki> This is much simpler than in the decimal system, as there is no table of multiplication to remember: just shifts and adds. This method is mathematically correct, but it has two serious engineering problems. The first is that it involves 32 intermediate additions in a 32-bit computer, or 64 intermediate additions in a 64-bit computer. These additions take a lot of time. The engineering implementation of binary multiplication consists, really, of taking a very simple mathematical process and complicating it a lot, in order to do fewer additions; a modern processor can multiply two 64-bit numbers with 16 additions (rather than 64), and can do several steps in parallel—but at a cost of making the process almost unreadable. The second problem is that the basic school method handles the sign with a separate rule ("+ with + yields +", "+ with - yields -", etc.). Modern computers embed the sign of the number in the number itself, usually in the [[two's complement]] representation. That forces the multiplication process to be adapted to handle two's complement numbers, and that complicates the process a bit more. Similarly, processors that use [[one's complement]], [[sign-and-magnitude]], [[IEEE-754]] or other binary representations require specific adjustments to the multiplication process. ==Engineering approach: an unsigned example== For example, suppose we want to multiply two [[signedness|unsigned]] eight bit integers together: ''a''[7:0] and ''b''[7:0]. We can produce eight partial products by performing eight one-bit multiplications, one for each bit in multiplicand ''a'': <nowiki>p0[7:0] = a[0] &times; b[7:0] = {8{a[0]}} & b[7:0] p1[7:0] = a[1] &times; b[7:0] = {8{a[1]}} & b[7:0] p2[7:0] = a[2] &times; b[7:0] = {8{a[2]}} & b[7:0] p3[7:0] = a[3] &times; b[7:0] = {8{a[3]}} & b[7:0] p4[7:0] = a[4] &times; b[7:0] = {8{a[4]}} & b[7:0] p5[7:0] = a[5] &times; b[7:0] = {8{a[5]}} & b[7:0] p6[7:0] = a[6] &times; b[7:0] = {8{a[6]}} & b[7:0] p7[7:0] = a[7] 