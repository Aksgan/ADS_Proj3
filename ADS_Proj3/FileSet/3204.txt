Tier-1 center that is part of the WLCG collaboration. NDGF is hosted by NORDUnet. NorGrid is funded in part by the Research Council of Norway through the eVITA programme on e-Science. ==External links== *[http://www.rcn.no/eVITA eVITA] programme on e-Science from the Research Council of Norway *[http://www.notur.no/ Notur] *[http://www.norstore.no/ NorStore] *[http://www.norgrid.no/ NorGrid] *[http://sigma.uninett.no/ UNINETT Sigma] *[http://www.ntnu.no/ NTNU] *[http://www.uib.no/ UiB] *[http://www.uio.no/ UiO] *[http://www.uit.no/ UiT] *[http://www.met.no/ met.no] [[Category:Computational science]] [[Category:Science and technology in Norway]]</text> </page> <page> <id>26626</id> <title>Nordic Data Grid Facility</title> <text>The '''Nordic Data Grid Facility''', or '''NDGF''', is a collaboration between the Nordic countries ([[Denmark]], [[Finland]], [[Norway]], [[Sweden]] and [[Iceland]]). The motivation for NDGF is to ensure that researchers in the Nordic countries can create and participate in computational challenges of scope and size unreachable for the national research groups alone. == History == Nordic Data Grid Facility traces its history back to end-2001, being intrinsically related to the [[NorduGrid]] project. Success of the latter indicated need for a larger pan-Nordic facility, with storage resources being of high priority. This need has been addressed by establishing a pilot NDGF infrastructure, which was operational in 2002-2005, and provided distributed storage in addition to the [[NorduGrid]] computing resources. During this phase, NDGF committed to provide a Nordic Tier1 (regional computing center) for the Worldwide [[Large Hadron Collider|LHC]] Computing Grid project at [[CERN]]. Specifics of this Tier1 are such that it has to be an internationally distributed Facility. The Nordic Data Grid Facility in its present function as a provider of the Nordic Grid Infrastructure was established in April 2006 by the Nordic Research Councils. It came into operation on June 1, 2006, and its initial priority is to live up to the original commitment of establishing the Nordic Tier1, with the traditional focus on storage facilities. A large team of developers is meant to assist in Grid middleware development, complementing [[NorduGrid]] efforts. == Users and resources == NDGF is a production [[Grid computing|Grid]] facility that leverages existing, national computational resources and Grid infrastructures. To qualify for support research groups should form a Virtual Organization, a VO. The VO provides compute resources for sharing and NDGF operates a Grid interface for the sharing of these resources. Currently, most computational resources of NDGF are accessible through [[Advanced Resource Connector|ARC]] middleware. Some resources are also available via [[Alien (software)|AliEn]] software and [[gLite]] middleware. Distributed storage facility is realised through [[dCache]] storage management solution. Today, the first operational user of the NDGF is the Nordic High Energy Physics community - the [[ALICE]], [[ATLAS]] and [[Content management system|CMS]] Virtual Organizations - through the operation of the Nordic Tier-1, which together with the Tier-0, [[CERN]], and the other 10 Tier-1s collects, stores and processes the data produced by the [[Large Hadron Collider]] at [[CERN]]. NDGF is hosted by [[NORDUnet]]. == NDGF vs [[NorduGrid]] == Many confuse NDGF and [[NorduGrid]] - which is not surprising, especially since in its second phase NDGF was proposed to assume the name "NorduGrid". It was however decided to distinguish between the mostly development-oriented project, [[NorduGrid]], and the mostly operations-oriented one, NDGF. As a rule of thumb, NDGF provides mostly services, while [[NorduGrid]] provides mostly [[Advanced Resource Connector|ARC]] middleware. == See also == * [[NorduGrid]] collaboration, provider of the [[Advanced Resource Connector|ARC]] middleware * [[NORDUnet]], the NDGF hosting organisation ===External links=== * [http://www.ndgf.org NDGF homepage] * [http://www.cern.ch CERN], host of the Worldwide LHC Computing Grid * [http://www.dcache.org dCache], system for storing and retrieving massive data [[Category:Grid computing]] [[Category:Distributed computing projects]]</text> </page> <page> <id>26634</id> <title>Normal form (term rewriting)</title> <text>{{Unreferenced|date=August 2009}} {{Cleanup|date=August 2009}} In considering [[rewriting]] systems, a '''normal form''' is an element of the system which cannot be rewritten any further. Consider the basic term rewriting system with reduction rule ρ : ''g''(''x'', ''y'') → ''x''. The term ''g''(''g''(4, 2), ''g''(3, 1)) has the following reduction sequence, according to the usual outermost [[strategy (term rewriting)|strategy]], that is, if the reduction rule is applied to each outermost occurrence of ''g'': : <math> g(g(4,2), g(3,1)) \rightarrow_\rho g(4,3) \rightarrow_\rho 4.</math> There is no rule that permits us to rewrite 4, so 4 is a normal form for this term rewriting system. Related concepts are related to the possibility of rewriting an element into normal form. ''Weak normalization'' is defined as the possibility that some element can be rewritten into a normal form. ''Strong normalization'' is defined as any reduction sequence starting from some element terminates. We say that the system is weakly normalizing (or strongly normalizing) if all elements are weakly normalizing (resp. strongly normalizing). [[Newman's lemma]] states that if an [[abstract reduction system]] ''A'' is strongly normalizing and is [[confluence (term rewriting)|weakly confluent]], then ''A'' is in fact confluent. The result enables us to further generalize the [[critical pair lemma]]. {{DEFAULTSORT:Normal Form (Term Rewriting)}} [[Category:Computability theory]] [[Category:Formal languages]] [[Category:Rewriting systems]] {{comp-sci-theory-stub}} [[pt:Forma normal]]</text> </page> <page> <id>26636</id> <title>Normal mapping</title> <text>{{No footnotes|date=February 2010}} [[Image:Normal map example.png|thumb|Normal mapping used to re-detail simplified meshes.]] In [[3D computer graphics]], '''normal mapping''', or "Dot3 bump mapping", is a technique used for faking the lighting of bumps and dents. It is used to add details without using more [[polygonal modeling|polygon]]s. A normal map is usually an [[RGB]] image that corresponds to the X, Y, and Z coordinates of a [[surface normal]] from a more detailed version of the object. A common use of this technique is to greatly enhance the appearance and details of a [[low poly|low polygon model]] by generating a normal map from a high polygon model. == History == The idea of taking geometric details from a high polygon model was introduced in "Fitting Smooth Surfaces to Dense Polygon Meshes" by Krishnamurthy and Levoy, Proc. [[SIGGRAPH]] 1996, where this approach was used for creating [[displacement mapping|displacement maps]] over [[nurbs]]. In 1998, two papers were presented with the idea of transferring details with normal maps from high to low polygon meshes: "Appearance Preserving Simplification", by Cohen et al. SIGGRAPH 1998, and "A general method for preserving attribute values on simplified meshes" by Cignoni et al. IEEE Visualization '98. The former presented a particular constrained simplification 