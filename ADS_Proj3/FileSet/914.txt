data that are themselves only a randomly selected subset of an entire statistical population of possible datasets. There are other answers, notably that provided by [[Bayesian inference]] in the form of [[credible intervals]]. The idea of confidence intervals is that they correspond to a chosen rule for determining the confidence bounds, where this rule is essentially determined before any data are obtained, or before an experiment is done. The criterion for choosing this rule is that, over all possible datasets that might be obtained, there is a high probability that the interval determined by the rule will include the true value of the quantity under consideration. That is a fairly straightforward and reasonable way of specifying a rule for determining uncertainty intervals. The Bayesian approach appears to offer intervals that can, subject to acceptance of an interpretation of "probability" as [[Bayesian probability]], be interpreted as meaning that the specific interval calculated from a given dataset has a certain probability of including the true value, conditional on the data and other information available. The confidence interval approach does not allow this, since in this formulation and at this same stage, both the bounds of interval and the true values are fixed values and there is no randomness involved. For example, in the poll example outlined in the introduction, one common-sense interpretation of a "95% interval" might be that readers of this information can be 95% confident that the actual number of voters intending to vote for the party in question is between 36% to 44%. However, this is technically incorrect. The actual meaning of confidence levels and confidence intervals is rather more subtle. In the above case, a correct interpretation would be as follows: If the polling a large were repeated a number of times, each time generating a 95% confidence interval from the poll sample, then approximately 95% of the generated intervals would contain the true percentage of voters who intend to vote for the given party. Each time the polling is repeated, a ''different'' confidence interval is produced; hence, it is not possible to make precise statements about probabilities for any one given interval. For more information, see the section on [[#Meaning and interpretation|meaning and interpretation]]. The questions of how an interval expressing uncertainty in an estimate might be formulated, and of how such intervals might be interpreted, are not strictly a mathematical problems and are philosophically problematic.<ref>T. Seidenfeld, ''Philosophical Problems of Statistical Inference: Learning from R.A. Fisher'', Springer-Verlag, 1979</ref> Mathematics can take over once the basic principles of an approach to inference have been established, but it has only a limited role in saying why one approach should be preferred to another. ==Confidence intervals for proportions and related quantities== {{See also|Margin of error|Binomial proportion confidence interval}} An approximate confidence interval for a population mean can be constructed for random variables that are not normally distributed in the population, relying on the [[central limit theorem]], if the [[sample size]]s and counts are big enough. The formulae are identical to the case above (where the sample mean is actually normally distributed about the population mean). The approximation will be quite good with only a few dozen observations in the sample if the [[probability distribution]] of the random variable is not too different from the [[normal distribution]] (e.g. its [[cumulative distribution function]] does not have any [[discontinuities]] and its [[skewness]] is moderate). One type of sample mean is the mean of an [[indicator variable]], which takes on the value 1 for true and the value 0 for false. The mean of such a variable is equal to the proportion that have the variable equal to one (both in the population and in any sample). This is a useful property of [[indicator variable]]s, especially for hypothesis testing. To apply the [[central limit theorem]], one must use a large enough sample. A rough rule of thumb is that one should see at least 5 cases in which the indicator is 1 and at least 5 in which it is 0. Confidence intervals constructed using the above formulae may include negative numbers or numbers greater than 1, but proportions obviously cannot be negative or exceed 1. Additionally, sample proportions can only take on a finite number of values, so the [[central limit theorem]] and the [[normal distribution]] are not the best tools for building a confidence interval. See "[[Binomial proportion confidence interval]]" for better methods which are specific to this case. ==See also== {{wikiversity}} * [[p-value]] * [[Error bar]] * [[Tolerance interval]] * [[Robust confidence intervals]] == Online calculators == * [http://www.stat.tamu.edu/~jhardin/applets/index.html TAMU's Confidence Interval Calculators] * [http://www.graphpad.com/quickcalcs/index.cfm GraphPad QuickCalcs] ==Notes== <!-- {{Cnote2 Begin|liststyle=upper-alpha|colwidth=40em}} --> {{Cnote2 Begin|liststyle=upper-alpha}} {{Cnote2|A|A sufficiently committed [[Frequentist statistics|Frequentist]] would not even accept the thought of a probability distribution for the parameter, as they would not consider the parameter a [[random variable]]}} {{Cnote2 End}} ==References== {{reflist}} ==Bibliography== {{refbegin}} * [[Ronald Fisher|Fisher, R.A.]] (1956) ''Statistical Methods and Scientific Inference.'' Oliver and Boyd, Edinburgh. (See p. 32.) * Freund, J.E. (1962) ''Mathematical Statistics'' Prentice Hall, Englewood Cliffs, NJ. (See pp. 227&ndash;228.) * [[Ian Hacking|Hacking, I.]] (1965) ''Logic of Statistical Inference.'' Cambridge University Press, Cambridge. ISBN 0521051657 * Keeping, E.S. (1962) ''Introduction to Statistical Inference.'' D. Van Nostrand, Princeton, NJ. * [[Jack Kiefer (mathematician)|Kiefer, J.]] (1977) [http://links.jstor.org/sici?sici=0162-1459%28197712%2972%3A360%3C789%3ACCSACE%3E2.0.CO%3B2-9 "Conditional Confidence Statements and Confidence Estimators (with discussion)"] ''Journal of the American Statistical Association,'' '''72,''' 789&ndash;827. * Mayo, D. G. (1981) [http://www.phil.vt.edu/dmayo/PhilStatistics/In%20Defense%20of%20the%20Neyman-Pearson%20Theory%20of%20Confidence%20Intervals.pdf "In defence of the Neyman-Pearson theory of confidence intervals"], ''Philosophy of Science'', 48 (2), 269&ndash;280. {{JSTOR|187185}} * [[Jerzy Neyman|Neyman, J.]] (1937) [http://links.jstor.org/sici?sici=0080-4614%2819370830%29236%3A767%3C333%3AOOATOS%3E2.0.CO%3B2-6 "Outline of a Theory of Statistical Estimation Based on the Classical Theory of Probability"] ''Philosophical Transactions of the Royal Society of London A,'' '''236,''' 333&ndash;380. (Seminal work.) * Robinson, G.K. (1975) [http://links.jstor.org/sici?sici=0006-3444%28197504%2962%3A1%3C155%3ASCTTTO%3E2.0.CO%3B2-4 "Some Counterexamples to the Theory of Confidence Intervals."] ''Biometrika,'' '''62,''' 155&ndash;161. * Smithson, M. (2003) ''Confidence intervals''. Quantitative Applications in the Social Sciences Series, No. 140. Belmont, CA: SAGE Publications. ISBN 9780761924999. {{refend}} ==External links== * [http://www.latrobe.edu.au/psy/esci/ The Exploratory Software for Confidence Intervals tutorial programs that run under Excel] * Confidence 