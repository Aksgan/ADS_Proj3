We can define a [[best response]] [[Mathematics|correspondence]] for player <math>i</math>, <math>b_i</math>. <math>b_i</math> is a relation from the set of all probability distributions over opponent player profiles to a set of player <math>i</math>'s strategies, such that each element of :<math>b_i(\sigma_{-i})\ </math> is a best response to <math>\sigma_{-i}</math>. Define :<math>b(\sigma) = b_1(\sigma_{-1}) \times b_2(\sigma_{-2}) \times \cdots \times b_n(\sigma_{-n}).\ </math> One can use the [[Kakutani fixed point theorem]] to prove that <math>b</math> has a fixed point. That is, there is a <math>\sigma^*</math> such that <math>\sigma^* \in b(\sigma^*)</math>. Since <math>b(\sigma^*)</math> represents the best response for all players to <math>\sigma^*</math>, the existence of the fixed point proves that there is some strategy set which is a best response to itself. No player could do any better by deviating, and it is therefore a Nash equilibrium. When Nash made this point to [[John von Neumann]] in 1949, von Neumann famously dismissed it with the words, "That's trivial, you know. That's just a [[Fixed point (mathematics)|fixed point]] theorem." (See Nasar, 1998, p. 94.) === Alternate proof using the Brouwer fixed point theorem === We have a game <math>G=(N,A,u)</math> where <math>N</math> is the number of players and <math>A = A_1 \times \ldots \times A_N</math> is the action set for the players. All of the action sets <math>A_i</math> are finite. Let <math>\Delta = \Delta_1 \times \ldots \times \Delta_N</math> denote the set of mixed strategies for the players. The finiteness of the <math>A_i</math>s ensures the compactness of <math>\Delta</math>. We can now define the gain functions. For a mixed strategy <math>\sigma \in \Delta</math>, we let the gain for player <math>i</math> on action <math>a \in A_i</math> be :<math>Gain_i(\sigma,a) = \max \{0, u_i(a_i, \sigma_{-i}) - u_i(\sigma_{i}, \sigma_{-i})\}.\ </math> The gain function represents the benefit a player gets by unilaterally changing his strategy. We now define <math>g = (g_1,\ldots,g_N)</math> where :<math>g_i(\sigma)(a) = \sigma_i(a) + Gain_i(\sigma,a)\ </math> for <math>\sigma \in \Delta, a \in A_i</math>. We see that :<math>\sum_{a \in A_i} g_i(\sigma)(a) = \sum_{a \in A_i} \sigma_i(a) + Gain_i(\sigma,a) = 1 + \sum_{a \in A_i} Gain_i(\sigma,a) > 0.\ </math> We now use <math>g</math> to define <math>f: \Delta \rightarrow \Delta</math> as follows. Let :<math> f_i(\sigma)(a) = \frac{g_i(\sigma)(a)}{\sum_{b \in A_i} g_i(\sigma)(b)} </math> for <math>a \in A_i</math>. It is easy to see that each <math>f_i</math> is a valid mixed strategy in <math>\Delta_i</math>. It is also easy to check that each <math>f_i</math> is a continuous function of <math>\sigma</math>, and hence <math>f</math> is a continuous function. Now <math>\Delta</math> is the cross product of a finite number of compact convex sets, and so we get that <math>\Delta</math> is also compact and convex. Therefore we may apply the Brouwer fixed point theorem to <math>f</math>. So <math>f</math> has a fixed point in <math>\Delta</math>, call it <math>\sigma^*</math>. I claim that <math>\sigma^*</math> is a Nash Equilibrium in <math>G</math>. For this purpose, it suffices to show that :<math> \forall 1 \leq i \leq N, ~ \forall a \in A_i, ~ Gain_i(\sigma^*,a) = 0 \text{.} </math> This simply states the each player gains no benefit by unilaterally changing his strategy which is exactly the necessary condition for being a Nash Equilibrium. Now assume that the gains are not all zero. Therefore, <math>\exists i</math>, <math>1 \leq i \leq N</math>, and <math>a \in A_i</math> such that <math>Gain_i(\sigma^*, a) > 0</math>. Note then that :<math> \sum_{a \in A_i} g_i(\sigma^*, a) = 1 + \sum_{a \in A_i} Gain_i(\sigma^*,a) > 1. </math> So let <math>C = \sum_{a \in A_i} g_i(\sigma^*, a)</math>. Also we shall denote <math>Gain(i,\cdot)</math> as the gain vector indexed by actions in <math>A_i</math>. Since <math>f(\sigma^*) = \sigma^*</math> we clearly have that <math>f_i(\sigma^*) = \sigma^*_i</math>. Therefore we see that :<math> \sigma^*_i = \frac{g_i(\sigma^*)}{\sum_{a \in A_i} g_i(\sigma^*)(a)} \Rightarrow \sigma^*_i = \frac{\sigma^*_i + Gain_i(\sigma^*,\cdot)}{C} \Rightarrow C\sigma^*_i = \sigma^*_i + Gain_i(\sigma^*,\cdot) </math> :<math> \left(C-1\right)\sigma^*_i = Gain_i(\sigma^*,\cdot) \Rightarrow \sigma^*_i = \left(\frac{1}{C-1}\right)Gain_i(\sigma^*,\cdot). </math> Since <math>C > 1</math> we have that <math>\sigma^*_i</math> is some positive scaling of the vector <math>Gain_i(\sigma^*,\cdot)</math>. Now I claim that :<math> \sigma^*_i(a)(u_i(a_i, \sigma^*_{-i}) - u_i(\sigma^*_i, \sigma^*_{-i})) = \sigma^*_i(a)Gain_i(\sigma^*, a) </math> <math>\forall a \in A_i</math>. To see this, we first note that if <math>Gain_i(\sigma^*, a) > 0</math> then this is true by definition of the gain function. Now assume that <math>Gain_i(\sigma^*, a) = 0</math>. By our previous statements we have that :<math> \sigma^*_i(a) = \left(\frac{1}{C-1}\right)Gain_i(\sigma^*, a) = 0 </math> and so the left term is zero, giving us that the entire expression is <math>0</math> as needed. So we finally have that :<math> 0 = u_i(\sigma^*_i, \sigma^*_{-i}) - u_i(\sigma^*_i, \sigma^*_{-i}) </math> <br/> :<math> = \left(\sum_{a \in A_i} \sigma^*_i(a)u_i(a_i, \sigma^*_{-i})\right) - u_i(\sigma^*_i, \sigma^*_{-i}) </math> <br/> :<math> = \sum_{a \in A_i} \sigma^*_i(a) (u_i(a_i, \sigma^*_{-i}) - u_i(\sigma^*_i, \sigma^*_{-i})) </math> <br/> :<math> = \sum_{a \in A_i} \sigma^*_i(a) Gain_i(\sigma^*, a) \quad \text{ by the previous statements } </math> <br/> :<math> = \sum_{a \in A_i} \left( C -1 \right) \sigma^*_i(a)^2 > 0 </math> where the last inequality follows since <math>\sigma^*_i</math> is a non-zero vector. But this is a clear contradiction, so all the gains must indeed be zero. Therefore <math>\sigma^*</math> is a Nash Equilibrium for <math>G</math> as needed. == Computing Nash equilibria == If a player A has a [[dominant strategy]] <math>s_A</math> then there exists a Nash equilibrium in which A plays <math>s_A</math>. In the case of two players A and B, there exists a Nash equilibrium in which A plays <math>s_A</math> and B plays a [[best response]] to <math>s_A</math>. If <math>s_A</math> is a strictly dominant strategy, A plays <math>s_A</math> in all Nash equilibria. If both A and B have strictly dominant strategies, there exists a unique Nash equilibrium in which each plays his strictly dominant strategy. In games with mixed strategy Nash equilibria, the probability of a player choosing any particular strategy can be computed by assigning a variable to each strategy that represents a fixed probability for choosing that strategy. In order for a player to be willing to randomize, his expected payoff for each strategy should be the same. In addition, the sum of the probabilities for each strategy of a particular player should be 1. This creates a system of equations from which the probabilities of choosing each strategy can be derived.<ref name="preliminaries" /> === Examples === {| 