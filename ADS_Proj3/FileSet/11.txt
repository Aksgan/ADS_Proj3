visualization field used in conjunction with [[3ds max]] and [[3ds viz]]. It is also commonly used with Maya. *[[YafRay]] is a raytracer/renderer distributed under the LGPL. This project is no longer being actively developed. *[[YafaRay]] YafRay's successor, a raytracer/renderer distributed under the LGPL. ==Related to 3D software== *[[Swift3D]] is the marquee tool for producing vector-based 3D content for Flash. Also comes in plug-in form for transforming models in Lightwave or 3DS Max into [[Adobe Systems|Flash]] animations. *[[Match moving]] software is commonly used to match live video with computer-generated video, keeping the two in sync as the camera moves. *After producing video, studios then [[Film editing|edit]] or [[Compositing|composite]] the video using programs such as [[Adobe Systems|Adobe]] [[Adobe Premiere Pro|Premiere]] or [[Apple Computer|Apple]] [[Final Cut Pro|Final Cut]] at the low end, or [[Autodesk Combustion]], [[Digital Fusion]], [[Apple Computer|Apple]] [[Shake (software)|Shake]] at the high end. *[[MetaCreations]] Detailer and Painter 3D are discontinued software applications specifically for painting [[texture map]]s on 3-D Models. *[[Simplygon]] A commercial mesh processing package for [[Computer graphics (computer science)#Geometry|remeshing]] general input meshes into [[Real-time computer graphics|real-time]] renderable meshes. *[[Typestry|Pixar Typestry]] is an abandonware 3D software program released in the 1990s by Pixar for Apple Macintosh and DOS-based PC computer systems. It rendered and animated text in 3d in various fonts based on the user's input. ==See also== {{Wikipedia-Books|3D Rendering}} * [[Comparison of 3D computer graphics software]] * [[3D data acquisition and object reconstruction]] * [[3D modeling]] * [[Computer-aided design]] * [[Game development tool]] * [[Game engine]] * [[Level editor]] * [[List of 3D graphics software]] * [[Render farm]] ==References== {{reflist}} == External links == * [http://wiki.cgsociety.org/index.php/Comparison_of_3d_tools Comparison of 3D Tools] from the Society of Digital Artists {{3D software}} {{DEFAULTSORT:3d Computer Graphics Software}} [[Category:3D graphics software| ]] [[Category:3D computer graphics]] [[de:3D-Grafik-Software]] [[fr:Logiciel de modélisation 3D]] [[ja:3DCGソフトウェア]] [[ro:Programe de grafică 3D]] [[fi:Luettelo 3D-grafiikkaohjelmista]] [[th:ซอฟต์แวร์เพื่องานกราฟิกส์สามมิติ]] [[zh:三维计算机图形软件]]</text> </page> <page> <id>139</id> <title>3D single object recognition</title> <text>{{FeatureDetectionCompVisNavbox}} In [[computer vision]], '''3D single [[object recognition]]''' involves recognizing and determining the pose of user-chosen [[Three-dimensional space|3D]] object in a [[photograph]] or [[range scan]]. Typically, an example of the object to be recognized is presented to a vision system in a controlled environment, and then for an arbitrary input such as a [[video stream]], the system locates the previously presented object. This can be done either [[off-line]], or in [[real-time]]. The [[algorithms]] for solving this problem are specialized for locating a single pre-identified object, and can be contrasted with algorithms which operate on general [[class (computer science)|classes]] of objects, such as [[Facial recognition system|face recognition systems]] or [[3D generic object recognition]]. Due to the low cost and ease of acquiring photographs, a significant amount of research has been devoted to 3D object recognition in photographs. == 3D single object recognition in photographs == The method of recognizing a 3D object depends on the properties of an object. For simplicity, many existing algorithms have focused on recognizing [[Stiffness|rigid]] objects consisting of a single part, that is, objects whose spatial transformation is a [[Euclidean motion]]. Two general approaches have been taken to the problem: [[pattern recognition]] approaches use low-level image appearance information to locate an object, while feature-based geometric approaches construct a model for the object to be recognized, and match the model against the photograph. === Pattern recognition approaches === These methods use appearance information gathered from pre-captured or pre-computed projections of an object to match the object in the potentially cluttered scene. However, they do not take the 3D geometric constraints of the object into consideration during matching, and typically also do not handle occlusion as well as feature-based approaches. See [Murase and Nayar 1995] and [Selinger and Nelson 1999]. === Feature-based geometric approaches === [[Image:Feature example.png|right|thumb|322px|An example of a detected feature in an image. Blue indicates the center of the feature, the red ellipse indicates the characteristic scale identified by the feature detector, and the green parallelogram is constructed from the coordinates of the ellipse as per [Lowe 2004].]] Feature-based approaches work well for objects which have distinctive [[Feature (Computer vision)|features]]. Thus far, objects which have good [[edge feature]]s or [[Blob detection|blob]] features have been successfully recognized; for example detection algorithms, see [[Harris affine region detector]] and [[Scale-invariant feature transform|SIFT]], respectively. Due to lack of the appropriate feature detectors, objects without textured, smooth surfaces cannot currently be handled by this approach. Feature-based object recognizers generally work by pre-capturing a number of fixed views of the object to be recognized, extracting features from these views, and then in the recognition process, matching these features to the scene and enforcing geometric constraints. As an example of a prototypical system taking this approach, we will present an outline of the method used by [Rothganger et al. 2004], with some detail elided. The method starts by assuming that objects undergo globally rigid transformations. Because smooth surfaces are locally planar, [[affine invariant]] features are appropriate for matching: the paper [[feature detector|detects]] ellipse-shaped regions of interest using both edge-like and blob-like features, and as per [Lowe 2004], finds the dominant gradient direction of the ellipse, converts the ellipse into a parallelogram, and takes a [[SIFT]] descriptor on the resulting parallelogram. Color information is used also to improve discrimination over SIFT features alone. [[Image:Partial features 3d.png|right|thumb|322px|Partial models of features, projected into 3D, constructed from nearby views of a teddy-bear. Taken from [Rothganger et al. 2004].]] Next, given a number of camera views of the object (24 in the paper), the method constructs a 3D model for the object, containing the 3D spatial position and orientation of each feature. Because the number of views of the object is large, typically each feature is present in several adjacent views. The center points of such matching features correspond, and detected features are aligned along the dominant gradient direction, so the points at (1, 0) in the local coordinate system of the feature parallelogram also correspond, as do the points (0, 1) in the parallelogram's local coordinates. Thus for every pair of matching features in nearby views, three point pair correspondences are known. Given at least two matching 