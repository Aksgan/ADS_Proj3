AI researchers argue that trying to pass the Turing Test is merely a distraction from more fruitful research.<ref name=SHIEBER/> Indeed, the Turing test is not an active focus of much academic or commercial effort—as [[Stuart Russell]] and [[Peter Norvig]] write: "AI researchers have devoted little attention to passing the Turing test."<ref name=RussellNorvig2003p3>{{Harvnb|Russell|Norvig|2003|p=3}}</ref> There are several reasons. First, there are easier ways to test their programs. Most current research in AI-related fields is aimed at modest and specific goals, such as [[automated planning and scheduling|automated scheduling]], [[object recognition]], or [[logistics]]. In order to test the intelligence of the programs that solve these problems, AI researchers simply give them the task directly, rather than going through the roundabout method of posing the question in a [[chat room]] populated with computers and people. Second, creating life-like simulations of human beings is a difficult problem on its own that does not need to be solved to achieve the basic goals of AI research. Believable human characters may be interesting in a work of art, a [[video game|game]], or a sophisticated [[user interface]], but they are not part of the science of creating intelligent machines, that is, machines that solve problems using intelligence. Russell and Norvig suggest an analogy with the [[history of flight]]: Planes are tested by how well they fly, not by comparing them to birds. "[[Aeronautics|Aeronautical engineering]] texts," they write, "do not define the goal of their field as 'making machines that fly so exactly like [[pigeon]]s that they can fool other pigeons.'"<ref name=RussellNorvig2003p3/> Turing, for his part, never intended his test to be used as a practical, day-to-day measure of the intelligence of AI programs; he wanted to provide a clear and understandable example to aid in the discussion of the [[philosophy of artificial intelligence]].<ref>{{Harvnb|Turing|1950}}, under the heading "The Imitation Game," where he writes, "Instead of attempting such a definition I shall replace the question by another, which is closely related to it and is expressed in relatively unambiguous words."</ref> As such, it is not surprising that the Turing test has had so little influence on AI research — the philosophy of AI, writes [[John McCarthy (computer scientist)|John McCarthy]], "is unlikely to have any more effect on the practice of AI research than philosophy of science generally has on the practice of science."<ref>John McCarthy [http://www-formal.stanford.edu/jmc/aiphil/node2.html#SECTION00020000000000000000 The philosophy of artificial intelligence]</ref> ==Predictions== Turing predicted that machines would eventually be able to pass the test; in fact, he estimated that by the year 2000, machines with 10<sup>9</sup> [[bit]]s (about 119.2 [[mebibyte|MiB]] or approximately 120 [[megabyte]]s) of memory would be able to fool thirty percent of human judges in a five-minute test. He also predicted that people would then no longer consider the phrase "thinking machine" contradictory. He further predicted that [[machine learning]] would be an important part of building powerful machines, a claim considered plausible by contemporary researchers in artificial intelligence.<ref>{{Harv|Turing|1950|p=442}}</ref> In a paper submitted to 19th Midwest Artificial Intelligence and Cognitive Science Conference, Dr.Shane T. Mueller predicted a modified Turing Test called a "Cognitive Decathlon" could be accomplished within 5 years.<ref>{{Citation | title = Is the Turing Test Still Relevant? A Plan for Developing the Cognitive Decathlon to Test Intelligent Embodied Behavior| journal = Paper submitted to the 19th Midwest Artificial Intelligence and Cognitive Science Conference | author = Shane T. Mueller, Ph.D.| url = http://www.dod.mil/pubs/foi/darpa/08_F_0799Is_the_Turing_test_Still_Relevant.pdf | accessdate = 2010-09-08 | year = 2008 | pages = 8pp }}</ref> By extrapolating an [[technological singularity#Accelerating change|exponential growth]] of technology over several decades, [[futurology|futurist]] [[Raymond Kurzweil]] predicted that Turing test-capable computers would be manufactured in the near future. In 1990, he set the year around 2020.<ref>{{Harvnb|Kurzweil|1990}}</ref> By 2005, he had revised his estimate to 2029.<ref>{{Harvnb|Kurzweil|2005}}</ref> The [[Long Bet Project]] is a wager of [[United States dollar|$]]20,000 between [[Mitch Kapor]] (pessimist) and Kurzweil (optimist) about whether a computer will pass a Turing Test by the year 2029. The bet specifies the conditions in some detail.<ref>[http://www.longbets.org/1#terms Long Bets - By 2029 no computer - or "machine intelligence" - will have passed the Turing Test]</ref> ==Variations of the Turing test== Numerous other versions of the Turing test, including those expounded above, have been mooted through the years. ===Reverse Turing test and CAPTCHA=== {{main|reverse Turing test|CAPTCHA}} A modification of the Turing test wherein the objective of one or more of the roles have been reversed between machines and humans is termed a reverse Turing test. An example is implied in the work of psychoanalyst [[Wilfred Bion]],<ref>{{Harvnb|Bion|1979}}</ref> who was particularly fascinated by the "storm" that resulted from the encounter of one mind by another. Carrying this idea forward, [[R. D. Hinshelwood]]<ref>{{Harvnb|Hinshelwood|2001}}</ref> described the mind as a "mind recognizing apparatus," noting that this might be some sort of "supplement" to the Turing test. The challenge would be for the computer to be able to determine if it were interacting with a human or another computer. This is an extension of the original question that Turing attempted answer but would, perhaps, offer a high enough standard to define a machine that could "think" in a way that we typically define as characteristically human. [[CAPTCHA]] is a form of reverse Turing test. Before being allowed to perform some action on a [[website]], the user is presented with alphanumerical characters in a distorted graphic image and asked to type them out. This is intended to prevent automated systems from being used to abuse the site. The rationale is that software sufficiently sophisticated to read and reproduce the distorted image accurately does not exist (or is not available to the average user), so any system able to do so is likely to be a human. Software that can reverse CAPTCHA with some accuracy by analyzing patterns in the generating engine is being actively developed.<ref>{{Citation | url=http://www.cs.sfu.ca/~mori/research/gimpy/ | title=Breaking a Visual CAPTCHA | authors=Greg Mori and [[Jitendra Malik]] }}</ref> ==="Fly on the wall" Turing test=== {{Unreferenced section|date=May 2009}} The "fly on the wall" variation of the Turing test changes the original Turing-test parameters in three ways. First, parties A and B communicate with each other 