{{commons cat|Activity diagrams}} *[http://www.omg.org/technology/documents/formal/uml.htm UML 2.0 Specification Documents] *[http://www.agilemodeling.com/artifacts/activityDiagram.htm Introduction to UML 2 Activity Diagrams] *[http://www.uml-diagrams.org/activity-diagrams.html UML 2 Activity Diagrams] {{UML}} {{DEFAULTSORT:Activity Diagram}} [[Category:UML diagrams]] [[Category:SysML]] {{uml-stub}} [[cs:Diagram aktivit]] [[de:Aktivitätsdiagramm]] [[es:Diagrama de actividades]] [[fr:Diagramme d'activité]] [[it:Activity diagram]] [[lt:Veiklos diagrama]] [[nl:Activiteitendiagram]] [[ja:アクティビティ図]] [[pl:Diagram czynności]] [[pt:Diagrama de atividade]] [[ru:Диаграмма деятельности]] [[sk:Diagram aktivít]] [[fi:Aktiviteettikaavio]] [[tr:Faaliyet Diyagramı]] [[uk:Діаграма діяльності]]</text> </page> <page> <id>898</id> <title>Activity recognition</title> <text>'''Activity recognition''' aims to recognize the actions and goals of one or more agents from a series of observations on the agents' actions and the environmental conditions. Since the 1980s, this research field has captured the attention of several [[computer science]] communities due to its strength in providing personalized support for many different applications and its connection to many different fields of study such as medicine, human-computer interaction, or sociology. To understand activity recognition better, consider the following scenario. An elderly man wakes up at dawn in his small studio apartment, where he stays alone. He lights the stove to make a pot of tea, switches on the toaster oven, and takes some bread and jelly from the cupboard. After taking his morning medication, a computer-generated voice gently reminds him to turn off the toaster. Later that day, his daughter accesses a secure website where she scans a check-list, which was created by a sensor network in her father's apartment. She finds that her father is eating normally, taking his medicine on schedule, and continuing to manage his daily life on his own. That information puts her mind at ease. Many different applications have been studied by researchers in activity recognition; examples include assisting the sick and disabled. For example, Pollack et al.<ref>Pollack, M.E., and et al., L. E. B. 2003. "Autominder: an intelligent cognitive orthotic system for people with memory impairment". ''Robotics and Autonomous Systems'' 44(3-4):273–282.</ref> show that by automatically monitoring human activities, home-based rehabilitation can be provided for people suffering from traumatic brain injuries. One can find applications ranging from security-related applications and logistics support to location-based services. Due to its many-faceted nature, different fields may refer to activity recognition as plan recognition, goal recognition, intent recognition, behavior recognition, location estimation and location-based services. ==Types of activity recognition== ===Sensor-based, single-user activity recognition=== [[Sensor]]-based activity recognition integrates the emerging area of sensor networks with novel [[data mining]] and [[machine learning]] techniques to model a wide range of human activities.<ref>Tanzeem Choudhury, Gaetano Borriello, et al. The Mobile Sensing Platform: An Embedded System for Activity Recognition. Appears in the IEEE Pervasive Magazine - Special Issue on Activity-Based Computing, April 2008.</ref> Mobile devices (e.g. smart phones) provide sufficient sensor data and calculation power to enable physical activity recognition to provide an estimation of the energy consumption during everyday life. Sensor-based activity recognition researchers believe that by empowering [[ubiquitous computing|ubiquitous computers]] and sensors to monitor the behavior of agents (under consent), these computers will be better suited to act on our behalf. ====Levels of sensor-based activity recognition==== Sensor-based activity recognition is a challenging task due to the inherent noisy nature of the input. Thus, [[statistical modeling]] has been the main thrust in this direction in layers, where the recognition at several intermediate levels is conducted and connected. At the lowest level where the sensor data are collected, statistical learning concerns how to find the detailed locations of agents from the received signal data. At an intermediate level, [[statistical inference]] may be concerned about how to recognize individuals' activities from the inferred location sequences and environmental conditions at the lower levels. Furthermore, at the highest level a major concern is to find out the overall goal or subgoals of an agent from the activity sequences through a mixture of logical and statistical reasoning. Scientific conferences where activity recognition work from wearable and environmental often appears are [[ISWC]] and [[UbiComp]]. ===Sensor-based, multi-user activity recognition=== Recognizing activities for multiple users using on-body sensors first appeared in the work by ORL using active badge systems <ref>Want R., Hopper A., Falcao V., Gibbons J.: The Active Badge Location System, ACM Transactions on Information, Systems, Vol. 40, No. 1, pp. 91-102, January 1992</ref> in the early 90´s. Other sensor technology such as acceleration sensors were used for identifying group activity patterns during office scenarios.<ref>Bieber G., Kirste T., Untersuchung des gruppendynamischen Aktivitaetsverhaltes im Office-Umfeld, 7. Berliner Werkstatt Mensch-Maschine-Systeme, Berlin, Germany, 2007</ref> Activities of Multiple Users in intelligent environments are addressed in Gu et al.<ref>Tao Gu, Zhanqing Wu, Liang Wang, Xianping Tao, and Jian Lu. Mining Emerging Patterns for Recognizing Activities of Multiple Users in Pervasive Computing. In Proc. of the 6th International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services (MobiQuitous '09), Toronto, Canada, July 13–16, 2009.</ref> In this work, they investigate the fundamental problem of recognizing activities for multiple users from sensor readings in a home environment, and propose a novel pattern mining approach to recognize both single-user and multi-user activities in a unified solution. Many interesting research topics can be spawn from this work. ===Vision-based activity recognition=== It is a very important and challenging problem to track and understand the behavior of agents through videos taken by various cameras. The primary technique employed is computer vision. Vision-based activity recognition has found many applications such as human-computer interaction, user interface design, robot learning, and surveillance, among others. Scientific conferences where vision based activity recognition work often appears are [[ICCV]] and [[CVPR]]. In vision-based activity recognition, a great deal of work has been done. Researchers have attempted a number of methods such as [[optical flow]], [[Kalman filtering]], hidden [[Markov model]]s, etc., under different modalities such as single camera, stereo, and infrared. In addition, researchers have considered multiple aspects on this topic, including single pedestrian tracking, group tracking, and detecting dropped objects. ====Levels of vision-based activity recognition==== In vision-based activity recognition, the computational process is often divided into four steps, namely human detection, human tracking, human activity recognition and then a high-level activity evaluation. ==Approaches of activity recognition== ===Activity recognition through logic and reasoning=== Logic-based approaches keep track of all [[logically consistent]] explanations of the observed actions. Thus, all 