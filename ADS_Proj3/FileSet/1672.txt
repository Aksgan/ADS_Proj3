wonder is that, even without choice, general metrics are [[monotonically normal]]. ''proof''. Case I: ''F'' is [[Archimedean]]. Now, if ''x'' in <math>G, G</math> open, we may take <math>\mu(x,G):= B(x,1/2n(x,G))</math>, where <math>n(x,G):= \min\{n\in\mathbb N:B(x,1/n)\subseteq G\}</math>, and the trick is done without choice. Case II: F is non-Archimedean. For given <math>x\in G</math> where ''G'' is open, consider the set <math>A(x,G):=\{a\in F\colon \forall n\in\mathbb N,B(x,n\cdot a)\subseteq G\}</math>. The set ''A''(''x'', ''G'') is non-empty. For, as ''G'' is open, there is an open ball ''B''(''x'', ''k'') within ''G''. Now, as ''F'' is non-Archimdedean, <math>\mathbb N_F</math> is not bounded above, hence there is some <math>\xi\in F</math> with <math>\forall n\in\mathbb N\colon n\cdot 1\le\xi</math>. Putting <math>a=k\cdot (2\xi)^{-1}</math>, we see that <math>a</math> is in ''A''(''x'', ''G''). Now define <math>\mu(x,G)=\bigcup\{B(x,a)\colon a\in A(x,G)\}</math>. We would show that with respect to this mu operator, the space is monotonically normal. Note that <math>\mu(x,G)\subseteq G</math>. If ''y'' is not in ''G''(open set containing ''x'') and ''x'' is not in ''H''(open set containing ''y''), then we'd show that <math>\mu(x,G)\cap\mu(y,H)</math> is empty. If not, say ''z'' is in the intersection. Then : <math>\exists a\in A(x,G)\colon d(x,z)<a;\;\; \exists b\in A(y,H)\colon d(z,y)<b</math>. From the above, we get that <math>d(x,y)\le d(x,z)+d(z,y)<2\cdot\max\{a,b\}</math>, which is impossible since this would imply that either ''y'' belongs to <math>\mu(x,G)\subseteq G</math> or ''x'' belongs to <math>\mu(y,H)\subseteq H</math>. So we are done! ==Discussion and links== * Carlos R. Borges, ''A study of monotonically normal spaces'', Proceedings of the American Mathematical Society, Vol. 38, No. 1. (Mar., 1973), pp. 211-214. [http://links.jstor.org/sici?sici=0002-9939(197303)38%3A1%3C211%3AASOMNS%3E2.0.CO%3B2-8] * FOM discussion [http://www.cs.nyu.edu/pipermail/fom/2007-August/011814.html link] [[category:topology]] [[category:Norms_(mathematics)]] [[category:Metric_geometry]]</text> </page> <page> <id>14962</id> <title>Generalized additive model</title> <text>In [[statistics]], the '''generalized additive model (GAM)''' is a [[statistical model]] developed by [[Trevor Hastie]] and [[Rob Tibshirani]] for blending properties of [[generalized linear model]]s with [[additive model]]s. The model specifies a distribution (such as a [[normal distribution]], or a [[binomial distribution]]) and a link function ''g'' relating the expected value of the distribution to the predictors, and attempts to fit functions ''f''<sub>''i''</sub>(''x''<sub>''i''</sub>) to satisfy: : <math>g(\operatorname{E}(Y))=\beta_0 + f_1(x_1) + f_2(x_2)+ \cdots + f_m(x_m).\,\!</math> The functions ''f''<sub>''i''</sub>(''x''<sub>''i''</sub>) may be fit using parametric or [[Nonparametric regression |non-parametric means]], thus providing the potential for better fits to data than other methods. The method hence is very general &ndash; a typical GAM might use a scatterplot smoothing function such as a locally weighted mean for ''f''<sub>1</sub>(''x''<sub>1</sub>), and then use a factor model for ''f''<sub>2</sub>(''x''<sub>2</sub>). By allowing nonparametric fits, well designed GAMs allow good fits to the training data with relaxed assumptions on the actual relationship, perhaps at the expense of interpretability of results. [[Overfitting]] can be a problem with GAMs. The number of smoothing parameters can be specified, and this number should be reasonably small, certainly well under the [[degrees of freedom (statistics)|degrees of freedom]] offered by the data. [[Cross-validation (statistics)|Cross-validation]] can be used to detect and/or reduce overfitting problems with GAMs (or other statistical methods). Other models such as [[Generalized linear model|GLMs]] may be preferable to GAMs unless GAMs improve predictive ability substantially for the application in question. ==See also== *[[Additive model]] *[[Generalized additive model for location, scale, and shape]] (GAMLSS) *[[Backfitting algorithm]] ==References== *{{cite book|author = Hastie, T. J. and Tibshirani, R. J.|title = Generalized Additive Models|publisher = Chapman & Hall/CRC|year = 1990|isbn=9780412343902}} *{{cite book|author = Wood, S. N.|title = Generalized Additive Models: An Introduction with R|publisher = Chapman & Hall/CRC|year = 2006|isbn=9781584884743}} [[Category:Regression analysis]] [[Category:Non-parametric regression]] [[fr:Modèle additif généralisé]]</text> </page> <page> <id>14967</id> <title>Generalized context-free grammar</title> <text>Generalized Context-free Grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context free composition functions to rewrite rules.<ref name="weir1988">Weir, David H. 1988. Characterizing mildly context-sensitive grammar formalisms. Dissertation, U Penn.</ref> [[Head grammar]] (and its weak equivalents) is an instance of such a GCFG which is known to be especially adept at handling a wide variety of non-CF properties of natural language. ==Description== A GCFG consists of two components: a set of composition functions that combine string tuples, and a set of rewrite rules. The composition functions all have the form <math>f(\langle x_1, ..., x_m \rangle, \langle y_1, ..., y_n \rangle, ...) = \gamma</math>, where <math>\gamma</math> is either a single string tuple, or some use of a (potentially different) composition function which reduces to a string tuple. Rewrite rules look like <math>X \to f(Y, Z, ...)</math>, where <math>Y</math>, <math>Z</math>, ... are string tuples or non-terminal symbols. The rewrite semantics of GCFGs is fairly straight forward. An occurrence of a non-terminal symbol is rewritten using rewrite rules as in a context-free grammar, eventually yielding just compositions (composition functions applied to string tuples or other compositions). The composition functions are then applied, reducing successively reducing the tuples to a single tuple. ==Example== A simple translation of a context-free grammar into a GCFG can be performed in the following fashion. Given the grammar in (1), which generates the palindrome language <math>\{ ww^R : w \in \{a, b\}^{*} \}</math>, where <math>w^R</math> is the string reverse of <math>w</math>, we can define the composition function ''conc'' as in (2a) and the rewrite rules as in (2b). # <math>S \to \epsilon ~|~ aSa ~|~ bSb</math> # ## <math>conc(\langle x \rangle, \langle y \rangle, \langle z \rangle) = \langle xyz \rangle</math> ## <math> S \to conc(\langle \epsilon \rangle, \langle \epsilon \rangle, \langle \epsilon \rangle) ~|~ conc(\langle a \rangle, S, \langle a \rangle) ~|~ conc(\langle b \rangle, S, \langle b \rangle)</math> The CF production of ''abbbba'' is S aSa abSba abbSbba abbbba and the corresponding GCFG production is <math>S \to conc(\langle a \rangle, S, \langle a \rangle)</math> <math>conc(\langle a \rangle, conc(\langle b \rangle, S, \langle b \rangle), \langle a \rangle)</math> <math>conc(\langle a \rangle, conc(\langle b \rangle, conc(\langle b \rangle, S, \langle b \rangle), \langle b \rangle), \langle a \rangle)</math> <math>conc(\langle a \rangle, conc(\langle b \rangle, conc(\langle b \rangle, conc(\langle \epsilon \rangle, \langle \epsilon \rangle, \langle \epsilon \rangle), \langle b \rangle), \langle b \rangle), \langle a \rangle)</math> <math>conc(\langle a \rangle, conc(\langle b \rangle, conc(\langle b \rangle, \langle \epsilon \rangle, \langle b \rangle), \langle b \rangle), \langle a \rangle)</math> <math>conc(\langle a \rangle, conc(\langle b \rangle, \langle bb \rangle, \langle b \rangle), \langle a 