x_1, x_2, \ldots , x_N \right) - \lambda \frac{dg}{dx_2}\left( x_1, x_2, \ldots, x_N \right) & = 0 \\ & {}\ \ \vdots \\ \frac{df}{dx_N}\left( x_1, x_2, \ldots x_N \right) - \lambda \frac{dg}{dx_N}\left( x_1, x_2, \ldots, x_N \right) & = 0 \end{align} </math> === Multiple constraints === For more than one constraint, the same reasoning applies. If there is more than one constraint active together, each constraint contributes a direction that will violate it. Together, these “violation directions” form a “violation space”, where infinitesimal movement in any direction within the space will violate one or more constraints. Thus, to satisfy multiple constraints we can state (using this new terminology) that at the stationary points, the direction that changes ''f'' is in the “violation space” created by the constraints acting jointly. The ''violation space'' created by the constraints consists of all points that can be reached by adding any combination of scaled and/or flipped versions of the individual violation direction vectors. In other words, all the points that are “reachable” when we use the individual violation directions as the basis of the space. Thus, we can succinctly state that ''v'' is in the space defined by <math>b_1, b_2, \ldots ,b_M</math> if and only if there exists a set of “multipliers” <math>\lambda_1, \lambda_2, \ldots , \lambda_M</math> such that: : <math>\sum\limits_{k=1}^M \lambda_k b_k = v</math> which for our purposes, translates to stating that the direction that changes ''f'' at ''p'' is in the “violation space” defined by the constraints <math>g_1,g_2, \ldots, g_M</math> if and only if: : <math>\sum_{k=1}^M \lambda_k \nabla g_k (p) = \nabla f(p) \quad \Rightarrow \quad \nabla f(p) - \sum_{k=1}^M {\lambda_k \nabla g_k (p)} = 0</math> As before, we now add simultaneous equation to guarantee that we only perform this test when we are at a point that satisfies every constraint, we end up with simultaneous equations that when solved, identify all constrained stationary points: : <math>\begin{matrix} \begin{align} g_1(p) & = 0 \\ g_2(p)& =0 \\ & \ \ \vdots \\ g_M(p) &= 0 \\ & \\ \nabla f(p) - \sum_{k=1}^M {\lambda_k \, \nabla g_k (p)} & = 0 \\ \end{align} & \begin{align} & \text{these mean the point satisfies all constraints} \\ & \\ & \\ & \\ & \\ & \text{this means the point is a stationary point} \\ \end{align} \\ \end{matrix}</math> The method is complete now (from the standpoint of solving the problem of finding stationary points) but as mathematicians delight in doing, these equations can be further condensed into an even more elegant and succinct form. Lagrange must have cleverly noticed that the equations above look like partial derivatives of some larger scalar function ''L'' that takes all the <math>x_1, x_2, \ldots, x_N</math> and all the <math>\lambda _1, \lambda_2, \ldots, \lambda _M</math> as inputs. Next, he might then have noticed that setting every equation equal to zero is exactly what one would have to do to solve for the ''unconstrained'' stationary points of that larger function. Finally, he showed that a larger function ''L'' with partial derivatives that are exactly the ones we require can be constructed very simply as below: : <math> \begin{align} & {} \quad L\left( x_1, x_2, \ldots , x_N, \lambda_1, \lambda_2, \ldots, \lambda _M \right) \\ & = f\left( x_1, x_2, \ldots, x_N \right) - \sum\limits_{k=1}^M {\lambda_k g_k\left( x_1, x_2, \ldots , x_N \right)} \end{align} </math> Solving the equation above for its ''unconstrained'' stationary points generates exactly the same stationary points as solving for the ''constrained'' stationary points of ''f'' under the constraints <math>g_1,g_2, \ldots, g_M</math>. In Lagrange’s honor, the function above is called a ''Lagrangian'', the scalars <math>\lambda_1, \lambda_2, \ldots, \lambda_M</math> are called ''Lagrange Multipliers'' and this optimization method itself is called ''The Method of Lagrange Multipliers''. The method of Lagrange multipliers is generalized by the [[Karush–Kuhn–Tucker conditions]], which can also take into account inequality constraints of the form ''h''('''x''') ≤ ''c''. ==Interpretation of the Lagrange multipliers== Often the Lagrange multipliers have an interpretation as some quantity of interest. To see why this might be the case, observe that: :<math>\frac{\partial \Lambda}{\partial {g_k}} = \lambda_k.</math> So, ''λ''<sub>''k''</sub> is the rate of change of the quantity being optimized as a function of the constraint variable. As examples, in [[Lagrangian mechanics]] the equations of motion are derived by finding stationary points of the [[Action (physics)|action]], the time integral of the difference between kinetic and potential energy. Thus, the force on a particle due to a scalar potential, <math>F=-\nabla V</math>, can be interpreted as a Lagrange multiplier determining the change in action (transfer of potential to kinetic energy) following a variation in the particle's constrained trajectory. In economics, the optimal profit to a player is calculated subject to a constrained space of actions, where a Lagrange multiplier is the increase in the value of the objective function due to the relaxation of a given constraint (e.g. through an increase in income or bribery or other means) – the [[marginal cost]] of a constraint, called the [[shadow price]]. In control theory this is formulated instead as [[costate equations]]. == Examples == === Very simple example === [[Image:Lagrange very simple.jpg|thumb|right|300px|Fig. 3. Illustration of the constrained optimization problem]] Suppose you wish to maximize <math>f(x,y)=x+y</math> subject to the constraint <math>x^2+y^2=1</math>. The constraint is the unit circle, and the [[level set]]s of ''f'' are diagonal lines (with slope -1), so one can see graphically that the maximum occurs at <math>(\sqrt{2}/2,\sqrt{2}/2)</math> (and the minimum occurs at <math>(-\sqrt{2}/2,-\sqrt{2}/2)</math>) Formally, set <math>g(x,y)-c=x^2+y^2-1</math>, and :<math>\Lambda(x, y, \lambda) = f(x,y) + \lambda(g(x,y)-c) = x+y + \lambda (x^2 + y^2 - 1)</math> Set the derivative <math>d\Lambda=0</math>, which yields the system of equations: :<math>\begin{align} \frac{\partial \Lambda}{\partial x} &= 1 + 2 \lambda x &&= 0, \qquad \text{(i)} \\ \frac{\partial \Lambda}{\partial y} &= 1 + 2 \lambda y &&= 0, \qquad \text{(ii)} \\ \frac{\partial \Lambda}{\partial \lambda} &= x^2 + y^2 - 1 &&= 0, \qquad \text{(iii)} \end{align}</math> As always, the <math>\partial \lambda</math> equation ((iii) here) is the original constraint. Combining the first two equations yields <math>x=y</math> (explicitly, <math>\lambda \neq 0</math>, otherwise (i) yields 1 = 0, so one has <math>x=-1/(2\lambda)=y</math>). Substituting 