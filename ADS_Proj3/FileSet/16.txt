software must also be [[porting|ported]] to use the new capabilities; older software is usually supported through either a ''hardware compatibility mode'' (in which the new processors support the older 32-bit version of the instruction set as well as the 64-bit version), through software [[Emulator|emulation]], or by the actual implementation of a 32-bit processor core within the 64-bit processor (as with the Itanium processors from Intel, which include an [[x86]] processor core to run 32-bit x86 applications). The operating systems for those 64-bit architectures generally support both 32-bit and 64-bit applications.<ref>{{cite web | title = Windows 7: 64 bit vs 32 bit? | publisher = W7 Forums | url = http://www.w7forums.com/windows-7-64-bit-vs-32-bit-t484.html | accessdate = 2009-04-05 }}</ref> One significant exception to this is the [[AS/400]], whose software runs on a virtual [[Instruction Set Architecture|ISA]], called TIMI (Technology Independent Machine Interface) which is translated to native machine code by low-level software before being executed. The low-level software is all that has to be rewritten to move the entire OS and all software to a new platform, such as when IBM transitioned their line from the older 32/48-bit "IMPI" instruction set to 64-bit PowerPC (IMPI wasn't anything like 32-bit PowerPC, so this was an even bigger transition than from a 32-bit version of an instruction set to a 64-bit version of the same instruction set). While 64-bit architectures indisputably make working with large data sets in applications such as [[digital video]], scientific computing, and large [[database]]s easier, there has been considerable debate as to whether they or their 32-bit compatibility modes will be faster than comparably-priced 32-bit systems for other tasks. In [[x86-64]] architecture (AMD64), the majority of the 32-bit operating systems and applications are able to run smoothly on the 64-bit hardware. A compiled Java program can run on a 32 bit or 64 bit Java virtual machine without modification. The lengths and precision of all the built in types are specified by the standard and are not dependent on the underlying architecture. Java programs that run on a 64 bit Java virtual machine have access to a larger address space.<ref>{{cite web | title = Frequently Asked Questions About the Java HotSpot VM | publisher = Sun Microsystems, Inc | url = http://java.sun.com/docs/hotspot/HotSpotFAQ.html#64bit_compilers | accessdate = 2007-05-03 }}</ref> Speed is not the only factor to consider in a comparison of 32-bit and 64-bit processors. Applications such as multi-tasking, stress testing, and clustering—for HPC ([[high-performance computing]])—may be more suited to a 64-bit architecture when deployed appropriately. 64-bit clusters have been widely deployed in large organizations such as IBM, HP and Microsoft, for this reason. ==Pros and cons== A common{{fact|date=January 2011}} misconception is that 64-bit architectures are no better than 32-bit architectures unless the computer has more than 4 GB of [[main memory]]. This is not entirely true: *Some operating systems and certain hardware configurations limit the physical memory space to 3 GB on [[IA-32]] systems, due to much of the 3–4 GB region being reserved for hardware addressing; see [[3 GB barrier]]. This is not present in 64-bit architectures, which can use 4 GB of memory and more. However, IA-32 processors from the [[Pentium II]] onwards allow for a 36-bit ''physical'' memory address space, using [[Physical Address Extension]] (PAE), which gives a 64 GB physical address range, of which up to 62 GB may be used by main memory; operating systems that support PAE may not be limited to 4GB of physical memory, even on IA-32 processors. *Some operating systems reserve portions of [[Process (computing)|process]] [[address space]] for OS use, effectively reducing the total address space available for mapping memory for user programs. For instance, Windows XP DLLs and other user mode OS components are mapped into each process's address space, leaving only 2 to 3 GB (depending on the settings) address space available. This limit is currently much higher on 64-bit operating systems and does not realistically restrict memory usage. *[[Memory-mapped file]]s are becoming more difficult to implement in 32-bit architectures.{{Citation needed|date=November 2010}} A 4 GB file is no longer uncommon, and such large files cannot be memory mapped easily to 32-bit architectures; only a region of the file can be mapped into the address space, and to access such a file by memory mapping, those regions will have to be mapped into and out of the address space as needed. This is a problem, as memory mapping remains one of the most efficient disk-to-memory methods, when properly implemented by the OS. *Some programs such as data encryption software can benefit greatly from 64-bit registers (if the software is 64-bit compiled) and effectively execute 3 to 5 times faster on 64-bit than on 32-bit.{{Citation needed|date=April 2010}} *Some 64-bit architectures, such as [[x86-64]], allow for more general purpose registers than their 32-bit counterparts. This is a significant speed increase for tight loops since the processor doesn't have to go out the second level cache or main memory to gather data if it can fit in the available registers. :Example in [[C (programming language)|C]]: <source lang="c"> for (a=0; a<100; a++) { b = a; c = b; d = c; e = d; } </source> :If a processor only has the ability to keep two three values/variables (registers) in fast memory it would need to stop executing and push and pop the stack to be able to process variable d and e as well. A process that takes a lot of CPU cycles. A processor that is capable of holding all the values/variables (registers) in memory can simply just loop through this without needing to halt execution for each iteration just to get the proper data in memory. This behavior can easily be compared with virtual memory, although any effects are contingent upon the compiler. The main disadvantage of 64-bit architectures is that relative to 32-bit architectures, the same data occupies more space in memory (due to swollen pointers and possibly other types and alignment padding). This increases the memory requirements of a given process and can have implications for efficient processor cache utilization. Maintaining 