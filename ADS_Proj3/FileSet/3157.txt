:''First'', the visual field content is unknown before perception occurred :''Second'', it may contain any of a number of objects. Important information could be contained in any bottom-up signal; Therefore, the similarity measure is constructed so that it accounts for all bottom-up signals, ''X''(''n''), :<math> L( \{\vec X(n)\}, \{\vec M_m( \vec S_m, n)\} ) = \prod_{n=1}^N{l(\vec X(n))}.</math> (1) This expression contains a product of partial similarities, l('''X'''(n)), over all bottom-up signals; therefore it forces the NMF system to account for every signal (even if one term in the product is zero, the product is zero, the similarity is low and the knowledge instinct is not satisfied); this is a reflection of the first principle. Second, before perception occurs, the mind does not know which object gave rise to a signal from a particular retinal neuron. Therefore a partial similarity measure is constructed so that it treats each model as an alternative (a sum over concept-models) for each input neuron signal. Its constituent elements are conditional partial similarities between signal '''X'''(n) and model '''M<sub>m</sub>''', l('''X'''(n)|m). This measure is “conditional” on object m being present, therefore, when combining these quantities into the overall similarity measure, L, they are multiplied by r(m), which represent a probabilistic measure of object m actually being present. Combining these elements with the two principles noted above, a similarity measure is constructed as follows: :<math> L( \{\vec X(n)\}, \{\vec M_m( \vec S_m, n)\} ) = \prod_{n=1}^N{ \sum_{m=1}^M { r(m) l(\vec X(n) | m) } }.</math> (2) The structure of the expression above follows standard principles of the probability theory: a summation is taken over alternatives, m, and various pieces of evidence, n, are multiplied. This expression is not necessarily a probability, but it has a probabilistic structure. If learning is successful, it approximates probabilistic description and leads to near-optimal Bayesian decisions. The name “conditional partial similarity” for l('''X'''(n)|m) (or simply l(n|m)) follows the probabilistic terminology. If learning is successful, l(n|m) becomes a conditional probability density function, a probabilistic measure that signal in neuron n originated from object m. Then L is a total likelihood of observing signals {'''X'''(n)} coming from objects described by concept-model {'''M<sub>m</sub>'''}. Coefficients r(m), called priors in probability theory, contain preliminary biases or expectations, expected objects m have relatively high r(m) values; their true values are usually unknown and should be learned, like other parameters '''S<sub>m</sub>'''. Note that in probability theory, a product of probabilities usually assumes that evidence is independent. Expression for L contains a product over n, but it does not assume independence among various signals '''X'''(n). There is a dependence among signals due to concept-models: each model '''M<sub>m</sub>'''('''S<sub>m</sub>''',n) predicts expected signal values in many neurons n. During the learning process, concept-models are constantly modified. Usually, the functional forms of models, '''M<sub>m</sub>'''('''S<sub>m</sub>''',n), are all fixed and learning-adaptation involves only model parameters, '''S<sub>m</sub>'''. From time to time a system forms a new concept, while retaining an old one as well; alternatively, old concepts are sometimes merged or eliminated. This requires a modification of the similarity measure L; The reason is that more models always result in a better fit between the models and data. This is a well known problem, it is addressed by reducing similarity L using a “skeptic penalty function,” ([[Penalty method]]) p(N,M) that grows with the number of models M, and this growth is steeper for a smaller amount of data N. For example, an asymptotically unbiased maximum likelihood estimation leads to multiplicative p(N,M) = exp(-N<sub>par</sub>/2), where N<sub>par</sub> is a total number of adaptive parameters in all models (this penalty function is known as [[Akaike information criterion]], see (Perlovsky 2001) for further discussion and references). ==Learning in NMF using dynamic logic algorithm== The learning process consists of estimating model parameters '''S''' and associating signals with concepts by maximizing the similarity L. Note that all possible combinations of signals and models are accounted for in expression (2) for L. This can be seen by expanding a sum and multiplying all the terms resulting in M<sup>N</sup> items, a huge number. This is the number of combinations between all signals (N) and all models (M). This is the source of Combinatorial Complexity, which is solved in NMF by utilizing the idea of [[Perlovsky|dynamic logic]]<ref>Perlovsky, L.I. (1996). Mathematical Concepts of Intellect. Proc. World Congress on Neural Networks, San Diego, CA; Lawrence Erlbaum Associates, NJ, pp.1013-16</ref>, <ref>Perlovsky, L.I.(1997). Physical Concepts of Intellect. Proc. Russian Academy of Sciences, 354(3), pp. 320-323.</ref>. An important aspect of dynamic logic is ''matching vagueness or fuzziness of similarity measures to the uncertainty of models''. Initially, parameter values are not known, and uncertainty of models is high; so is the fuzziness of the similarity measures. In the process of learning, models become more accurate, and the similarity measure more crisp, the value of the similarity increases. The maximization of similarity L is done as follows. First, the unknown parameters {'''S'''<sub>m</sub>} are randomly initialized. Then the association variables f(m|n) are computed, :<math> f(m|n) = \frac{r(m) l( \vec X(n|m)) }{ \sum_{m'=1}^M { r(m') l( \vec X(n|m')) } } </math> (3). Equation for f(m|n) looks like the Bayes formula for a posteriori probabilities; if l(n|m) in the result of learning become conditional likelihoods, f(m|n) become Bayesian probabilities for signal n originating from object m. The dynamic logic of the NMF is defined as follows: :<math> \frac{d \vec S_m }{dt} = \sum_{n=1}^N { f(m|n) \frac{\partial{\ln l(n|m)} }{\partial{\vec M_m} } \frac{\partial{\vec M_m}}{\partial{\vec S_m}} } </math> (4). :<math> \frac{df(m|n)}{dt} = f(m|n)\sum_{m'=1}^M { [\delta_{mm'} - f(m'|n)] \frac{\partial{\ln l(n|m')}}{\partial{\vec M_{m'}}} } \frac{\partial{\vec M_{m'}}}{\partial{\vec S_{m'}}} \frac{d \vec S_{m'}}{dt} </math> (5) The following theorem has been proved (Perlovsky 2001): ''Theorem''. Equations (3), (4), and (5) define a convergent dynamic NMF system with stationary states defined by max{S<sub>m</sub>}L. It follows that the stationary states of an MF system are the maximum similarity states. When partial similarities are specified as probability density functions (pdf), or likelihoods, the stationary values of parameters {'''S'''<sub>m</sub>} are asymptotically unbiased and efficient estimates of these parameters<ref>Cramer, H. (1946). Mathematical Methods of Statistics, Princeton University Press, Princeton NJ.</ref>. The computational 