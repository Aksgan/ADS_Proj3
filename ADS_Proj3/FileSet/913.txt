confidence intervals that are quoted are only approximately valid, perhaps derived from "plus or minus twice the standard error", and the implications of this for the supposedly corresponding hypothesis tests are usually unknown. ==Meaning and interpretation== For users of frequentist methods, various interpretations of a confidence interval can be given. *The confidence interval can be expressed in terms of samples (or repeated samples): "''Were this procedure to be repeated on multiple samples, the calculated confidence interval (which would differ for each sample) would encompass the true population parameter 90% of the time."''<ref>Cox DR, Hinkley DV. (1974) Theoretical Statistics, Chapman & Hall, p49, 209</ref> Note that this need not be repeated sampling from the same population, just repeated sampling <ref>Kendall, M.G. and Stuart, D.G. (1973) The Advanced Theory of Statistics. Vol 2: Inference and Relationship, Griffin, London. Section 20.4</ref>. *The explanation of a confidence interval can amount to something like: "''The confidence interval represents values for the population parameter for which the difference between the parameter and the observed estimate is not [[statistically significant]] at the 10% level''"<ref>Cox DR, Hinkley DV. (1974) Theoretical Statistics, Chapman & Hall, p214, 225, 233</ref>. In fact, this relates to one particular way in which a confidence interval may be constructed. *The probability associated with a confidence interval may also be considered from a pre-experiment point of view, in the same context in which arguments for the random allocation of treatments to study items are made. Here the experimenter sets out the way in which they intend to calculate a confidence interval and know, before they do the actual experiment, that the interval they will end up calculating has a certain chance of covering the true but unknown value.<ref>[[Jerzy Neyman|Neyman, J.]] (1937) [http://links.jstor.org/sici?sici=0080-4614%2819370830%29236%3A767%3C333%3AOOATOS%3E2.0.CO%3B2-6 "Outline of a Theory of Statistical Estimation Based on the Classical Theory of Probability"], ''Philosophical Transactions of the Royal Society of London A,'' 236, 333&ndash;380.</ref> This is very similar to the "repeated sample" interpretation above, except that it avoids relying on considering hypothetical repeats of a sampling procedure that may not be repeatable in any meaningful sense. See [[Neyman construction]]. In each of the above, the following applies: If the true value of the parameter lies outside the 90% confidence interval once it has been calculated, then an event has occurred which had a probability of 10% (or less) of happening by chance. === Meaning of the term "confidence" ===<!-- linked to from [[Statistical significance]] --> There is a difference in meaning between the common usage of the word "confidence" and its statistical usage, which is often confusing to the layman, and this is one of the [[#Alternatives and critiques|critiques]] of confidence intervals, namely that in application by non-statisticians, the term "confidence" is misleading. In common usage, a claim to 95% confidence in something is normally taken as indicating virtual certainty. In statistics, a claim to 95% confidence simply means that the researcher has seen something occur that only happens one time in 20 or less. If one were to roll two dice and get double six (which happens 1/36th of the time, or about 3%), few would claim this as proof that the dice were fixed, although statistically speaking one could have 97% confidence that they were. Similarly, the finding of a statistical link at 95% confidence is not proof, nor even very good evidence, that there is any real connection between the things linked. When a study involves multiple statistical tests, some laymen assume that the confidence associated with individual tests is the confidence one should have in the results of the study itself. In fact, the results of all the statistical tests conducted during a study must be judged as a whole in determining what confidence one may place in the positive links it produces. For example, say a study is conducted which involves 40 statistical tests at 95% confidence, and which produces 3 positive results. Each test has a 5% chance of producing a false positive, so such a study will produce 3 false positives about two times in three. Thus the confidence one can have that any of the study's positive conclusions are correct is only about 32%, well below the 95% the researchers have set as their standard of acceptance. == Alternatives and critiques == {{Main|Interval estimation|Credible interval|Prediction interval}} Confidence intervals are one method of [[interval estimation]], and the most widely used in [[frequentist statistics]]. An analogous concept in [[Bayesian statistics]] is [[credible interval]]s, while an alternative frequentist method is that of [[prediction interval]]s which, rather than estimating ''parameters,'' estimate the outcome of ''future'' samples. For other approaches to expressing uncertainty using intervals, see [[interval estimation]]. There is disagreement about which of these methods produces the most useful results: the mathematics of the computations are rarely in question – confidence intervals being based on sampling distributions, credible intervals being based on [[Bayes' theorem]] – but the application of these methods, the utility and interpretation of the produced statistics, is debated. Users of Bayesian methods, if they produced an [[interval estimation|interval estimate]], would in contrast to confidence intervals, want to say "''My degree of ''belief'' that the parameter is in fact in this interval is 90%,''"<ref>Cox DR, Hinkley DV. (1974) Theoretical Statistics, Chapman & Hall, p390</ref> while users of prediction intervals would instead say "I ''predict'' that the ''next sample'' will fall in this interval 90% of the time."{{Citation needed|date=October 2010}} Confidence intervals are an expression of probability and are subject to the normal laws of probability. If several statistics are presented with confidence intervals, each calculated separately on the assumption of independence, that assumption must be honoured or the calculations will be rendered invalid. For example, if a researcher generates a set of statistics with intervals and selects some of them as significant, the act of selecting invalidates the calculations used to generate the intervals. ===Philosophical issues=== The principle behind confidence intervals was formulated to provide an answer to the question raised in [[statistical inference]] of how to deal with the uncertainty inherent in results derived from 