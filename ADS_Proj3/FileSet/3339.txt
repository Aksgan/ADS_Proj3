are equally active for positive and negative reinforcers, and have been demonstrated to cause [[neuroplasticity|plasticity]] in many [[cerebral cortex|cortical]] regions.<ref>PNAS 93:11219-24 1996, Science 279:1714–8 1998</ref> Evidence also exists that [[Dopamine#Functions in the brain|dopamine]] is activated at similar times. There is considerable evidence that dopamine participates in both reinforcement and aversive learning.<ref>Neuron 63:244–253, 2009, Frontiers in Behavioral Neuroscience, 3: Article 13, 2009</ref> Dopamine pathways project much more densely onto [[frontal cortex]] regions. [[Cholinergic]] projections, in contrast, are dense even in the posterior cortical regions like the [[primary visual cortex]]. A study of patients with [[Parkinson's disease]], a condition attributed to the insufficient action of dopamine, further illustrates the role of dopamine in positive reinforcement.<ref>Michael J. Frank, Lauren C. Seeberger, and Randall C. O'Reilly (2004) "By Carrot or by Stick: Cognitive Reinforcement Learning in Parkinsonism," Science 4, November 2004</ref> It showed that while off their medication, patients learned more readily with aversive consequences than with positive reinforcement. Patients who were on their medication showed the opposite to be the case, positive reinforcement proving to be the more effective form of learning when the action of dopamine is high. ==Factors that alter the effectiveness of consequences== When using consequences to modify a response, the effectiveness of a consequence can be increased or decreased by various factors. These factors can apply to either reinforcing or punishing consequences. # '''Satiation/Deprivation:''' The effectiveness of a consequence will be reduced if the individual's "appetite" for that source of stimulation has been satisfied. Inversely, the effectiveness of a consequence will increase as the individual becomes deprived of that stimulus. If someone is not hungry, food will not be an effective reinforcer for behavior. Satiation is generally only a potential problem with primary reinforcers, those that do not need to be learned such as food and water. # '''Immediacy:''' After a response, how immediately a consequence is then felt determines the effectiveness of the consequence. More immediate feedback will be more effective than less immediate feedback. If someone's license plate is caught by a traffic camera for speeding and they receive a speeding ticket in the mail a week later, this consequence will not be very effective against speeding. But if someone is speeding and is caught in the act by an officer who pulls them over, then their speeding behavior is more likely to be affected. # '''Contingency:''' If a consequence does not contingently (reliably, or consistently) follow the target response, its effectiveness upon the response is reduced. But if a consequence follows the response consistently after successive instances, its ability to modify the response is increased. The schedule of reinforcement, when consistent, leads to faster learning. When the schedule is variable the learning is slower. Extinction is more difficult when learning occurs during intermittent reinforcement and more easily extinguished when learning occurs during a highly consistent schedule. # '''Size:''' This is a "cost-benefit" determinant of whether a consequence will be effective. If the size, or amount, of the consequence is large enough to be worth the effort, the consequence will be more effective upon the behavior. An unusually large lottery jackpot, for example, might be enough to get someone to buy a one-dollar lottery ticket (or even buying multiple tickets). But if a lottery jackpot is small, the same person might not feel it to be worth the effort of driving out and finding a place to buy a ticket. In this example, it's also useful to note that "effort" is a punishing consequence. How these opposing expected consequences (reinforcing and punishing) balance out will determine whether the behavior is performed or not. Most of these factors exist for biological reasons. The biological purpose of the Principle of Satiation is to maintain the organism's [[homeostasis]]. When an organism has been deprived of sugar, for example, the effectiveness of the taste of sugar as a reinforcer is high. However, as the organism reaches or exceeds their optimum blood-sugar levels, the taste of sugar becomes less effective, perhaps even aversive. The Principles of Immediacy and Contingency exist for neurochemical reasons. When an organism experiences a reinforcing stimulus, [[dopamine]] pathways in the brain are activated. This network of pathways "releases a short pulse of dopamine onto many [[dendrites]], thus broadcasting a rather global reinforcement signal to postsynaptic neurons."<ref>Schultz, Wolfram (1998). Predictive Reward Signal of Dopamine Neurons. ''The Journal of Neurophysiology'', 80(1), 1–27.</ref> This results in the plasticity of these synapses allowing recently activated synapses to increase their sensitivity to efferent signals, hence increasing the probability of occurrence for the recent responses preceding the reinforcement. These responses are, statistically, the most likely to have been the behavior responsible for successfully achieving reinforcement. But when the application of reinforcement is either less immediate or less contingent (less consistent), the ability of dopamine to act upon the appropriate synapses is reduced. ==Operant variability== Operant variability is what allows a response to adapt to new situations. Operant behavior is distinguished from reflexes in that its '''response topography''' (the form of the response) is subject to slight variations from one performance to another. These slight variations can include small differences in the specific motions involved, differences in the amount of force applied, and small changes in the timing of the response. If a subject's history of reinforcement is consistent, such variations will remain stable because the same successful variations are more likely to be reinforced than less successful variations. However, behavioral variability can also be altered when subjected to certain controlling variables.<ref>Neuringer, A. (2002). Operant variability: Evidence, functions, and theory. Psychonometric Bulletin & Review, 9(4), 672–705.</ref> ==Avoidance learning== Avoidance learning belongs to negative reinforcement schedules. The subject learns that a certain response will result in the termination or prevention of an aversive stimulus. There are two kinds of commonly used experimental settings: discriminated and free-operant avoidance learning. ===Discriminated avoidance learning=== In discriminated avoidance learning, a novel stimulus such as a light or a tone is followed by an aversive stimulus such as a shock (CS-US, similar to classical conditioning). During the first trials (called escape-trials) 